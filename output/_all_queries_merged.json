[
  {
    "topic":"AI in healthcare",
    "title":"AI in Healthcare: Uses, Examples and Benefits - Built In",
    "url":"https:\/\/builtin.com\/artificial-intelligence\/artificial-intelligence-healthcare",
    "domain":"builtin.com",
    "snippet":"Artificial intelligence simplifies the lives of patients, doctors and hospital administrators by performing tasks that are typically done by humans, but in less time and at a fraction of the cost. AI in healthcare shows up in a number of ways, such as finding new links between genetic codes, powerin...",
    "content":"Artificial intelligence simplifies the lives of patients, doctors and hospital administrators by performing tasks that are typically done by humans, but in less time and at a fraction of the cost.\nAI in healthcare shows up in a number of ways, such as finding new links between genetic codes, powering surgery-assisting robots, automating administrative tasks, personalizing treatment options and much more.\nUses for AI in Healthcare\n- Improving medical diagnosis\n- Speeding up drug discovery\n- Transforming patient experience\n- Managing healthcare data\n- Performing robotic surgery\nPut simply, AI is reinventing \u2014 and reinvigorating \u2014 modern healthcare through machines that can predict, comprehend, learn and act.\nWhat Is AI in Healthcare?\nAI in healthcare refers to the use of machine learning, natural language processing, deep learning and other AI technologies to enhance the experiences of both healthcare professionals and patients. The data-processing and predictive capabilities of AI enable health professionals to better manage their resources and take a more proactive approach to various aspects of healthcare.\nWith these technologies, doctors can then make quicker and more accurate diagnoses, health administrators can locate electronic health records faster and patients can receive more timely and personalized treatments.\nExamples of AI in Healthcare\nTo give you a better understanding of the rapidly evolving field, we rounded up some examples and use cases of AI in healthcare.\nAI in Medical Diagnosis\nEvery year, roughly 400,000 hospitalized patients suffer preventable harm, with 100,000 deaths. In light of that, the promise of improving the diagnostic process is one of AI\u2019s most exciting healthcare applications. Incomplete medical histories and large caseloads can lead to deadly human errors. Immune to those variables, AI can predict and diagnose disease at a faster rate than most medical professionals.\nAI in Drug Discovery\nThe drug development industry is bogged down by skyrocketing development costs and research that takes thousands of human hours. Putting each drug through clinical trials costs an estimated average of $1.3 billion, and only 10 percent of those drugs are successfully brought to market. Due to breakthroughs in technology, AI is speeding up this process by helping design drugs, predicting any side effects and identifying ideal candidates for clinical trials.\nAI in Patient Experience\nAI can be used to support digital communications, offering schedule reminders, tailored health tips and suggested next steps to patients. The ability of AI to aid in health diagnoses also improves the speed and accuracy of patient visits, leading to faster and more personalized care. And efficiently providing a seamless patient experience allows hospitals, clinics and physicians to treat more patients on a daily basis.\nAI in Healthcare Data Management\nHighly valuable information can sometimes get lost among the forest of trillions of data points. Additionally, the inability to connect important data points slows the development of new drugs, preventative medicine and proper diagnosis. Because of its ability to handle massive volumes of data, AI breaks down data silos and connects in minutes information that used to take years to process. This can reduce the time and costs of healthcare administrative processes, contributing to more efficient daily operations and patient experiences.\nAI in Robotic Surgery\nHospitals use AI and robots to help with everything from minimally invasive procedures to open heart surgery. Surgeons can control a robot\u2019s mechanical arms while seated at a computer console as the robot gives the doctor a three-dimensional, magnified view of the surgical site. The surgeon then leads other team members who work closely with the robot through the entire operation. Robot-assisted surgeries have led to fewer surgery-related complications, less pain and a quicker recovery time.\nCompanies Using AI in Healthcare\nThese are some of the companies paving the way for healthcare innovation by applying AI technology.\nLocation: New York, New York\nEliseAI specializes in conversational AI solutions. In the healthcare space, EliseAI offers AI-powered technology that can automate administrative tasks like appointment scheduling and sending payment reminders. Its AI capabilities engage patients across SMS, voice, email and web chat formats.\nLocation: San Mateo, California\nEvidation\u2019s mobile app supports users\u2019 health through rewards and education content. It also gives them the option of participating in health research for life sciences companies, government agencies and academic institutions. The company uses AI to support its research partners, developing solutions for applications like notifying users who report flu systems and are in the right geographic location about how to join a clinical trial for a flu treatment.\nLocation: Boston, Massachusetts\nCohere Health uses AI and machine learning to revolutionize prior authorization processes to ensure patients can access care swiftly. Through its Cohere Unify Platform, health plans can proactively create data-driven care paths, leading to pre-approval for services. By integrating real-time analytics, clinical intelligence and responsible AI, Cohere aligns patients, healthcare providers and health plans. It aims to facilitate stress-free experiences to deliver efficient, quality, cost-effective care.\nLocation: New York, New York\nFlatiron Health is a cloud-based SaaS company specializing in cancer care, offering oncology software that connects cancer centers nationwide to improve treatments and accelerate research. Using advanced technology, including artificial intelligence, it advances oncology by connecting community oncologists, academics, hospitals and life science researchers, providing integrated patient population data and business intelligence analytics. By leveraging billions of data points from cancer patients, Flatiron Health enables stakeholders to gain new insights and enhance patient care.\nLocation: Evanston, Illinois\nGlobal consulting firm ZS specializes in providing strategic support to businesses across various sectors, with a particular focus on healthcare, leveraging its expertise in AI, sales, marketing, analytics and digital transformation. ZS helps clients navigate complex challenges within industries such as medical technology, life sciences, health plans and pharmaceuticals, using advanced AI and analytics tools.\nLocation: New York, New York\nHealthee uses AI to power its employee benefits app, which businesses rely on to help their team members effectively navigate the coverage and medical treatment options available to them. It includes a virtual healthcare assistant known as Zoe that offers Healthee users personalized answers to benefits-related questions.\nLocation: New York, New York\nPfizer uses AI to aid its research into new drug candidates for treating various diseases. For example, the company used AI and machine learning to support the development of a Covid-19 treatment called PAXLOVID. Scientists at Pfizer are able to rely on modeling and simulation to identify compounds that have the highest likelihood of being effective treatment candidates so they can narrow their efforts.\nLocation: Tokyo, Japan\nAs a global pharmaceutical company, Takeda works to develop treatments and vaccines to address conditions ranging from celiac disease and Parkinson\u2019s disease to rare autoimmune disorders and dengue. Takeda\u2019s outline for sustainably and responsibly adopting AI into its operations explains that the company uses the technology for applications like developing new medicines and optimizing treatments already in use.\nLocation: Fort Collins, Colorado\nEnlitic develops deep learning medical tools to streamline radiology diagnoses. The company\u2019s deep learning platform analyzes unstructured medical data \u2014 radiology images, blood tests, EKGs, genomics, patient medical history \u2014 to give doctors better insight into a patient\u2019s real-time needs.\nLocation: Austin, Texas\nBabylon is on a mission to re-engineer healthcare by shifting the focus away from caring for the sick to helping prevent sickness, leading to better health and fewer health-related expenses. The platform features an AI engine created by doctors and deep learning scientists that operates an interactive symptom checker, using known symptoms and risk factors to provide the most informed and up-to-date medical information possible.\nLocation: Burlington, Massachusetts\nButterfly Network designs AI-powered probes that connect to a mobile phone, so healthcare personnel can conduct ultrasounds in a range of settings. Both the iQ3 and IQ+ products provide high-quality images and extract data for fast assessments. With the ability to create and analyze 3D visualizations, Butterfly Network\u2019s tools can be used for anesthesiology, primary care, emergency medicine and other areas.\nLocation: Palo Alto, California\nCloudMedX uses machine learning to generate insights for improving patient journeys throughout the healthcare system. The company\u2019s technology helps hospitals and clinics manage patient data, clinical history and payment information by using predictive analytics to intervene at critical junctures in the patient care experience. Healthcare providers can use these insights to efficiently move patients through the system.\nLocation: Boston, Massachusetts\nBiofourmis connects patients and health professionals with its cloud-based platform to support home-based care and recovery. The company\u2019s platform integrates with mobile devices and wearables, so teams can collect AI-driven insights, message patients when needed and conduct virtual visits. This way, hospitals can release patients earlier and ensure a smoother transition while remotely monitoring their progress.\nLocation: San Mateo, California\nCaption Health combines AI and ultrasound technology for early disease identification. AI guides providers through the ultrasound process in real time to produce diagnostic-quality images that the software then helps to interpret and assess.\nLocation: Copenhagen, Denmark\nCorti\u2019s platform leverages AI to improve the operations and practices of emergency medical services personnel. A suite of Corti features automatically summarizes emergency calls, speeds up documentation and tracks employee performance. By compiling and analyzing this data, Corti can deliver insights to help teams pinpoint inefficiencies, offer employees tailored feedback and update any call guidelines as needed.\nLocation: San Francisco, California\nAtomwise uses AI to tackle serious diseases, including Ebola and multiple sclerosis. The company\u2019s neural network, AtomNet, helps predict bioactivity and identify patient characteristics for clinical trials. Atomwise\u2019s AI technology screens between 10 and 20 million genetic compounds each day and can reportedly deliver results 100 times faster than traditional pharmaceutical companies.\nLocation: South San Francisco, California\nFreenome uses AI in screenings, diagnostic tests and blood work to test for cancer. By deploying AI at general screenings, Freenome aims to detect cancer in its earliest stages and subsequently develop new treatments.\nLocation: Salt Lake City, Utah\nRecursion\u2019s operating system accelerates drug discovery and development by generating and analyzing large amounts of in-house biological and chemical data. During experiments, Recursion relies on hardware systems, microscopes and continuous video feeds to collect data for its OS to review. The company has also partnered with NVIDIA to apply generative AI to its methods, making drug development even faster.\nLocation: San Francisco, California\nInsitro specializes in human disease biology, combining generative AI and machine learning to spearhead medicine development. The company generates phenotypic cellular data and gathers clinical data from human cohorts for deep learning and machine learning models to comb through. Based on this information, Insitro\u2019s technology can spot patterns in genetic data and build disease models to spur the discovery of new medicines.\nLocation: New York, New York\nOwkin leverages AI technology for drug discovery and diagnostics with the goal of enhancing cancer treatment. The company\u2019s AI tools help identify new drug targets, recommend possible drug combinations and suggest additional diseases that a drug can be repurposed to treat. Owkin also produces RlapsRisk, a diagnostic tool for assessing a breast cancer patient\u2019s risk of relapse, and MSIntuit, a tool that assists with screening for colorectal cancer.\nLocation: Toronto, Ontario\nDeep Genomics\u2019 AI platform helps researchers find candidates for developmental drugs related to neuromuscular and neurodegenerative disorders. Finding the right candidates during a drug\u2019s development statistically raises the chances of successfully passing clinical trials while also decreasing time and cost to market.\nLocation: Armonk, New York\nOnce known as a Jeopardy-winning supercomputer, IBM\u2019s Watson now helps healthcare professionals harness their data to optimize hospital efficiency, better engage with patients and improve treatment. Watson applies its skills to everything from developing personalized health plans to interpreting genetic testing results and catching early signs of disease.\nLocation: Houston, Texas\nInformAI offers a suite of AI products for the healthcare field. Its RadOncAI tool uses AI to create a radiation therapy plan, homing in on tumors while limiting cancer patients\u2019 exposure as much as possible. Meanwhile, TransplantAI evaluates donor and recipient data to determine promising matches and support successful organ transplants. And InformAI\u2019s SinusAI product helps health teams more quickly detect sinus diseases.\nLocation: San Francisco, California\nKomodo Health has built the \u201cindustry\u2019s largest and most complete database of de-identified, real-world patient data,\u201d known as the Healthcare Map. This Map tracks individual patient interactions across the healthcare system, applying AI and machine learning to extract data related to individuals or larger demographics. With this information, healthcare professionals can develop more complete patient profiles while also using categories like race and ethnicity to factor social inequities into a patient\u2019s health history.\nLocation: Philadelphia, Pennsylvania\nOncora Medical aids oncologists in cancer research and prevention. During patient consultations, the company\u2019s platform automates notetaking and locates important patient details from past records, saving oncologists time. Oncora\u2019s platform also comes equipped with machine learning models that can identify high-risk individuals and determine when patients are eligible to participate in clinical trials.\nLocation: New York, New York\nAiCure helps healthcare teams ensure patients are following drug dosage instructions during clinical trials. Supplementing AI and machine learning with computer vision, the company\u2019s mobile app tracks when patients aren\u2019t taking their medications and gives clinical teams time to intervene. In addition, AiCure provides a platform that gleans insights from clinical data to explain patient behavior, so teams can study how patients react to medications.\nLocation: Boston, Massachusetts\nPathAI develops machine learning technology to assist pathologists in making more accurate diagnoses. The company\u2019s goals include reducing errors in cancer diagnosis and developing methods for individualized medical treatment. PathAI worked with drug developers like Bristol-Myers Squibb and organizations like the Bill & Melinda Gates Foundation to expand its AI technology into other healthcare industries.\nLocation: Menlo Park, California\nGRAIL leverages AI to detect cancer in its early stages. With a single blood test, the company\u2019s Galleri test screens over 100,000 DNA regions for cancer signals. If it detects cancerous cells, the test can predict the tissue or organ associated with the cancer. GRAIL intends for its test to become a routine screening for cancer along with other comprehensive detection methods.\nLocation: Boston, Massachusetts\nWith its early detection platform for cognitive assessments, Linus Health is on a mission to modernize brain health. Its proprietary assessment technology DCTclock takes the gold standard pen-and-paper clock drawing test for early signs of cognitive impairment and digitizes it, bringing together the most recent advances in neuroscience and AI to analyze over 100 metrics that reflect the patient\u2019s cognitive function.\nLocation: San Francisco, California\nIn healthcare, delays can mean the difference between life and death, so Viz.ai helps care teams react faster with AI-powered healthcare solutions. The company\u2019s AI products can detect issues and notify care teams quickly, enabling providers to discuss options and provide faster treatment decisions, thus saving lives.\nLocation: Los Angeles, California\nRegard uses AI technology to diagnose patients. The company describes its automated system to be the clinical \u201cco-pilot\u201d to electronic medical records (EMRs). The data from EMRs is synthesized to discover a diagnosis. Additionally, healthcare providers receive specific recommendations about patient care. The system also updates patient documents automatically to reduce burnout among healthcare workers.\nLocation: Boston, Massachusetts\nDeveloped by a team out of Harvard Medical School, Buoy Health is an AI-based symptom and cure checker that uses algorithms to diagnose and treat illness. Here\u2019s how it works: a chatbot listens to a patient\u2019s symptoms and health concerns, then guides that patient to the correct care based on its diagnosis.\nLocation: Boston, Massachusetts\nBeth Israel Deaconess Medical Center used AI for diagnosing potentially deadly blood diseases at an early stage. Doctors developed AI-enhanced microscopes to scan for harmful bacteria like E. coli and staphylococcus in blood samples at a faster rate than is possible using manual scanning. The scientists used 25,000 images of blood samples to teach the machines how to search for bacteria. The machines then learned how to identify and predict harmful bacteria in blood with 95 percent accuracy.\nLocation: Cambridge, Massachusetts\nIterative Health applies AI to gastroenterology to improve disease diagnosis and treatment. The company\u2019s AI recruitment service uses computational algorithms to automate the process of identifying patients who are eligible to be potential candidates for inflammatory bowel disease clinical trials. Iterative Health also produces SKOUT, a tool that uses AI to help doctors identify potentially cancerous polyps.\nLocation: Peoria, Illinois\nVirtuSense uses AI sensors to track a patient\u2019s movements so that providers and caregivers can be notified of potential falls. The company\u2019s products include VSTAlert, which can predict when a patient intends to stand up and notify appropriate medical staff, and VST Balance, which employs AI and machine vision to analyze a person\u2019s risk of falling within the next year.\nLocation: Fully Remote\nCleerly makes AI technology to improve cardiovascular care. The company\u2019s AI-enabled digital care platform measures and analyzes atherosclerosis, which is a buildup of plaque in the heart\u2019s arteries. The technology is able to determine an individual\u2019s risk of having a heart attack and recommend a personalized treatment plan.\nLocation: Bagsv\u00e6rd, Denmark\nNovo Nordisk is a pharmaceutical and biotech company collaborating with Valo Health to develop new treatments for cardiometabolic diseases. The partnership seeks to make discovery and development faster by using Valo\u2019s AI-powered computational platform, patient data and human tissue modeling technology.\nLocation: New Haven, Connecticut\nBioXcel Therapeutics uses AI to identify and develop new medicines in the fields of immuno-oncology and neuroscience. Additionally, the company\u2019s drug re-innovation program employs AI to find new applications for existing drugs or to identify new patients.\nLocation: Boston, Massachusetts\nValo uses artificial intelligence to achieve its mission of transforming the drug discovery and development process. With its Opal Computational Platform, Valo collects human-centric data to identify common diseases among a specific phenotype, genotype and other links, which eliminates the need for animal testing. The company then establishes the molecule design and clinical development.\nLocation: Cambridge, Massachusetts\nCombining AI, the cloud and quantum physics, XtalPi\u2019s ID4 platform predicts the chemical and pharmaceutical properties of small-molecule candidates for drug design and development. The company\u2019s investors have included Google, Tencent and Sequoia Capital.\nLocation: London, England\nThe primary goal of BenevolentAI is to get the right treatment to the right patients at the right time by using AI to produce a better target selection and provide previously undiscovered insights through deep learning. BenevolentAI works with major pharmaceutical groups to license drugs, while also partnering with charities to develop easily transportable medicines for rare diseases.\nLocation: Menlo Park, California\nDeepcell uses artificial intelligence and microfluidics to develop technology for single-cell morphology. The company\u2019s platform has a variety of applications, including cancer research, cell therapy and developmental biology.\nLocation: Austin, Texas\nWith the goal of improving patient care, Iodine Software is creating AI-powered and machine-learning solutions for mid-revenue cycle leakages, like resource optimization and increased response rates. The company\u2019s CognitiveML product discovers client insights, ensuriodes documentation accuracy and highlights missing information.\nLocation: New York, New York\nKaia Health operates a digital therapeutics platform that features live physical therapists to provide people care within the boundaries of their schedules. The platform includes personalized programs with case reviews, exercise routines, relaxation activities and learning resources for treating chronic back pain and COPD. Kaia Health also features a PT-grade automated feedback coach that uses AI technology.\nLocation: New York, New York\nSpring Health offers a mental health benefit solution employers can adapt to provide their employees with the resources to keep their mental health in check. The technology works by collecting a comprehensive dataset from each individual and comparing that against hundreds of thousands of other data points. The platform then uses a machine learning model to match people with the right specialist for either in-person care or telehealth appointments.\nLocation: Mountain View, California\nTwin Health\u2019s holistic method seeks to address and potentially reverse chronic conditions like Type 2 Diabetes through a mixture of IoT tech, AI, data science, medical science and healthcare. The company created the Whole Body Digital Twin \u2014 a digital representation of human metabolic function built around thousands of health data points, daily activities and personal preferences.\nLocation: Mountain View, California\nQventus is an AI-based software platform that solves operational challenges, including those related to emergency rooms and patient safety. The company\u2019s automated platform can prioritize patient illness and injury and tracks hospital waiting times to help hospitals and health systems optimize care delivery.\nLocation: Cleveland, Ohio\nThe Cleveland Clinic teamed up with IBM on the Discovery Accelerator, an AI-infused initiative focused on faster healthcare breakthroughs. The joint center is building an infrastructure that supports research in areas such as genomics, chemical and drug discovery and population health. The collaboration employs big data medical research for the purpose of innovating patient care and approaches to public health threats.\nLocation: Baltimore, Maryland\nJohns Hopkins Hospital partnered with GE Healthcare to use predictive AI techniques to improve the efficiency of patient operational flow. A task force, augmented with AI, quickly prioritized hospital activity to benefit patients. Since implementing the program, the facility has assigned patients admitted to the emergency department to beds 38 percent faster.\nLocation: New York, New York\nOne Drop provides a discreet solution for managing chronic conditions like diabetes and high blood pressure, as well as weight management. The One Drop Premium app allows people to manage their conditions head first, offering interactive coaching from real-world professionals, predictive glucose readings powered by AI and data science, learning resources and daily tracking of readings taken from One Drop\u2019s Bluetooth-enabled glucose reader and other devices.\nLocation: Menlo Park, California\nSubtle Medical uses AI to enhance images for radiology departments. The SubtlePET and SubtleMR products work with the machines a facility already uses to speed up MRI and PET scans while reducing image noise. The software has the potential to shrink wait times by scanning more patients each day.\nLocation: New York, New York\nTwill describes itself as \u201cThe Intelligent Healing Company,\u201d delivering digital healthcare products and partnering with enterprises, pharma companies and health plans to develop products using its Intelligent Healing Platform. The company uses AI to tailor personalized care tracks for managing medical conditions like multiple sclerosis and psoriasis. These individualized programs can include digital therapeutics, care communities and coaching options.\nLocation: San Francisco, California\nAugmedix offers a suite of AI-enabled medical documentation tools for hospitals, health systems, individual physicians and group practices. The company\u2019s products use natural language processing and automated speech recognition to save users time, increase productivity and improve patient satisfaction.\nLocation: Indianapolis, Indiana\nGreenlight Guru, a medical technology company, uses AI in its search engine to detect and assess security risks in network devices. The company specializes in developing medical software, and its search engine leverages machine learning to aggregate and process industry data. Meanwhile, its risk management platform provides auto-calculated risk assessments, among other services.\nLocation: Chicago, Illinois\nTempus uses AI to sift through the world\u2019s largest collection of clinical and molecular data to personalize healthcare treatments. The company develops AI tools that give physicians insights into treatments and cures, aiding in areas like radiology, cardiology, and neurology.\nLocation: Austin, Texas\nClosedLoop.ai is an end-to-end platform that uses AI to discover at-risk patients and recommend treatment options. Through the platform, healthcare organizations can receive personalized data about patients\u2019 needs while collecting looped feedback, outreach and engagement strategies and digital therapeutics. The platform can be used by healthcare providers, payers, pharma and life science companies.\nLocation: Boston, Massachusetts\nBeacon Biosignals aims to treat neurological and psychiatric diseases through its EEG analytics platform, which utilizes portal reporting, standardized neurobiomarkers and machine learning algorithms that \u201cincrease the probability of success at each stage of drug development.\u201d Additionally, population stratification is used to identify various patient populations.\nLocation: Philadelphia, Pennsylvania\nProscia is a digital pathology platform that uses AI to detect patterns in cancer cells. The company\u2019s software helps pathology labs eliminate bottlenecks in data management and uses AI-powered image analysis to connect data points that support cancer discovery and treatment.\nLocation: Mountain View, California\nH2O.ai\u2019s AI analyzes data throughout a healthcare system to mine, automate and predict processes. It has been used to predict ICU transfers, improve clinical workflows and pinpoint a patient\u2019s risk of hospital-acquired infections. Using the company\u2019s AI to mine health data, hospitals can predict and detect sepsis, which ultimately reduces death rates.\nLocation: South San Francisco, California\nAKASA\u2019s AI platform helps healthcare providers streamline workflows by automating administrative tasks to allow staff to focus where they\u2019re needed. The automation can be customized to meet a facility\u2019s particular needs and priorities, while maintaining accuracy for managing claims, payments and other elements of the revenue cycle.\nLocation: Waltham, Massachusetts\nVicarious Surgical combines virtual reality with AI-enabled robots so surgeons can perform minimally invasive operations. Using the company\u2019s technology, surgeons can virtually shrink and explore the inside of a patient\u2019s body in detail. Vicarious Surgical\u2019s technology concept prompted former Microsoft chief Bill Gates to invest in the company.\nLocation: Madison, Wisconsin\nThe Accuray CyberKnife system uses AI and robotics to precisely treat cancerous tumors. The technology lets providers personalize stereotactic radiosurgery and stereotactic body radiation therapy for each patient. Using the robot\u2019s real-time tumor tracking capabilities, doctors and surgeons can treat affected areas rather than the whole body.\nLocation: Sunnyvale, California\nThe first robotic surgery assistant approved by the FDA, Intuitive\u2019s da Vinci platforms feature cameras, robotic arms and surgical tools to aid in minimally invasive procedures. Da Vinci platforms constantly take in information and provide analytics to surgeons to improve future procedures. Da Vinci has assisted in over 10 million operations.\nLocation: Pittsburgh, Pennsylvania\nThe Robotics Institute at Carnegie Mellon University developed HeartLander, a miniature mobile robot designed to facilitate therapy on the heart. Under a physician\u2019s control, the tiny robot enters the chest through a small incision, navigates to certain locations of the heart by itself, adheres to the surface of the heart and administers therapy.\nLocation: Eindhoven, Netherlands\nMicrosure\u2019s robots help surgeons overcome their human physical limitations. The company\u2019s motion stabilizer system is intended to improve performance and precision during surgical procedures. Its MUSA surgical robot, developed by engineers and surgeons, can be controlled via joysticks for performing microsurgery.\nLocation: Boston, Massachusetts\nLaudio works to help frontline managers build high-performing teams. The company\u2019s technology leverages AI-powered recommendations to drive targeted managerial actions that help streamline workflows for frontline healthcare workers. Laudio\u2019s goal is to help frontline teams improve efficiency, employee engagement and patient experiences.\nLocation: Framingham, Massachusetts\nDefinitive Healthcare offers healthcare intelligence software that converts third-party data, secondary and proprietary research into actionable insights. It aims to deliver an organized, searchable and user-friendly platform. The company helps businesses in the healthcare space to market their products to their target audiences.\nLocation: New York, New York\nFormation Bio is a pharmaceutical company that uses AI to develop new and existing drugs. The company uses AI throughout development, manufacturing and marketing. It aims to accelerate drug development pipelines and get new products to patients more efficiently.\nLocation: Denver, Colorado\nStrive Health aims to transform kidney disease care through services and technology that prioritize early identification and responses that help lower overall costs. It provides its clients with local providers who use predictive and comparative data to design home-first dialysis options and comprehensive care plans. The Kidney Heroes\u2122, who include nurses, social workers, nurse practitioners, dietitians and care coordinators are trained to understand all intricacies of kidney disease and provide specialized care.\nLocation: Rosemont, Illinois\nIMO Health incorporates AI into its solutions for improving the quality of clinical data. The technology can be used to maintain accurate surgical dictionaries and ensure documentation aligns with regulatory requirements. IMO Health\u2019s offerings have uses for a variety of organizations, including health plans, healthcare providers and clinical research programs.\nArtera offers a patient communication platform using AI models and infrastructure. Its workflows are built to increase patient access, reduce staff response time and improve staff to patient ratios. The company\u2019s generative AI and classification models are meant to improve inbox management by moving the highest priority messages to the top.\nLocation: Boston, Massachusetts\nHealthcare providers use Arcadia\u2019s data platform to access insights that can help them improve operational efficiency and deliver proactive, informed patient care. Its technology comes with a generative AI assistant that unifies data from various sources to offer context and recommendations across areas like financial risk, compliance and care management.\nLocation: Santa Monica, California\nTigerConnect offers a platform designed to unify communications across healthcare operations, with the goal of enabling streamlined collaboration and improving the patient care experience. The technology comes with AI-powered features that providers can use to simplify daily tasks like scheduling.\nRelated Articles\nFrequently Asked Questions\nWhat is AI in healthcare?\nAI in healthcare is the use of machine learning, natural language processing, deep learning and other types of AI technology in the health field. These technologies are intended to improve health professionals\u2019 capabilities and performance while enhancing the patient experience.\nHow is AI used in healthcare?\nAI is used in healthcare to facilitate disease detection, automate documentation, store and organize health data and accelerate drug discovery and development, among other use cases.\nWhat companies are using AI in healthcare?\nSome healthcare companies using AI are EliseAI, Cohere Health, Pfizer, Butterfly Network and Novo Nordisk.\nWhat are the pros and cons of AI in healthcare?\nArtificial intelligence can offer many benefits to the healthcare industry, improving operational efficiency in clinics and hospitals and enabling more personalized treatment plans for patients. It is also good at analyzing large sets of data quickly, which can speed up the medical diagnostic process. AI systems are not infallible, though, and may produce errors or biased results, which can affect their trustworthiness. Plus, these systems pose some data privacy concerns, as they may lead to sensitive patient information being exposed or misused in some way.",
    "scraped_at":"2025-07-07T18:26:00.610262"
  },
  {
    "topic":"AI in healthcare",
    "title":"Artificial intelligence in healthcare: transforming the practice of ...",
    "url":"https:\/\/pmc.ncbi.nlm.nih.gov\/articles\/PMC8285156\/",
    "domain":"pmc.ncbi.nlm.nih.gov",
    "snippet":"ABSTRACT Artificial intelligence (AI) is a powerful and disruptive area of computer science, with the potential to fundamentally transform the practice of medicine and the delivery of healthcare. In this review article, we outline recent breakthroughs in the application of AI in healthcare, describe...",
    "content":"ABSTRACT\nArtificial intelligence (AI) is a powerful and disruptive area of computer science, with the potential to fundamentally transform the practice of medicine and the delivery of healthcare. In this review article, we outline recent breakthroughs in the application of AI in healthcare, describe a roadmap to building effective, reliable and safe AI systems, and discuss the possible future direction of AI augmented healthcare systems.\nKEYWORDS: AI, digital health\nIntroduction\nHealthcare systems around the world face significant challenges in achieving the \u2018quadruple aim\u2019 for healthcare: improve population health, improve the patient's experience of care, enhance caregiver experience and reduce the rising cost of care.1\u20133 Ageing populations, growing burden of chronic diseases and rising costs of healthcare globally are challenging governments, payers, regulators and providers to innovate and transform models of healthcare delivery. Moreover, against a backdrop now catalysed by the global pandemic, healthcare systems find themselves challenged to \u2018perform\u2019 (deliver effective, high-quality care) and \u2018transform\u2019 care at scale by leveraging real-world data driven insights directly into patient care. The pandemic has also highlighted the shortages in healthcare workforce and inequities in the access to care, previously articulated by The King's Fund and the World Health Organization (Box 1).4,5\nBox 1.\n| By 2030, the gap between supply of and demand for staff employed by NHS trusts could increase to almost 250,000 full-time equivalent posts.4 |\n| Based on the current trends and needs of the global population by 2030, the world will have 18 million fewer healthcare professionals (especially marked differences in the developing world), including 5 million fewer doctors than society will require.5 |\nThe application of technology and artificial intelligence (AI) in healthcare has the potential to address some of these supply-and-demand challenges. The increasing availability of multi-modal data (genomics, economic, demographic, clinical and phenotypic) coupled with technology innovations in mobile, internet of things (IoT), computing power and data security herald a moment of convergence between healthcare and technology to fundamentally transform models of healthcare delivery through AI-augmented healthcare systems.\nIn particular, cloud computing is enabling the transition of effective and safe AI systems into mainstream healthcare delivery. Cloud computing is providing the computing capacity for the analysis of considerably large amounts of data, at higher speeds and lower costs compared with historic \u2018on premises\u2019 infrastructure of healthcare organisations. Indeed, we observe that many technology providers are increasingly seeking to partner with healthcare organisations to drive AI-driven medical innovation enabled by cloud computing and technology-related transformation (Box 2).6\u20138\nBox 2.\n| Satya Nadella, chief executive officer, Microsoft: \u2018AI is perhaps the most transformational technology of our time, and healthcare is perhaps AI's most pressing application.\u20196 |\n| Tim Cook, chief executive officer, Apple: \u2018[Healthcare] is a business opportunity ... if you look at it, medical health activity is the largest or second-largest component of the economy.\u20197 |\n| Google Health: \u2018We think that AI is poised to transform medicine, delivering new, assistive technologies that will empower doctors to better serve their patients. Machine learning has dozens of possible application areas, but healthcare stands out as a remarkable opportunity to benefit people.\u20198 |\nHere, we summarise recent breakthroughs in the application of AI in healthcare, describe a roadmap to building effective AI systems and discuss the possible future direction of AI augmented healthcare systems.\nWhat is artificial intelligence?\nSimply put, AI refers to the science and engineering of making intelligent machines, through algorithms or a set of rules, which the machine follows to mimic human cognitive functions, such as learning and problem solving.9 AI systems have the potential to anticipate problems or deal with issues as they come up and, as such, operate in an intentional, intelligent and adaptive manner.10 AI's strength is in its ability to learn and recognise patterns and relationships from large multidimensional and multimodal datasets; for example, AI systems could translate a patient's entire medical record into a single number that represents a likely diagnosis.11,12 Moreover, AI systems are dynamic and autonomous, learning and adapting as more data become available.13\nAI is not one ubiquitous, universal technology, rather, it represents several subfields (such as machine learning and deep learning) that, individually or in combination, add intelligence to applications. Machine learning (ML) refers to the study of algorithms that allow computer programs to automatically improve through experience.14 ML itself may be categorised as \u2018supervised\u2019, \u2018unsupervised\u2019 and \u2018reinforcement learning\u2019 (RL), and there is ongoing research in various sub-fields including \u2018semi-supervised\u2019, \u2018self-supervised\u2019 and \u2018multi-instance\u2019 ML.\nSupervised learning leverages labelled data (annotated information); for example, using labelled X-ray images of known tumours to detect tumours in new images.15\n\u2018Unsupervised learning\u2019 attempts to extract information from data without labels; for example, categorising groups of patients with similar symptoms to identify a common cause.16\nIn RL, computational agents learn by trial and error, or by expert demonstration. The algorithm learns by developing a strategy to maximise rewards. Of note, major breakthroughs in AI in recent years have been based on RL.\nDeep learning (DL) is a class of algorithms that learns by using a large, many-layered collection of connected processes and exposing these processors to a vast set of examples. DL has emerged as the predominant method in AI today driving improvements in areas such as image and speech recognition.17,18\nHow to build effective and trusted AI-augmented healthcare systems?\nDespite more than a decade of significant focus, the use and adoption of AI in clinical practice remains limited, with many AI products for healthcare still at the design and develop stage.19\u201322 While there are different ways to build AI systems for healthcare, far too often there are attempts to force square pegs into round holes ie find healthcare problems to apply AI solutions to without due consideration to local context (such as clinical workflows, user needs, trust, safety and ethical implications).\nWe hold the view that AI amplifies and augments, rather than replaces, human intelligence. Hence, when building AI systems in healthcare, it is key to not replace the important elements of the human interaction in medicine but to focus it, and improve the efficiency and effectiveness of that interaction. Moreover, AI innovations in healthcare will come through an in-depth, human-centred understanding of the complexity of patient journeys and care pathways.\nIn Fig 1, we describe a problem-driven, human-centred approach, adapted from frameworks by Wiens et al, Care and Sendak to building effective and reliable AI-augmented healthcare systems.23\u201325\nDesign and develop\nThe first stage is to design and develop AI solutions for the right problems using a human-centred AI and experimentation approach and engaging appropriate stakeholders, especially the healthcare users themselves.\nStakeholder engagement and co-creation\nBuild a multidisciplinary team including computer and social scientists, operational and research leadership, and clinical stakeholders (physician, caregivers and patients) and subject experts (eg for biomedical scientists) that would include authorisers, motivators, financiers, conveners, connectors, implementers and champions.26 A multi-stakeholder team brings the technical, strategic, operational expertise to define problems, goals, success metrics and intermediate milestones.\nHuman-centred AI\nA human-centred AI approach combines an ethnographic understanding of health systems, with AI. Through user-designed research, first understand the key problems (we suggest using a qualitative study design to understand \u2018what is the problem\u2019, \u2018why is it a problem\u2019, \u2018to whom does it matter\u2019, \u2018why has it not been addressed before\u2019 and \u2018why is it not getting attention\u2019) including the needs, constraints and workflows in healthcare organisations, and the facilitators and barriers to the integration of AI within the clinical context. After defining key problems, the next step is to identify which problems are appropriate for AI to solve, whether there is availability of applicable datasets to build and later evaluate AI. By contextualising algorithms in an existing workflow, AI systems would operate within existing norms and practices to ensure adoption, providing appropriate solutions to existing problems for the end user.\nExperimentation\nThe focus should be on piloting of new stepwise experiments to build AI tools, using tight feedback loops from stakeholders to facilitate rapid experiential learning and incremental changes.27 The experiments would allow the trying out of new ideas simultaneously, exploring to see which one works, learn what works and what doesn't, and why.28 Experimentation and feedback will help to elucidate the purpose and intended uses for the AI system: the likely end users and the potential harm and ethical implications of AI system to them (for instance, data privacy, security, equity and safety).\nEvaluate and validate\nNext, we must iteratively evaluate and validate the predictions made by the AI tool to test how well it is functioning. This is critical, and evaluation is based on three dimensions: statistical validity, clinical utility and economic utility.\nStatistical validity is understanding the performance of AI on metrics of accuracy, reliability, robustness, stability and calibration. High model performance on retrospective, in silico settings is not sufficient to demonstrate clinical utility or impact.\nTo determine clinical utility, evaluate the algorithm in a real-time environment on a hold-out and temporal validation set (eg longitudinal and external geographic datasets) to demonstrate clinical effectiveness and generalisability.25\nEconomic utility quantifies the net benefit relative to the cost from the investment in the AI system.\nScale and diffuse\nMany AI systems are initially designed to solve a problem at one healthcare system based on the patient population specific to that location and context. Scale up of AI systems requires special attention to deployment modalities, model updates, the regulatory system, variation between systems and reimbursement environment.\nMonitor and maintain\nEven after an AI system has been deployed clinically, it must be continually monitored and maintained to monitor for risks and adverse events using effective post-market surveillance. Healthcare organisations, regulatory bodies and AI developers should cooperate to collate and analyse the relevant datasets for AI performance, clinical and safety-related risks, and adverse events.29\nWhat are the current and future use cases of AI in healthcare?\nAI can enable healthcare systems to achieve their \u2018quadruple aim\u2019 by democratising and standardising a future of connected and AI augmented care, precision diagnostics, precision therapeutics and, ultimately, precision medicine (Table 1).30 Research in the application of AI healthcare continues to accelerate rapidly, with potential use cases being demonstrated across the healthcare sector (both physical and mental health) including drug discovery, virtual clinical consultation, disease diagnosis, prognosis, medication management and health monitoring.\nTable 1.\n| Timeline | Connected\/augmented care | Precision diagnostics | Precision therapeutics | Precision Medicine | Summary |\n|---|---|---|---|---|---|\n| Short term: 0\u20135 years | Internet of things in healthcare Virtual assistants Augmented telehealth Personalised mental health support |\nPrecision imaging (eg diabetic retinopathy and radiotherapy planning) | CRISPR (increasing use) | Digital and AI enabled research hospitals30 | AI automates time consuming, high-volume repetitive tasks, especially within precision imaging |\n| Medium-term: 5\u201310 years | Ambient intelligence in healthcare | Large-scale adoption and scale-up of precision imaging | Synthetic biology Immunomics |\nCustomisation of healthcare Robotic assisted therapies |\nAI uses multi-modal datasets to drive precision therapeutics |\n| Long term: >10 years | Autonomous virtual health assistants, delivering predictive and anticipatory care Networked and connected care organisations (single digital infrastructure) |\nHolographic and hybrid imaging Holomics (integrated genomic\/radiomic\/proteomic\/clinical\/immunohistochemical data) |\nGenomics medicine AI driven drug discovery |\nNew curative treatments AI empowered healthcare professionals (eg digital twins) |\nAI enables healthcare systems to achieve a state of precision medicine through AI-augmented healthcare and connected care |\nTimings are illustrative to widescale adoption of the proposed innovation taking into account challenges \/ regulatory environment \/ use at scale.\nWe describe a non-exhaustive suite of AI applications in healthcare in the near term, medium term and longer term, for the potential capabilities of AI to augment, automate and transform medicine.\nAI today (and in the near future)\nCurrently, AI systems are not reasoning engines ie cannot reason the same way as human physicians, who can draw upon \u2018common sense\u2019 or \u2018clinical intuition and experience\u2019.12 Instead, AI resembles a signal translator, translating patterns from datasets. AI systems today are beginning to be adopted by healthcare organisations to automate time consuming, high volume repetitive tasks. Moreover, there is considerable progress in demonstrating the use of AI in precision diagnostics (eg diabetic retinopathy and radiotherapy planning).\nAI in the medium term (the next 5\u201310 years)\nIn the medium term, we propose that there will be significant progress in the development of powerful algorithms that are efficient (eg require less data to train), able to use unlabelled data, and can combine disparate structured and unstructured data including imaging, electronic health data, multi-omic, behavioural and pharmacological data. In addition, healthcare organisations and medical practices will evolve from being adopters of AI platforms, to becoming co-innovators with technology partners in the development of novel AI systems for precision therapeutics.\nAI in the long term (>10 years)\nIn the long term, AI systems will become more intelligent, enabling AI healthcare systems achieve a state of precision medicine through AI-augmented healthcare and connected care. Healthcare will shift from the traditional one-size-fits-all form of medicine to a preventative, personalised, data-driven disease management model that achieves improved patient outcomes (improved patient and clinical experiences of care) in a more cost-effective delivery system.\nConnected\/augmented care\nAI could significantly reduce inefficiency in healthcare, improve patient flow and experience, and enhance caregiver experience and patient safety through the care pathway; for example, AI could be applied to the remote monitoring of patients (eg intelligent telehealth through wearables\/sensors) to identify and provide timely care of patients at risk of deterioration.\nIn the long term, we expect that healthcare clinics, hospitals, social care services, patients and caregivers to be all connected to a single, interoperable digital infrastructure using passive sensors in combination with ambient intelligence.31 Following are two AI applications in connected care.\nVirtual assistants and AI chatbots\nAI chatbots (such as those used in Babylon (www.babylonhealth.com) and Ada (https:\/\/ada.com)) are being used by patients to identify symptoms and recommend further actions in community and primary care settings. AI chatbots can be integrated with wearable devices such as smartwatches to provide insights to both patients and caregivers in improving their behaviour, sleep and general wellness.\nAmbient and intelligent care\nWe also note the emergence of ambient sensing without the need for any peripherals.\nEmerald (www.emeraldinno.com): a wireless, touchless sensor and machine learning platform for remote monitoring of sleep, breathing and behaviour, founded by Massachusetts Institute of Technology faculty and researchers.\nGoogle nest: claiming to monitor sleep (including sleep disturbances like cough) using motion and sound sensors.32\nA recently published article exploring the ability to use smart speakers to contactlessly monitor heart rhythms.33\nAutomation and ambient clinical intelligence: AI systems leveraging natural language processing (NLP) technology have the potential to automate administrative tasks such as documenting patient visits in electronic health records, optimising clinical workflow and enabling clinicians to focus more time on caring for patients (eg Nuance Dragon Ambient eXperience (www.nuance.com\/healthcare\/ambient-clinical-intelligence.html)).\nPrecision diagnostics\nDiagnostic imaging\nThe automated classification of medical images is the leading AI application today. A recent review of AI\/ML-based medical devices approved in the USA and Europe from 2015\u20132020 found that more than half (129 (58%) devices in the USA and 126 (53%) devices in Europe) were approved or CE marked for radiological use.34 Studies have demonstrated AI's ability to meet or exceed the performance of human experts in image-based diagnoses from several medical specialties including pneumonia in radiology (a convolutional neural network trained with labelled frontal chest X-ray images outperformed radiologists in detecting pneumonia), dermatology (a convolutional neural network was trained with clinical images and was found to classify skin lesions accurately), pathology (one study trained AI algorithms with whole-slide pathology images to detect lymph node metastases of breast cancer and compared the results with those of pathologists) and cardiology (a deep learning algorithm diagnosed heart attack with a performance comparable with that of cardiologists).35\u201338\nWe recognise that there are some exemplars in this area in the NHS (eg University of Leeds Virtual Pathology Project and the National Pathology Imaging Co-operative) and expect widescale adoption and scaleup of AI-based diagnostic imaging in the medium term.39 We provide two use cases of such technologies.\nDiabetic retinopathy screening\nKey to reducing preventable, diabetes-related vision loss worldwide is screening individuals for detection and the prompt treatment of diabetic retinopathy. However, screening is costly given the substantial number of diabetes patients and limited manpower for eye care worldwide.40 Research studies on automated AI algorithms for diabetic retinopathy in the USA, Singapore, Thailand and India have demonstrated robust diagnostic performance and cost effectiveness.41\u201344 Moreover, Centers for Medicare & Medicaid Services approved Medicare reimbursement for the use of Food and Drug Administration approved AI algorithm \u2018IDx-DR\u2019, which demonstrated 87% sensitivity and 90% specificity for detecting more-than-mild diabetic retinopathy.45\nImproving the precision and reducing waiting timings for radiotherapy planning\nAn important AI application is to assist clinicians for image preparation and planning tasks for radiotherapy cancer treatment. Currently, segmentation of the images is time consuming and laborious task, performed manually by an oncologist using specially designed software to draw contours around the regions of interest. The AI-based InnerEye open-source technology can cut this preparation time for head and neck, and prostate cancer by up to 90%, meaning that waiting times for starting potentially life-saving radiotherapy treatment can be dramatically reduced (Fig 2).46,47\nPrecision therapeutics\nTo make progress towards precision therapeutics, we need to considerably improve our understanding of disease. Researchers globally are exploring the cellular and molecular basis of disease, collecting a range of multimodal datasets that can lead to digital and biological biomarkers for diagnosis, severity and progression. Two important future AI applications include immunomics \/ synthetic biology and drug discovery.\nImmunomics and synthetic biology\nThrough the application of AI tools on multimodal datasets in the future, we may be able to better understand the cellular basis of disease and the clustering of diseases and patient populations to provide more targeted preventive strategies, for example, using immunomics to diagnose and better predict care and treatment options. This will be revolutionary for multiple standards of care, with particular impact in the cancer, neurological and rare disease space, personalising the experience of care for the individual.\nAI-driven drug discovery\nAI will drive significant improvement in clinical trial design and optimisation of drug manufacturing processes, and, in general, any combinatorial optimisation process in healthcare could be replaced by AI. We have already seen the beginnings of this with the recent announcements by DeepMind and AlphaFold, which now sets the stage for better understanding disease processes, predicting protein structures and developing more targeted therapeutics (for both rare and more common diseases; Fig 3).48,49\nPrecision medicine\nNew curative therapies\nOver the past decade, synthetic biology has produced developments like CRISPR gene editing and some personalised cancer therapies. However, the life cycle for developing such advanced therapies is still extremely inefficient and expensive.\nIn future, with better access to data (genomic, proteomic, glycomic, metabolomic and bioinformatic), AI will allow us to handle far more systematic complexity and, in turn, help us transform the way we understand, discover and affect biology. This will improve the efficiency of the drug discovery process by helping better predict early which agents are more likely to be effective and also better anticipate adverse drug effects, which have often thwarted the further development of otherwise effective drugs at a costly late stage in the development process. This, in turn will democratise access to novel advanced therapies at a lower cost.\nAI empowered healthcare professionals\nIn the longer term, healthcare professionals will leverage AI in augmenting the care they provide, allowing them to provide safer, standardised and more effective care at the top of their licence; for example, clinicians could use an \u2018AI digital consult\u2019 to examine \u2018digital twin\u2019 models of their patients (a truly \u2018digital and biomedical\u2019 version of a patient), allowing them to \u2018test\u2019 the effectiveness, safety and experience of an intervention (such as a cancer drug) in the digital environment prior to delivering the intervention to the patient in the real world.\nChallenges\nWe recognise that there are significant challenges related to the wider adoption and deployment of AI into healthcare systems. These challenges include, but are not limited to, data quality and access, technical infrastructure, organisational capacity, and ethical and responsible practices in addition to aspects related to safety and regulation. Some of these issues have been covered, but others go beyond the scope of this current article.\nConclusion and key recommendations\nAdvances in AI have the potential to transform many aspects of healthcare, enabling a future that is more personalised, precise, predictive and portable. It is unclear if we will see an incremental adoption of new technologies or radical adoption of these technological innovations, but the impact of such technologies and the digital renaissance they bring requires health systems to consider how best they will adapt to the changing landscape. For the NHS, the application of such technologies truly has the potential to release time for care back to healthcare professionals, enabling them to focus on what matters to their patients and, in the future, leveraging a globally democratised set of data assets comprising the \u2018highest levels of human knowledge\u2019 to \u2018work at the limits of science\u2019 to deliver a common high standard of care, wherever and whenever it is delivered, and by whoever.50 Globally, AI could become a key tool for improving health equity around the world.\nAs much as the last 10 years have been about the roll out of digitisation of health records for the purposes of efficiency (and in some healthcare systems, billing\/reimbursement), the next 10 years will be about the insight and value society can gain from these digital assets, and how these can be translated into driving better clinical outcomes with the assistance of AI, and the subsequent creation of novel data assets and tools. It is clear that we are at an turning point as it relates to the convergence of the practice of medicine and the application of technology, and although there are multiple opportunities, there are formidable challenges that need to be overcome as it relates to the real world and the scale of implementation of such innovation. A key to delivering this vision will be an expansion of translational research in the field of healthcare applications of artificial intelligence. Alongside this, we need investment into the upskilling of a healthcare workforce and future leaders that are digitally enabled, and to understand and embrace, rather than being intimidated by, the potential of an AI-augmented healthcare system.\nHealthcare leaders should consider (as a minimum) these issues when planning to leverage AI for health:\nprocesses for ethical and responsible access to data: healthcare data is highly sensitive, inconsistent, siloed and not optimised for the purposes of machine learning development, evaluation, implementation and adoption\naccess to domain expertise \/ prior knowledge to make sense and create some of the rules which need to be applied to the datasets (to generate the necessary insight)\naccess to sufficient computing power to generate decisions in real time, which is being transformed exponentially with the advent of cloud computing\nresearch into implementation: critically, we must consider, explore and research issues which arise when you take the algorithm and put it in the real world, building \u2018trusted\u2019 AI algorithms embedded into appropriate workflows.\nReferences\n- 1.Berwick DM, Nolan TW, Whittington J. The Triple Aim: Care, health, and cost. Health Affairs 2008;27:759\u201369. [DOI] [PubMed] [Google Scholar]\n- 2.Bodenheimer T, Sinsky C. From triple to quadruple aim: care of the patient requires care of the provider. Ann Fam Med 2014;12:573\u20136. [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 3.Feeley D. The Triple Aim or the Quadruple Aim? Four Points to Help Set Your Strategy. Institute for Healthcare Improvement, 2017. www.ihi.org\/communities\/blogs\/the-triple-aim-or-the-quadruple-aim-four-points-to-help-set-your-strategy. [Google Scholar]\n- 4.The Health Foundation, Nuffield Trust, The King's Fund . The health care workforce in England: make or break? The King's Fund, 2018. [Google Scholar]\n- 5.World Health Organization. Working for health and growth: Investing in the health workforce. WHO, 2016. http:\/\/apps.who.int\/iris\/bitstream\/10665\/250047\/1\/9789241511308-eng.pdf [Accessed 31 January 2020]. [Google Scholar]\n- 6.Satya Nadella announces strategic collaboration with Novartis. You Tube, 2019. www.youtube.com\/watch?v=wMfsQE-D2q4\n- 7.Lashinsky A. Tim Cook on how Apple champions the environment, education, and health care. Fortune, 2017. [Google Scholar]\n- 8.Turea M. How the \u2018Big 4\u2019 tech companies are leading healthcare innovation. Healthcare Weekly, 2019. [Google Scholar]\n- 9.McCarthy J. What is artificial intelligence? John McCarthy, 1998. [Google Scholar]\n- 10.Shukla SS, Jaiswal V. Applicability of artificial intelligence in different fields of life. IJSER 2013;1:28\u201335. [Google Scholar]\n- 11.Deng J, Dong W, Socher R, et al. Imagenet: a large-scale hierarchical image database. 2009 IEEE Conference on Computer Vision and Pattern Recognition 2009:248\u201355. [Google Scholar]\n- 12.Quinn TP, Senadeera M, Jacobs S, Coghlan S, Le V. Trust and medical AI: the challenges we face and the expertise needed to overcome them. J Am Med Inform Assoc 2021;28:890\u20134. [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 13.Binns R, Gallo V. Trade-offs. Information Commissioner's Office, 2019. https:\/\/ico.org.uk\/about-the-ico\/news-and-events\/ai-blog-trade-offs\n- 14.Mitchell T. Machine learning. McGraw Hill, 1997. www.cs.cmu.edu\/afs\/cs.cmu.edu\/user\/mitchell\/ftp\/mlbook.html [Google Scholar]\n- 15.Reardon S. Rise of robot radiologists. Nature 2019;576:S54\u20138. [DOI] [PubMed] [Google Scholar]\n- 16.Lasko TA, Denny JC, Levy MA. Computational phenotype discovery using unsupervised feature learning over noisy, sparse, and irregular clinical data. PLoS One 2013;8:e66341. [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 17.The Royal Society . Machine learning: the power and promise of computers that learn by example. The Royal Society, 2017. [Google Scholar]\n- 18.LeCun Y, Bengio Y, Hinton G. Deep learning. Nature 2015;521:436\u201344. [DOI] [PubMed] [Google Scholar]\n- 19.Topol EJ. High-performance medicine: the convergence of human and artificial intelligence. Nat Med 2019;25:44\u201356. [DOI] [PubMed] [Google Scholar]\n- 20.Kelly CJ, Karthikesalingam A, Suleyman M, Corrado G, King D. Key challenges for delivering clinical impact with artificial intelligence. BMC Medicine 2019;17:195. [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 21.Panch T, Mattie H, Celi LA. The \u2018inconvenient truth\u2019 about AI in healthcare. NPJ Digit Med 2019;2:77. [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 22.NHSX . Artificial intelligence: How to get it right. NHS, 2019. [Google Scholar]\n- 23.Wiens J, Saria S, Sendak M, et al. Do no harm: a roadmap for responsible machine learning for health care. Nat Med 2019;25:1337\u201340. [DOI] [PubMed] [Google Scholar]\n- 24.United States Government Accountability Office . Artificial intelligence in health care: Benefits and challenges of technologies to augment patient care. GAO, 2020. [Google Scholar]\n- 25.Sendak MP, D'Arcy J, Kashyap S, et al. A path for translation of machine learning products into healthcare delivery. EMJ Innov 2020;10:19\u201300172. [Google Scholar]\n- 26.Andrews M, McConnell J, Wescott A. Development as leadership-led change: working paper series RWP10-009. Harvard University, 2010. [Google Scholar]\n- 27.Andrews M, Pritchett L, Woolcock M. Escaping capability traps through problem-driven iterative adaptation (PDIA): WIDER working paper 2012\/064. UNU-WIDER, 2012. [Google Scholar]\n- 28.Andrews M. Who really leads development? WIDER working paper 2013\/092. UNU-WIDER, 2013. [Google Scholar]\n- 29.Davahli MR, Karwowski W, Fiok K, Wan T, Parsaei HR. Controlling safety of artificial intelligence-based systems in healthcare. Symmetry 2021;13:102. [Google Scholar]\n- 30.Nachev P, Herron D, McNally N, Rees G, Williams B. Redefining the research hospital. NPJ Digit Med 2019;2:119. [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 31.Haque A, Milstein A, Fei-Fei L. Illuminating the dark spaces of healthcare with ambient intelligence. Nature 2020;585:193\u2013202. [DOI] [PubMed] [Google Scholar]\n- 32.Muoio D. Google's next-gen Nest Hub debuts with contactless sleep monitoring and analysis features. Mobi Health News, 2021. www.mobihealthnews.com\/news\/googles-next-gen-nest-hub-debuts-contactless-sleep-monitoring-and-analysis-features [Google Scholar]\n- 33.Wang A, Nguyen D, Sridhar AR, et al. Using smart speakers to contactlessly monitor heart rhythms. Commun Biol 2021;4:319. [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 34.Muehlematter UJ, Daniore P, Vokinger KN. Approval of artificial intelligence and machine learning-based medical devices in the USA and Europe (2015\u201320): a comparative analysis. Lancet Digital Health 2021;3:e195\u2013203. [DOI] [PubMed] [Google Scholar]\n- 35.Wang X, Peng Y, Lu L, et al. Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases. IEEE CVPR 2017:2097\u2013106. [Google Scholar]\n- 36.Esteva A, Robicquet A, Ramsundar B, et al. A guide to deep learning in healthcare. Nat Med 2019;25:24\u20139. [DOI] [PubMed] [Google Scholar]\n- 37.Bejnordi BE, Veta M, Van Diest PJ, et al. Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer. JAMA 2017;318:2199\u2013210. [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 38.Strodthoff N, Strodthoff C. Detecting and interpreting myocardial infarction using fully convolutional neural networks. Physiological Measurement 2019;40:015001. [DOI] [PubMed] [Google Scholar]\n- 39.University of Leeds . NPIC - Northern Pathology Imaging Co-operative. University of Leeds, 2020. www.virtualpathology.leeds.ac.uk\/npic [Google Scholar]\n- 40.Bellemo V, Lim ZW, Lim G, et al. Artificial intelligence using deep learning to screen for referable and vision-threatening diabetic retinopathy in Africa: a clinical validation study. Lancet Digit Health 2019;1:e35\u201344. [DOI] [PubMed] [Google Scholar]\n- 41.Gulshan V, Peng L, Coram M, et al. Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs. JAMA 2016;316:2402\u201310. [DOI] [PubMed] [Google Scholar]\n- 42.Ting DSW, Pasquale LR, Peng L, et al. Artificial intelligence and deep learning in ophthalmology. Br J Ophthalmol 2019;103:167\u201375. [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 43.Raumviboonsuk P, Krause J, Chotcomwongse P, et al. Deep learning versus human graders for classifying diabetic retinopathy severity in a nationwide screening program. NPJ Digit Med 2019;2:25. [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 44.Xie Y, Nguyen QD, Hamzah H, et al. Artificial intelligence for teleophthalmology-based diabetic retinopathy screening in a national programme: an economic analysis modelling study. Lancet Digit Health 2020;2:e240\u20139. [DOI] [PubMed] [Google Scholar]\n- 45.Simonite T. The US government will pay doctors to use these AI algorithms. Wired, 2020. www.wired.com\/story\/us-government-pay-doctors-use-ai-algorithms [Google Scholar]\n- 46.Oktay O, Nanavati J, Schwaighofer A, et al. Evaluation of deep learning to augment image-guided radiotherapy for head and neck and prostate cancers. JAMA Netw Open 2020;3:e2027426. [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 47.Alverez-Valle J, Moore GJ. Project InnerEye open-source deep learning toolkit: Democratizing medical imaging AI. Microsoft, 2020. www.microsoft.com\/en-us\/research\/blog\/project-innereye-open-source-deep-learning-toolkit-democratizing-medical-imaging-ai [Google Scholar]\n- 48.Senior AW, Evans R, Jumper J, et al. Improved protein structure prediction using potentials from deep learning. Nature 2020;577:706\u201310. [DOI] [PubMed] [Google Scholar]\n- 49.The AlphaFold team . AlphaFold: a solution to a 50-year-old grand challenge in biology. DeepMind, 2020. https:\/\/deepmind.com\/blog\/article\/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology [Google Scholar]\n- 50.Department of Health and Social Care. NHS Constitution or England. DHSC, 2012. www.gov.uk\/government\/publications\/the-nhs-constitution-for-england [Google Scholar]",
    "scraped_at":"2025-07-07T18:26:00.912168"
  },
  {
    "topic":"AI in healthcare",
    "title":"Benefits and Risks of AI in Health Care: Narrative Review - PMC",
    "url":"https:\/\/pmc.ncbi.nlm.nih.gov\/articles\/PMC11612599\/",
    "domain":"pmc.ncbi.nlm.nih.gov",
    "snippet":"Abstract Background The integration of artificial intelligence (AI) into health care has the potential to transform the industry, but it also raises ethical, regulatory, and safety concerns. This review paper provides an in-depth examination of the benefits and risks associated with AI in health car...",
    "content":"Abstract\nBackground\nThe integration of artificial intelligence (AI) into health care has the potential to transform the industry, but it also raises ethical, regulatory, and safety concerns. This review paper provides an in-depth examination of the benefits and risks associated with AI in health care, with a focus on issues like biases, transparency, data privacy, and safety.\nObjective\nThis study aims to evaluate the advantages and drawbacks of incorporating AI in health care. This assessment centers on the potential biases in AI algorithms, transparency challenges, data privacy issues, and safety risks in health care settings.\nMethods\nStudies included in this review were selected based on their relevance to AI applications in health care, focusing on ethical, regulatory, and safety considerations. Inclusion criteria encompassed peer-reviewed articles, reviews, and relevant research papers published in English. Exclusion criteria included non\u2013peer-reviewed articles, editorials, and studies not directly related to AI in health care. A comprehensive literature search was conducted across 8 databases: OVID MEDLINE, OVID Embase, OVID PsycINFO, EBSCO CINAHL Plus with Full Text, ProQuest Sociological Abstracts, ProQuest Philosopher\u2019s Index, ProQuest Advanced Technologies & Aerospace, and Wiley Cochrane Library. The search was last updated on June 23, 2023. Results were synthesized using qualitative methods to identify key themes and findings related to the benefits and risks of AI in health care.\nResults\nThe literature search yielded 8796 articles. After removing duplicates and applying the inclusion and exclusion criteria, 44 studies were included in the qualitative synthesis. This review highlights the significant promise that AI holds in health care, such as enhancing health care delivery by providing more accurate diagnoses, personalized treatment plans, and efficient resource allocation. However, persistent concerns remain, including biases ingrained in AI algorithms, a lack of transparency in decision-making, potential compromises of patient data privacy, and safety risks associated with AI implementation in clinical settings.\nConclusions\nIn conclusion, while AI presents the opportunity for a health care revolution, it is imperative to address the ethical, regulatory, and safety challenges linked to its integration. Proactive measures are required to ensure that AI technologies are developed and deployed responsibly, striking a balance between innovation and the safeguarding of patient well-being.\nKeywords: artificial intelligence, safety risks, biases, AI, benefit, risk, health care, safety, ethics, transparency, data privacy, accuracy\nIntroduction\nArtificial intelligence (AI) has rapidly proliferated across various sectors in recent years, with the health care industry emerging as a primary arena for its transformative potential. This technological advancement holds promise for revolutionizing patient care and administrative operations by leveraging vast longitudinal patient data [1]. AI encompasses a spectrum of technologies, including machine learning (ML), natural language processing (NLP), rule-based expert systems (RBES), physical robots, and robotic process automation, each offering unique capabilities from predictive modeling and disease detection to enhancing surgical precision and automating administrative tasks [2-7]. The integration of AI into health care promises heightened diagnostic accuracy, informed decision-making, and optimized treatment planning, thereby potentially reducing medical errors and improving patient outcomes [1].\nHowever, alongside these promising developments, AI adoption in health care is accompanied by significant ethical and regulatory challenges that require careful consideration [8]. Concerns range from safeguarding patient data privacy to addressing algorithmic biases that may perpetuate disparities in health care outcomes [9,10]. The regulatory landscape is evolving to keep pace with technological advancements, aiming to establish robust governance frameworks that ensure the responsible use of AI in health care settings. Furthermore, the advent of pretrained large language models, exemplified by models like BERT (Bidirectional Encoder Representations from Transformers), GPT (Generative Pre-trained Transformer), and their variants, has further expanded the capabilities of AI in health care [11-14]. These models leverage vast amounts of text data to learn rich representations of language, enabling tasks ranging from clinical documentation improvement to automated summarization of medical literature [15,16].\nAgainst this backdrop, this study presents a narrative review aimed at comprehensively exploring the multifaceted role of AI in health care. By synthesizing existing literature, this research aims to provide insights into the diverse applications of AI, its associated benefits, and the ethical and regulatory considerations that underpin its integration into clinical practice [9,10,17]. This review aims to facilitate informed decision-making among health care professionals, policy makers, and researchers, fostering a balanced approach that maximizes the benefits of AI while mitigating potential risks within the health care landscape.\nThis review seeks to contribute to ongoing discussions on AI ethics, governance, and effective deployment strategies, thereby guiding the responsible and impactful adoption of AI technologies in health care. By examining current trends, challenges, and future directions, this review aims to lay the groundwork for advancing AI\u2019s role in enhancing health care delivery, improving patient outcomes, and supporting health care systems globally.\nMethods\nOverview\nThis narrative review aims to assess the benefits and risks associated with the integration of AI into health care, with a primary focus on potential biases, transparency issues, data privacy concerns, and safety risks. A literature review was conducted to explore the current landscape of AI applications in health care and to identify relevant ethical, regulatory, and safety considerations.\nEligibility Criteria\nSpecific inclusion and exclusion criteria were established to guide the selection of studies for this narrative review. Studies were included if they were relevant to the 3 core concepts of AI, ethics, and health and were written in the English language. Articles were excluded if they did not explicitly address each of the core concepts of AI, ethics, and health or if they were not written in English. In addition, studies focusing solely on ethics and big data without explicit mention of AI methods or applications were excluded. Non\u2013peer-reviewed academic literature, such as letters and non\u2013peer-reviewed conference proceedings, as well as books and book chapters, were also excluded as they were deemed irrelevant to this review. No restrictions were applied regarding the publication date or study design to ensure a broad overview of the topic.\nInformation Sources\nThe literature search used 8 electronic databases: OVID MEDLINE (1946-present), OVID Embase (1947-present), OVID PsycINFO (1806-present), EBSCO CINAHL Plus with Full Text (1937-present), ProQuest Sociological Abstracts (1952-present), ProQuest Philosopher\u2019s Index (1940-present), ProQuest Advanced Technologies & Aerospace (1962-present), and Wiley Cochrane Library. Search strategies were tailored to each database (Multimedia Appendix 1), using controlled vocabulary, Medical Subject Headings (MeSH) terms, EMTREE terms, American Psychological Association\u2019s Thesaurus of Psychological Index Terms, CINAHL headings, Sociological Thesaurus, Philosopher\u2019s Index subject headings, and Advanced Technologies & Aerospace subject headings. The searches were limited to English language\u2013only articles, and filters excluding animal studies were applied to specific databases. In addition, a filter for health or medicine-related studies was applied to the Advanced Technologies & Aerospace database.\nThe final searches of the peer-reviewed literature were completed on June 23, 2023. Gray literature was not searched in this narrative review.\nSelection and Sources of Evidence\nAll identified records from the academic literature searches were imported into the reference management software EndNote (Clarivate). After removing duplicate records, screening was conducted in 2 steps: initial title and abstract screening followed by full-text review. Full-text reviews were conducted to ensure that the selected studies provided substantial insights for the narrative synthesis.\nData Charting Process\nData charting forms were developed and refined based on the narrative review research question. The forms included fields for recording data such as the objective of each paper, institutional affiliations of authors, publication year, country of the first and corresponding authors, conflict of interest disclosures, health context of interest, AI applications or technologies discussed, ethical concepts, issues or implications raised, reference to global health, and recommendations for future research, policy, or practice. Data were recorded directly into the data charting form with corresponding page numbers to ensure accuracy.\nSynthesis of Results\nData analysis included thematic components. Thematic analysis was conducted inductively, generating open descriptive codes from a sample of records. Codes were applied to relevant data points across all records, with new codes added as needed. These codes were then organized into themes, allowing for the identification of commonalities and gaps in the literature. Results are presented in a narrative format.\nResults\nOverview\nWithin the realm of integrating AI into health care, this narrative review has revealed a broad range of insights that span a spectrum of possibilities and challenges. This section categorizes the findings into 2 overarching categories: \u201cBenefits\u201d and \u201cRisks.\u201d Each category encapsulates a tapestry of themes that emerged from an exploration of academic literature. As these themes are explored, the multifaceted landscape of AI\u2019s influence on health care is illuminated. The \u201cBenefits\u201d section unveils the potential for AI to revolutionize health care delivery, ushering in more accurate diagnoses, personalized treatment regimens, and streamlined resource allocation. Conversely, the \u201cRisks\u201d section delves into the intricate ethical, privacy, and safety concerns that accompany the integration of AI into clinical settings. Through a comprehensive examination of these themes, this review provides a nuanced perspective on the implications and imperatives in harnessing AI\u2019s potential for the betterment of health care.\nThe systematic literature review process, as illustrated in the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) flow diagram (Figure 1), outlines a thorough and rigorous methodology. Initial searches across multiple databases\u2014MEDLINE, Embase, PsycINFO, ProQuest Sociological Abstracts, CINAHL, ProQuest Philosopher\u2019s Index, ProQuest Advanced Technologies & Aerospace, and Cochrane Library\u2014yielded a total of 8796 articles. After removing 4798 duplicates using Endnote, 3738 unique records were screened for relevance. Of these, 3155 articles were excluded based on title and abstract review for not meeting the inclusion criteria. The remaining 583 articles underwent full-text assessment for eligibility. Further evaluation led to the exclusion of 539 articles due to various reasons, such as unavailability of full text (n=171), irrelevance to the primary outcome (n=290), non-English language (n=22), not being peer-reviewed (n=29), and not being original research (n=27). Ultimately, 44 studies were included in the qualitative synthesis and data extraction. This meticulous selection process ensured that the final set of studies provided a robust and representative foundation for examining the integration of AI in health care.\nBenefits of AI in Health Care\nTextbox 1 below describes the main benefits of implementing AI in health care. The benefits are explained in detail below.\nBenefits of artificial intelligence (AI) in health care.\nMedical benefits\nHelps in prediction of various risks and diseases\nHelps in prevention and control of various diseases\nLeads to better data-driven decisions within the health care system\nAssists in improving surgery\nSupports mental health\nEconomic and social benefits\nReduction in posttreatment expenditures\nCost saving through early diagnosis\nCost saving with enhanced clinical trials\nPatient empowerment\nRelieving medical practitioners\u2019 workload\nMedical Benefits\nAI adoption in health care offers various medical, economic, and social benefits. This section discusses some of the key medical benefits of AI.\nPrediction of Risks and Diseases\nAI leverages big data to predict diseases and assess risk exposure among patients. For example, Google collaborates with health delivery networks to develop prediction models that alert clinicians of high-risk illnesses like sepsis and heart failure [18]. ML models can also be used to forecast populations at risk of specific diseases or accidents [19,20]. In addition, AI algorithms, such as deep learning, aid in disease classification and enable more personalized care [21].\nPrevention and Control of Diseases\nAI can play a significant role in the prevention and control of diseases. For instance, AI can enhance sexually transmitted infection (STI) prevention and control by improving surveillance and intervention. By analyzing publicly available social media data, AI can predict county-level syphilis prevalence, enabling faster and more efficient monitoring [22]. AI can also analyze trends in web data to reduce the stigma associated with STI prevention and care and identify and flag STI-related misinformation [22].\nData-Driven Decision Making\nAI enables better data-driven decisions within the health care system. In a digitalized health care environment, the quality of decision-making relies on the availability and accuracy of underlying data [23]. AI can assist in decision-making by offering real-time recommendations based on clinical guidelines or advancements, reducing the likelihood of medical mistakes [24]. For example, IBM Watson Health uses ML to provide clinical decision support and achieved a high level of agreement with physician recommendations [25].\nImprovement in Surgery\nAI has made significant advancements in surgical procedures. Robotic surgery, such as in gynecologic, prostate, and oral and maxillofacial surgery, enhances surgical precision and predictability [7,26]. Telesurgical techniques driven by AI enable remote surgery and provide better supervision of surgeons [27]. AI-powered surgical mentorship allows skilled surgeons to offer real-time advice and guidance to other surgeons during procedures, improving surgical outcomes [28].\nMental Health Support.\nAI use in mental health treatments is growing as patients prefer simple and quick feedback [29]. According to Lovejoy et al [30], psychiatric professionals have historically relied on therapeutic discourse and patient narrative to assess mental health since language is the primary means to communicate our emotional and mental well-being. Recent advancements in AI have opened up new perspectives on the subject by enabling technology to infer emotional meaning from more data sources [30]. According to Habermann [31], with a unique combination of NLP and sentiment analysis, data scientists have developed algorithms to comprehend human emotion from the text. Le Glaz et al [32] mentions that in recent years, NLP models have been used to track mental self-disclosure on Twitter, forecast suicide risk online, and identify suicidal thoughts in clinical notes. These models are used in medicine to give complete details about a patient\u2019s emotional and psychological health [31].\nEconomic and Social Benefits\nIn addition to the medical health benefits, using AI in health care has other economic and social advantages, as discussed below.\nReduction in Posttreatment Expenditures.\nAI-powered systems can analyze posttreatment result patterns and identify the most effective remedies based on patient profiles. This personalized approach to care can significantly reduce the expenses associated with posttreatment complications, which are a major cost driver in health care systems worldwide [33]. By providing immediate diagnosis and appropriate interventions, AI can help minimize the financial burden of posttreatment complications and lead to substantial cost savings.\nCost Saving Through Early Diagnosis.\nAI has demonstrated superior accuracy and speed in analyzing medical images, such as mammograms, leading to the early detection of diseases like breast cancer. By enabling prompt diagnosis and action before issues escalate, AI can help reduce health care costs associated with late-stage diagnoses [28]. In addition, AI\u2019s ability to process and interpret various medical tests, such as computed tomography scans, with high accuracy reduces the likelihood of physician errors, contributing to cost savings.\nCost Saving with Enhanced Clinical Trials.\nAI-powered programs can simulate and evaluate numerous potential treatments to predict their effectiveness against various diseases, optimizing the drug development process in clinical trials [34]. By leveraging biomarker monitoring frameworks and analyzing large volumes of patient data, AI accelerates the evaluation of potential treatments, leading to significant cost savings in the development of life-saving medications.\nPatient Empowerment.\nAI has the potential to empower individuals in managing their health. Wearable devices, such as smartwatches, can collect standard health data, which AI algorithms can analyze to provide personalized health recommendations and warnings for potential diseases [35]. Smartphone apps that use ML algorithms can help patients with chronic diseases better manage their conditions, leading to healthier populations and reduced health care expenses [36].\nRelieving Medical Practitioners\u2019 Workload.\nAI technologies can alleviate the burden on health care workers by assisting with administrative tasks, data analysis, and image interpretation. AI can automate clerical responsibilities, analyze patient data more efficiently, and aid in diagnosing various medical conditions [37,38]. By reducing manual labor and prioritizing critical cases, AI helps save time and resources for medical practitioners, ultimately leading to increased productivity and improved patient care.\nRisks of AI in Health Care\nThe risks of AI in health care are listed in Textbox 2.\nRisks of artificial intelligence (AI) in health care.\nRisks of AI in health care\nAI diagnosis is not always superior to human diagnosis\nAI programs may be difficult to understand and overly ambitious\nImplementation issues\nTransparency issues and risks with data sharing\nBiases\nMistakes in disease diagnosis or AI cannot be held accountable\nData availability and accessibility\nRegulatory concerns\nSocial challenges\nAI Diagnosis Is Not Always Superior to Human Diagnosis.\nWhile AI has the potential to improve accurate diagnosis, it is not always superior to human diagnosis. Early AI systems, such as the MYCIN program developed in the 1970s, showed promise in diagnosing and treating diseases but did not outperform human diagnosticians [39]. These RBES needed better integration with clinical workflows and medical record systems to be practical and effective. In addition, AI models can suffer from overfitting, generating irrelevant correlations between patient characteristics and outcomes, which can lead to incorrect predictions when applied to new cases [40].\nChallenges in Understanding and Ambition of AI Programs\nPhysicians may find it challenging to understand AI programs, particularly in complex domains like cancer diagnosis and treatment. IBM\u2019s Watson program, which combines ML and NLP, garnered attention for its focus on precision medicine. However, integrating Watson into care processes and systems and programming it to handle certain types of cancer has proven difficult [41]. The ambition of AI programs, such as tackling complex cancer therapy, may exceed their current capabilities.\nImplementation Issues\nImplementing AI in health care faces several challenges. RBES embedded in electronic health care systems are commonly used but may lack the accuracy of algorithmic systems based on ML. These RBES struggle to keep up with evolving medical knowledge and handle large amounts of data [42]. The lack of empirical evidence confirming the efficacy of AI-based treatments in prospective clinical trials hinders successful implementation [43]. Much of the AI research in health care is preclinical and lacks real-world validation [44]. Integration into physician workflow is crucial for successful implementation, but there are limited examples of AI integration into clinical treatment, and training physicians to use AI effectively can be a time-consuming process [45].\nTransparency Issues and Risks With Data Sharing\nThe use of intelligent machines in health care decision-making raises concerns about accountability, transparency, permission, and privacy [2]. Understanding and interpreting AI systems, such as deep learning algorithms used in image analysis, can be challenging [2]. Physicians who lack comprehension of the inner workings of AI models may struggle to communicate the medical treatment process to patients [46]. Increased reliance on AI may lead to automated decision-making, limiting the contact and communication between health care workers and patients [46].\nThe rapid emergence of new technologies in health care has sparked skepticism due to the risks associated with data sharing [17]. There is a need for public norms that ensure data governance and openness, as well as improve patient understanding of how and why data are used [17]. Concerns about privacy violations arise from the collection of large data sets and the potential for AI to anticipate personal information [47]. Patients may perceive this as a violation of their privacy, especially if the findings are made public to third parties [48].\nRespecting patient confidentiality and acquiring informed consent for data use are ethically required [49]. AI systems should be protected from privacy breaches to prevent psychological and reputational harm to patients [49]. Recent incidents, such as the misuse of Facebook personal data by Cambridge Analytica and the sharing of patient data without explicit consent by the Royal Free London NHS Foundation Trust, have raised concerns about privacy violations [49,50].\nBiases\nML systems in health care can be prone to algorithmic bias, leading to predictions based on noncausal factors like gender or ethnicity [51]. Prejudice and inequality are among the risks associated with health care AI [28]. Biases present in the data used to train AI systems can result in inaccurate outcomes, especially if certain races or genders are underrepresented [28]. Unrepresentative data can further perpetuate health inequities and lead to risk underestimation or overestimation in specific patient populations [52].\nMistakes in Disease Diagnosis and Lack of Accountability\nAI systems can make mistakes in patient diagnosis and treatment, creating potential harm [28]. Holding AI systems accountable can be challenging, as liability concerns arise regarding errors and the allocation of responsibility [53]. The lack of explanation from deep learning algorithms can hinder both legal accountability and scientific understanding, potentially eroding patients\u2019 trust in the system [54].\nDetermining accountability for AI failures is an ongoing challenge, as holding the physician accountable may seem unjust, while holding the developer accountable may be too removed from the clinical setting [24]. The question of who should be held accountable when AI systems fail remains to be answered [24].\nData Availability and Accessibility\nLarge amounts of data from various sources are required to train AI algorithms in health care [55]. However, accessing health data can be challenging due to fragmentation across different platforms and systems [55]. Data availability in health care is limited, and there is often a reluctance to share data between hospitals [56]. The continuous availability of data for ongoing improvement of ML-based systems can be difficult due to organizational resistance [57]. Technological advancements and improved algorithms can help address the problem of limited data sets [57].\nRegulatory Concerns\nThe autolearn feature of AI software poses regulatory challenges as algorithms evolve continuously with use [58]. This creates the need for additional policies and procedures to ensure patient safety [58]. Many countries have yet to formalize regulatory guidelines for assessing AI algorithmic safety, which can hinder AI adoption and lead to risky practices [59]. The lack of industry rules on the ethical usage of AI in health care further complicates the accountability issue [60]. Efforts by the Food and Drug Administration and National Health Service to establish guidelines and standards are ongoing but pose barriers to regulatory approval [60,61].\nSocial Challenges\nMisconceptions about AI replacing health care jobs lead to skepticism and aversion to AI-based interventions [43]. However, the arrival of AI does not necessarily mean job obsolescence but rather job reengineering [62]. Overcoming skepticism and fostering trust in AI requires a better understanding of its capabilities and meaningful public discourse [62]. Improving public and health care professionals\u2019 understanding of AI is essential to managing expectations and addressing concerns.\nDiscussion\nPrincipal Findings\nThis narrative review delves into the dynamic landscape of AI integration in health care, aiming to uncover a spectrum of perspectives, concerns, and opportunities. This exploration encompasses a diverse range of health care settings from different countries and regions, unveiling a rich tapestry of AI adoption. Overall, AI offers tremendous potential and will continue to play a crucial role in future health care decisions. If AI is successfully used, it can reduce pressure on health care workers while improving work quality by lowering mistakes and improving precision. It has the potential to give people more control over their health decisions and can lower avoidable hospitalizations. It can broaden the scope of medical knowledge and build on the present clinical guidelines. Given its advantages and capability to drive the development of precision medicine, it is universally acknowledged to be a much-needed enhancement in medicine. AI is anticipated to eventually master most of the essential domains within health care.\nHowever, there are some difficulties associated with incorporating AI in health care. Acquiring enough data to train precise algorithms is a continual effort that necessitates a shift in attitude towards data sharing that promotes technical advancement. Specific guidelines on how to securely adopt and evaluate AI technology and research on AI\u2019s potential and limitations are required. Robust research is also required to empirically demonstrate the benefits of AI use in the actual world. While the perfect conditions for successful AI adoption may not yet exist, there is still room for AI advancement in health care.\nGiven that AI has tremendous potential and is the future, there are a few crucial points to consider when using AI in health care. First, given the need for more general agreement in AI governance, it may be impossible to develop AI-based systems whose algorithms can be generalized across all health care domains. As a result, it may be wise to concentrate on systems that can be implemented and used effectively in the health care institutions for which they were designed. Fundamentally, patient care must take priority over the excitement of cutting-edge technology. The AI system\u2019s safety and competence must be weighed for use only when appropriate and valuable to patients.\nSecond, AI in health care must still be complemented with human input. Although AI has advantages in speed and accuracy, physicians are still needed for more cognitively complex or psychological elements and activities. Similarly, although the detection and monitoring of vital disease symptoms are now automated, the objective behind AI is not to eliminate physician input but to focus their expertise on areas where they are more necessary and on what computers cannot and may never imitate. Therefore, focusing on developing complementarity between the use of AI and physicians by training is essential.\nIn addition, while it is critical to lower expectations, it is also critical not to be excessively gloomy about the role of AI in health care. While physicians may need to comprehend the processes of AI algorithms, most physicians understand magnetic resonance imaging or computed tomography to some level. Despite a lack of individual physician comprehension of their specific process, these studies are extensively used. The lack of transparency in ML algorithms may thus be tolerable if the algorithm\u2019s efficacy can be demonstrated. Again, this can be achieved with training and familiarizing the physician with the AI system.\nRather than putting AI to a standard of either perfect or nil results, one should compare the outcomes of using AI to those of the natural world, where physicians can and will make mistakes. Importantly, AI is dynamic in nature and can improve using more extensive data sets. As a result, it is entirely possible that the combined usage of physician and AI input would be more successful over time. However, it is critical not to overstate the status of AI. Its implementation in health care will be a careful, deliberate, and progressive process, including strict control and monitoring of its use and efficacy. AI can help patients and increase the quality of care when combined with input and oversight from health care professionals. AI systems will not wholly replace human clinicians but will supplement their efforts to care for patients. Human therapists may eventually shift towards jobs and job designs that require distinctly human skills, such as enthusiasm and knowledge to use AI in health care.\nAs global communities live longer lives and the prevalence of chronic disease rises, the rising cost of health care will remain a hot topic among health care stakeholders. It is time to seek the assistance of machines as they can potentially reduce economic costs. Furthermore, coordination between government and private sector industry partners is vital to realize this potential and take advantage of AI\u2019s full potential in health care delivery.\nWith all this, the key challenge for AI in many sectors of health care is ensuring its adoption in daily clinical practice rather than whether the technologies will be equipped to be effective. AI systems must be approved by regulators, linked with electronic health record systems, standardized to the point that similar products perform similarly, taught to medical practitioners, paid for by public or private payer organizations, and modified in the field over time for widespread adoption to occur shortly. Since AI has a significant and lasting impact on lives and is the future of health care, it is essential to address the associated concerns. Given its importance, AI needs proper policy guidelines and regulations regarding its usage in health care to reap its maximum benefits.\nComparison With Previous Literature\nIn comparing the findings of this review with existing literature, several key similarities and differences emerge. This review aligns with Gazquez-Garcia et al [63] and Mooghali et al [64] in highlighting the crucial role of health care professional training for effective AI integration. Both emphasize the need for proficiency in AI fundamentals, data analytics, and ethical considerations, reinforcing the notion that successful AI adoption requires a well-prepared workforce. The review also echoes Sapci and Sapci\u2019s [65] advocacy for incorporating AI education into medical curricula to address future challenges.\nHowever, this review diverges in its emphasis on practical AI implementation challenges. While Moghadasi et al [66] and Muley et al [67] discuss the risks associated with AI, including the need for enhanced transparency and stakeholder collaboration, this review adds a nuanced perspective on balancing AI\u2019s potential benefits with its ethical risks. For instance, this review highlights the importance of human oversight and the complementarity of AI with clinician expertise, which aligns with Morley et al [68] and Zhang and Zhang [69] but also offers additional insights into practical implementation issues not fully covered in the previous reviews.\nIn terms of public perception, this review supports Kerstan [70] and Castagno and Khalifa [71] by acknowledging that trust in AI is influenced by knowledge and transparency. However, it further explores the dynamic interaction between AI\u2019s promise and the necessity for rigorous validation and ethical governance, as discussed by Macrae [72] and Tulk Jesso et al [73]. This review underscores that while AI has the potential to revolutionize health care, its integration must be handled with careful consideration of both practical and ethical dimensions to achieve meaningful improvements in patient care and outcomes.\nStrengths and Limitations\nFirst, the generalizability of the findings may be affected by the inherent variations in study methodologies, AI implementations, and health care settings across different regions. This heterogeneity introduces variability that could influence the applicability of the conclusions. To mitigate this limitation, rigorous search strategies were used across multiple databases to include a diverse range of studies. Future reviews could benefit from incorporating more standardized studies to enhance generalizability. Second, the reliance on published literature from electronic databases introduces potential publication bias. Studies with positive outcomes related to AI integration in health care may be more likely to be published, which could skew perceptions of AI effectiveness and adoption rates. Efforts were made to address this bias by including a broad range of databases and emphasizing recent literature. Future research should aim to include unpublished studies or grey literature to provide a more balanced view. Third, the rapid evolution of AI technologies means that newer developments and implementations may not have been fully captured in this review. The review focused on the most current literature available at the time of the search to address this issue. Regular updates will be necessary to incorporate the latest advancements and ensure the review remains relevant. In addition, the absence of details around stakeholder engagement could have enriched the study by providing additional depth and perspective. Engaging stakeholders in such a dynamic field would offer diverse viewpoints and further validate the conclusions. Future research should consider incorporating stakeholder engagement to enhance the robustness and applicability of the findings.\nDespite these limitations, this review offers several notable strengths. It provides a comprehensive overview of AI integration in health care, leveraging rigorous search strategies across multiple databases to ensure a diverse and current collection of literature. This approach contributes to a nuanced understanding of AI\u2019s potential and limitations. Furthermore, the emphasis on recent developments helps ensure that the review reflects the most current trends and advancements in AI technologies.\nFuture Directions\nMoving forward, further research in the field of AI integration in health care should address several key areas to advance understanding and application. First, studies should prioritize incorporating stakeholder engagement, including health care providers, patients, policymakers, and technology developers, to provide diverse perspectives on AI adoption and implementation strategies, enhancing relevance and acceptance in clinical practice. Second, longitudinal studies are crucial to assess the long-term impacts of AI technologies in health care settings, providing insights into sustainability, scalability, and real-world effectiveness over time. Third, comprehensive research focusing on the ethical implications of AI, including data privacy, algorithm bias, patient consent, and regulatory frameworks, is needed to build trust and ensure responsible deployment. In addition, comparative effectiveness research comparing AI-assisted interventions with standard care protocols can provide evidence of AI\u2019s impact on clinical outcomes, patient safety, and health care efficiency. Interdisciplinary collaboration between computer scientists, health care professionals, social scientists, and ethicists is essential to foster innovative approaches aligned with health care needs. Education and training programs for health care professionals on AI technologies will ensure proficiency in interpreting AI-generated insights and integrating them into patient care effectively. Finally, research should explore how AI can reduce health care disparities and improve access to quality care, particularly in underserved communities and low-resource settings. Addressing these priorities will realize AI\u2019s potential in transforming health care delivery and improving patient outcomes globally.\nConclusions\nIn summary, AI presents a transformative force in health care, with the potential to enhance patient care, reduce errors, and broaden medical knowledge. However, its successful integration requires adaptability; complementarity with human expertise; transparency; and a deliberate, incremental approach. AI\u2019s impact on health care is evolutionary, not revolutionary, and collaboration between stakeholders, standardization, education, and robust policies are essential to harness its full potential while upholding patient-centric care and innovation.\nAbbreviations\n- AI\nartificial intelligence\n- BERT\nBidirectional Encoder Representations from Transformers\n- GPT\nGenerative Pre-trained Transformer\n- MeSH\nMedical Subject Headings\n- ML\nmachine learning\n- NLP\nnatural language processing\n- PRISMA\nPreferred Reporting Items for Systematic Reviews and Meta-Analyses\n- RBES\nrule-based expert systems\n- STI\nsexually transmitted infection\nDetailed search strategy across databases for artificial intelligence (AI) integration in health care.\nData Availability\nAll data generated or analyzed during this study are included in this published paper and its supplementary information files.\nFootnotes\nAuthors' Contributions: As the sole author of this manuscript, MC was responsible for all aspects of the study, including conceptualization, literature review, writing, and editing.\nConflicts of Interest: None declared.\nReferences\n- 1.Ghafur S, van Dael J, Leis M, Darzi A, Sheikh A. Public perceptions on data sharing: key insights from the UK and the USA. Lancet Digit Health. 2020;2(9):e444\u2013e446. doi: 10.1016\/S2589-7500(20)30161-8. https:\/\/linkinghub.elsevier.com\/retrieve\/pii\/S2589-7500(20)30161-8 .S2589-7500(20)30161-8 [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 2.Davenport T, Kalakota R. The potential for artificial intelligence in healthcare. Future Healthc J. 2019;6(2):94\u201398. doi: 10.7861\/futurehosp.6-2-94. https:\/\/linkinghub.elsevier.com\/retrieve\/pii\/S2514-6645(24)01059-2 .S2514-6645(24)01059-2 [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 3.Lee SI, Celik S, Logsdon BA, Lundberg SM, Martins TJ, Oehler VG, Estey EH, Miller CP, Chien S, Dai J, Saxena A, Blau CA, Becker PS. A machine learning approach to integrate big data for precision medicine in acute myeloid leukemia. Nat Commun. 2018;9(1):42. doi: 10.1038\/s41467-017-02465-5. https:\/\/doi.org\/10.1038\/s41467-017-02465-5 .10.1038\/s41467-017-02465-5 [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 4.Sordo M. Open Clinical Knowledge Management for Medical Care. Boston, MA: Margarita Sordo; 2002. Introduction to Neural Networks in Healthcare. [Google Scholar]\n- 5.Fakoor R, Ladhak F, Nazi A, Huber M. Using deep learning to enhance cancer diagnosis and classification. The 30th International Conference on Machine Learning (ICML 2013), WHEALTH Workshop; June 16-21, 2023; Atlanta, GA. 2013. https:\/\/www.researchgate.net\/publication\/281857285_Using_deep_learning_to_enhance_cancer_diagnosis_and_classification . [Google Scholar]\n- 6.Vial A, Stirling D, Field M, Ros M, Ritz C, Carolan M, Holloway L, Miller AA. The role of deep learning and radiomic feature extraction in cancer-specific predictive modelling: a review. Transl Cancer Res. 2018;7(3):803\u2013816. doi: 10.21037\/tcr.2018.05.02. [DOI] [Google Scholar]\n- 7.Davenport TH, Glaser J. Just-in-time delivery comes to knowledge management. Harv Bus Rev. 2002;80(7):107\u201311, 126. [PubMed] [Google Scholar]\n- 8.Quinn TP, Senadeera M, Jacobs S, Coghlan S, Le V. Trust and medical AI: the challenges we face and the expertise needed to overcome them. J Am Med Inform Assoc. 2021;28(4):890\u2013894. doi: 10.1093\/jamia\/ocaa268. https:\/\/europepmc.org\/abstract\/MED\/33340404 .6042213 [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 9.Albahri AS, Duhaim AM, Fadhel MA, Alnoor A, Baqer NS, Alzubaidi L, Albahri OS, Alamoodi AH, Bai J, Salhi A, Santamar\u00eda J, Ouyang C, Gupta A, Gu Y, Deveci M. A systematic review of trustworthy and explainable artificial intelligence in healthcare: assessment of quality, bias risk, and data fusion. Information Fusion. 2023;96:156\u2013191. doi: 10.1016\/j.inffus.2023.03.008. [DOI] [Google Scholar]\n- 10.Wesson P, Hswen Y, Valdes G, Stojanovski K, Handley MA. Risks and opportunities to ensure equity in the application of big data research in public health. Annu Rev Public Health. 2022;43:59\u201378. doi: 10.1146\/annurev-publhealth-051920-110928. https:\/\/www.annualreviews.org\/content\/journals\/10.1146\/annurev-publhealth-051920-110928?crawler=true&mimetype=application\/pdf . [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 11.Powezka K, Slater L, Wall M, Gkoutos G, Juszczak M. Source of data for artificial intelligence applications in vascular surgery - a scoping review. medRxiv. doi: 10.1101\/2023.10.03.23296506. Preprint posted online on October 4, 2023. [DOI] [Google Scholar]\n- 12.Gaviria-Valencia S, Murphy SP, Kaggal VC, McBane Ii RD, Rooke TW, Chaudhry R, Alzate-Aguirre M, Arruda-Olson AM. Near real-time natural language processing for the extraction of abdominal aortic aneurysm diagnoses from radiology reports: algorithm development and validation study. JMIR Med Inform. 2023;11:e40964. doi: 10.2196\/40964. https:\/\/medinform.jmir.org\/2023\/\/e40964\/ v11i1e40964 [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 13.Liu W, Zhang X, Lv H, Li J, Liu Y, Yang Z, Weng X, Lin Y, Song H, Wang Z. Using a classification model for determining the value of liver radiological reports of patients with colorectal cancer. Front Oncol. 2022;12:913806. doi: 10.3389\/fonc.2022.913806. https:\/\/europepmc.org\/abstract\/MED\/36479085 . [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 14.Yang X, Chen A, PourNejatian N, Shin HC, Smith KE, Parisien C, Compas C, Martin C, Costa AB, Flores MG, Zhang Y, Magoc T, Harle CA, Lipori G, Mitchell DA, Hogan WR, Shenkman EA, Bian J, Wu Y. A large language model for electronic health records. NPJ Digit Med. 2022;5(1):194. doi: 10.1038\/s41746-022-00742-2. https:\/\/doi.org\/10.1038\/s41746-022-00742-2 .10.1038\/s41746-022-00742-2 [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 15.Bhayana R. Chatbots and large language models in radiology: a practical primer for clinical and research applications. Radiology. 2024;310(1):e232756. doi: 10.1148\/radiol.232756. [DOI] [PubMed] [Google Scholar]\n- 16.Hu Y, Chen Q, Du J, Peng X, Keloth VK, Zuo X, Zhou Y, Li Z, Jiang X, Lu Z, Roberts K, Xu H. Improving large language models for clinical named entity recognition via prompt engineering. J Am Med Inform Assoc. 2024;31(9):1812\u20131820. doi: 10.1093\/jamia\/ocad259.7590607 [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 17.Muehlematter UJ, Daniore P, Vokinger KN. Approval of artificial intelligence and machine learning-based medical devices in the USA and Europe (2015-20): a comparative analysis. Lancet Digit Health. 2021;3(3):e195\u2013e203. doi: 10.1016\/S2589-7500(20)30292-2. https:\/\/linkinghub.elsevier.com\/retrieve\/pii\/S2589-7500(20)30292-2 .S2589-7500(20)30292-2 [DOI] [PubMed] [Google Scholar]\n- 18.Rysavy M. Evidence-based medicine: a science of uncertainty and an art of probability. Virtual Mentor. 2013;15(1):4\u20138. doi: 10.1001\/virtualmentor.2013.15.1.fred1-1301. https:\/\/journalofethics.ama-assn.org\/article\/evidence-based-medicine-science-uncertainty-and-art-probability\/2013-01 .virtualmentor.2013.15.1.fred1-1301 [DOI] [PubMed] [Google Scholar]\n- 19.Rajkomar A, Oren E, Chen K, Dai AM, Hajaj N, Hardt M, Liu PJ, Liu X, Marcus J, Sun M, Sundberg P, Yee H, Zhang K, Zhang Y, Flores G, Duggan GE, Irvine J, Le Q, Litsch K, Mossin A, Tansuwan J, Wang D, Wexler J, Wilson J, Ludwig D, Volchenboum SL, Chou K, Pearson M, Madabushi S, Shah NH, Butte AJ, Howell MD, Cui C, Corrado GS, Dean J. Scalable and accurate deep learning with electronic health records. NPJ Digit Med. 2018;1:18. doi: 10.1038\/s41746-018-0029-1. https:\/\/doi.org\/10.1038\/s41746-018-0029-1 .29 [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 20.Shimabukuro DW, Barton CW, Feldman MD, Mataraso SJ, Das R. Effect of a machine learning-based severe sepsis prediction algorithm on patient survival and hospital length of stay: a randomised clinical trial. BMJ Open Respir Res. 2017;4(1):e000234. doi: 10.1136\/bmjresp-2017-000234. https:\/\/bmjopenrespres.bmj.com\/lookup\/pmidlookup?view=long&pmid=29435343 .bmjresp-2017-000234 [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 21.Cheng JZ, Ni D, Chou YH, Qin J, Tiu CM, Chang YC, Huang CS, Shen D, Chen CM. Computer-aided diagnosis with deep learning architecture: applications to breast lesions in US images and pulmonary nodules in CT scans. Sci Rep. 2016;6:24454. doi: 10.1038\/srep24454. https:\/\/doi.org\/10.1038\/srep24454 .srep24454 [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 22.Young SD, Crowley JS, Vermund SH. Artificial intelligence and sexual health in the USA. Lancet Digit Health. 2021;3(8):e467\u2013e468. doi: 10.1016\/S2589-7500(21)00117-5. https:\/\/linkinghub.elsevier.com\/retrieve\/pii\/S2589-7500(21)00117-5 .S2589-7500(21)00117-5 [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 23.Madsen LB. Data-Driven Healthcare: How Analytics and BI are Transforming The Industry. Hoboken, NJ: Wiley Publishing; 2014. [Google Scholar]\n- 24.Aung YYM, Wong DCS, Ting DSW. The promise of artificial intelligence: a review of the opportunities and challenges of artificial intelligence in healthcare. Br Med Bull. 2021;139(1):4\u201315. doi: 10.1093\/bmb\/ldab016.6353269 [DOI] [PubMed] [Google Scholar]\n- 25.Jones LD, Golan D, Hanna S, Ramachandran M. Artificial intelligence, machine learning and the evolution of healthcare: A bright future or cause for concern? Bone and Joint Research. 2018;7(3):223\u2013225. doi: 10.1302\/2046-3758.73.BJR-2017-0147.R1. https:\/\/boneandjoint.org.uk\/article\/10.1302\/2046-3758.73.BJR-2017-0147.R1 . [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 26.Hashimoto DA, Ward TM, Meireles OR. The role of artificial intelligence in surgery. Adv Surg. 2020;54:89\u2013101. doi: 10.1016\/j.yasu.2020.05.010.S0065-3411(20)30017-8 [DOI] [PubMed] [Google Scholar]\n- 27.Akbar Safav A, Fekri P, Setoodeh P, Zadeh MH. Toward deep secure tele-surgery system. The 16th International Conference on Scientific Computing (CSC'18); October 13, 2024; Las Vegas, NV. 2018. https:\/\/www.researchgate.net\/publication\/346502758_Toward_Deep_Secure_Tele-surgery_System . [Google Scholar]\n- 28.Shaheen MY. AI in healthcare: medical and socioeconomic benefits and challenges. OSF. doi: 10.31219\/osf.io\/um38t. Preprint posted online on September 28, 2021. [DOI] [Google Scholar]\n- 29.Luxton DD. Artificial Intelligence in Behavioral and Mental Health Care. London, United Kingdom: Elsevier Academic Press; 2016. An introduction to artificial intelligence in behavioral and mental health care; pp. 1\u201326. [Google Scholar]\n- 30.Lovejoy CA, Buch V, Maruthappu M. Technology and mental health: the role of artificial intelligence. Eur Psychiatry. 2019 Jan;55:1\u20133. doi: 10.1016\/j.eurpsy.2018.08.004.S0924-9338(18)30162-7 [DOI] [PubMed] [Google Scholar]\n- 31.Habermann J. Language and psycho-social well-being. Knowledge Common Works. doi: 10.17613\/gb58-rx71. Preprint posted online in 2021. [DOI] [Google Scholar]\n- 32.Le Glaz A, Haralambous Y, Kim-Dufor DH, Lenca P, Billot R, Ryan TC, Marsh J, DeVylder J, Walter M, Berrouiguet S, Lemey C. Machine learning and natural language processing in mental health: systematic review. J Med Internet Res. 2021;23(5):e15708. doi: 10.2196\/15708. https:\/\/www.jmir.org\/2021\/5\/e15708\/ v23i5e15708 [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 33.Nguyen LT, Do TTH. Artificial Intelligence in Healthcare: A New Technology Benefit for Patients and Doctors. Proceedings of the Portland International Conference on Management of Engineering and Technology (PICMET); August 25-29, 2019; Portland, OR. 2019. pp. 1\u201315. [DOI] [Google Scholar]\n- 34.Beck JT, Rammage M, Jackson GP, Preininger AM, Dankwa-Mullan I, Roebuck MC, Torres A, Holtzen H, Coverdill SE, Williamson MP, Chau Q, Rhee K, Vinegra M. Artificial intelligence tool for optimizing eligibility screening for clinical trials in a large community cancer center. JCO Clin Cancer Inform. 2020;4:50\u201359. doi: 10.1200\/CCI.19.00079. https:\/\/ascopubs.org\/doi\/10.1200\/CCI.19.00079?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub0pubmed . [DOI] [PubMed] [Google Scholar]\n- 35.Ichikawa D, Saito T, Ujita W, Oyama H. How can machine-learning methods assist in virtual screening for hyperuricemia? A healthcare machine-learning approach. J Biomed Inform. 2016;64:20\u201324. doi: 10.1016\/j.jbi.2016.09.012. https:\/\/linkinghub.elsevier.com\/retrieve\/pii\/S1532-0464(16)30125-3 .S1532-0464(16)30125-3 [DOI] [PubMed] [Google Scholar]\n- 36.Vollmer S, Mateen BA, Bohner G, Kir\u00e1ly FJ, Ghani R, Jonsson P, Cumbers S, Jonas A, McAllister KSL, Myles P, Granger D, Birse M, Branson R, Moons KGM, Collins GS, Ioannidis JPA, Holmes C, Hemingway H. Machine learning and artificial intelligence research for patient benefit: 20 critical questions on transparency, replicability, ethics, and effectiveness. BMJ. 2020;368:l6927. doi: 10.1136\/bmj.l6927. http:\/\/www.bmj.com\/lookup\/pmidlookup?view=long&pmid=32198138 . [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 37.Verghese A, Shah NH, Harrington RA. What this computer needs is a physician: humanism and artificial intelligence. JAMA. 2018;319(1):19\u201320. doi: 10.1001\/jama.2017.19198.2666717 [DOI] [PubMed] [Google Scholar]\n- 38.Dilsizian SE, Siegel EL. Artificial intelligence in medicine and cardiac imaging: harnessing big data and advanced computing to provide personalized medical diagnosis and treatment. Curr Cardiol Rep. 2014;16(1):441. doi: 10.1007\/s11886-013-0441-8. [DOI] [PubMed] [Google Scholar]\n- 39.Bush J. How AI is taking the scut work out of health care. Harvard Business Review. 2018. Mar 5, [2024-10-04]. https:\/\/hbr.org\/2018\/03\/how-ai-is-taking-the-scut-work-out-of-health-care .\n- 40.Wiens J, Shenoy ES. Machine learning for healthcare: on the verge of a major shift in healthcare epidemiology. Clin Infect Dis. 2018;66(1):149\u2013153. doi: 10.1093\/cid\/cix731. https:\/\/europepmc.org\/abstract\/MED\/29020316 .4085880 [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 41.Swetlitz L, Ross C. IBM pitched its Watson supercomputer as a revolution in cancer care. It\u2019s nowhere close. STAT. 2017. Sep 5, [2017-09-05]. https:\/\/www.statnews.com\/2017\/09\/05\/watson-ibm-cancer\/\n- 42.Davenport TH. The AI Advantage: How to Put the Artificial Intelligence Revolution to Work. Cambridge, MA: The MIT Press; 2018. [Google Scholar]\n- 43.Sun TQ, Medaglia R. Mapping the challenges of artificial intelligence in the public sector: evidence from public healthcare. Government Information Quarterly. 2019;36(2):368\u2013383. doi: 10.1016\/j.giq.2018.09.008. [DOI] [Google Scholar]\n- 44.Fogel AL, Kvedar JC. Artificial intelligence powers digital medicine. NPJ Digit Med. 2018;1:5. doi: 10.1038\/s41746-017-0012-2. https:\/\/doi.org\/10.1038\/s41746-017-0012-2 .12 [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 45.Stewart J, Sprivulis P, Dwivedi G. Artificial intelligence and machine learning in emergency medicine. Emerg Med Australas. 2018;30(6):870\u2013874. doi: 10.1111\/1742-6723.13145. [DOI] [PubMed] [Google Scholar]\n- 46.Vayena E, Blasimme A, Cohen IG. Machine learning in medicine: Addressing ethical challenges. PLoS Med. 2018;15(11):e1002689. doi: 10.1371\/journal.pmed.1002689. [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 47.Marwan M, Kartit A, Ouahmane H. Security enhancement in healthcare cloud using machine learning. Procedia Computer Science. 2018;127:388\u2013397. doi: 10.1016\/j.procs.2018.01.136. [DOI] [Google Scholar]\n- 48.van der Schaar M, Alaa AM, Floto A, Gimson A, Scholtes S, Wood A, McKinney E, Jarrett D, Lio P, Ercole A. How artificial intelligence and machine learning can help healthcare systems respond to COVID-19. Mach Learn. 2021;110(1):1\u201314. doi: 10.1007\/s10994-020-05928-x. https:\/\/europepmc.org\/abstract\/MED\/33318723 .5928 [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 49.Dawson D, Schleiger E, McLaughlin J, Robinson C, Quezada G, Scowcroft J, Hajkowicz S. Artificial Intelligence Australia\u2019s Ethics Framework A Discussion Paper. Eveleigh, Australia: Data 61 CSIRO; 2019. [Google Scholar]\n- 50.Powles J, Hodson H. Google deepMind and healthcare in an age of algorithms. Health Technol (Berl) 2017;7(4):351\u2013367. doi: 10.1007\/s12553-017-0179-1. https:\/\/europepmc.org\/abstract\/MED\/29308344 .179 [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 51.Davenport TH, Dreyer KJD. AI will change radiology, but it won't replace radiologists. Harvard Business Publishing Education. 2018. [2024-10-08]. https:\/\/hbsp.harvard.edu\/search?action=&author=Keith+J+Dreyer+DO&activeTab=products .\n- 52.Angwin J, Larson J, Mattu S, Kirchner L. Machine bias. In: Martin K, editor. Ethics of Data and Analytics. New York, NY: Auerbach Publications; 2022. [Google Scholar]\n- 53.Reddy S, Fox J, Purohit MP. Artificial intelligence-enabled healthcare delivery. J R Soc Med. 2019;112(1):22\u201328. doi: 10.1177\/0141076818815510. https:\/\/europepmc.org\/abstract\/MED\/30507284 . [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 54.Wang F, Preininger A. AI in health: state of the art, challenges, and future directions. Yearb Med Inform. 2019;28(1):16\u201326. doi: 10.1055\/s-0039-1677908. http:\/\/www.thieme-connect.com\/DOI\/DOI?10.1055\/s-0039-1677908 . [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 55.Jianying Hu APFW. Data-driven analytics for personalized healthcare. Healthcare Information Management Systems. 2016:529\u2013554. https:\/\/link.springer.com\/chapter\/10.1007\/978-3-319-20765-0_31 . [Google Scholar]\n- 56.Johnson KW, Torres Soto J, Glicksberg BS, Shameer K, Miotto R, Ali M, Ashley E, Dudley JT. Artificial intelligence in cardiology. J Am Coll Cardiol. 2018;71(23):2668\u20132679. doi: 10.1016\/j.jacc.2018.03.521. https:\/\/linkinghub.elsevier.com\/retrieve\/pii\/S0735-1097(18)34408-5 .S0735-1097(18)34408-5 [DOI] [PubMed] [Google Scholar]\n- 57.Lopez K, Fodeh SJ, Allam A, Brandt CA, Krauthammer M. Reducing annotation burden through multimodal learning. Front Big Data. 2020;3:19. doi: 10.3389\/fdata.2020.00019. https:\/\/europepmc.org\/abstract\/MED\/33693393 . [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 58.Deciding when to submit a 510(k) for a software change to an existing device. Food and Drug Administration. 2017. Oct, [2024-11-06]. https:\/\/www.fda.gov\/regulatory-information\/search-fda-guidance-documents\/deciding-when-submit-510k-software-change-existing-device .\n- 59.Parikh RB, Obermeyer Z, Navathe AS. Regulation of predictive analytics in medicine. Science. 2019;363(6429):810\u2013812. doi: 10.1126\/science.aaw0029. [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 60.Jiang F, Jiang Y, Zhi H, Dong Y, Li H, Ma S, Wang Y, Dong Q, Shen H, Wang Y. Artificial intelligence in healthcare: past, present and future. Stroke Vasc Neurol. 2017;2(4):230\u2013243. doi: 10.1136\/svn-2017-000101. https:\/\/svn.bmj.com\/lookup\/pmidlookup?view=long&pmid=29507784 .svn-2017-000101 [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 61.Ramesh AN, Kambhampati C, Monson JRT, Drew PJ. Artificial intelligence in medicine. Ann R Coll Surg Engl. 2004;86(5):334\u20138. doi: 10.1308\/147870804290. https:\/\/europepmc.org\/abstract\/MED\/15333167 . [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 62.Topol EJ. High-performance medicine: the convergence of human and artificial intelligence. Nat Med. 2019;25(1):44\u201356. doi: 10.1038\/s41591-018-0300-7.10.1038\/s41591-018-0300-7 [DOI] [PubMed] [Google Scholar]\n- 63.Gazquez-Garcia J, S\u00e1nchez-Bocanegra CL, Sevillano JL. Artificial intelligence in the health sector: key skills for future health professionals. JMIR Preprints. doi: 10.2196\/preprints.58161. Preprint posted online on March 7, 2024. [DOI] [Google Scholar]\n- 64.Mooghali M, Stroud AM, Yoo DW, Barry BA, Grimshaw AA, Ross JS, Zhu X, Miller JE. Barriers and facilitators to trustworthy and ethical AI-enabled medical care from patient's and healthcare provider's perspectives: a literature review. medRxiv. doi: 10.1101\/2023.10.02.23296447. Preprint posted on online on October 2, 2023. [DOI] [Google Scholar]\n- 65.Sapci AH, Sapci HA. Artificial intelligence education and tools for medical and health informatics students: systematic review. JMIR Med Educ. 2020;6(1):e19285. doi: 10.2196\/19285. https:\/\/mededu.jmir.org\/2020\/1\/e19285\/ v6i1e19285 [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 66.Moghadasi N, Valdez RS, Piran M, Moghaddasi N, Linkov I, Polmateer TL, Loose DC, Lambert JH. Risk analysis of artificial intelligence in medicine with a multilayer concept of system order. Systems. 2024;12(2):47. doi: 10.3390\/systems12020047. [DOI] [Google Scholar]\n- 67.Muley A, Muzumdar P, Kurian G, Basyal GP. Risk of AI in healthcare: a comprehensive literature review and study framework. AJMAH. 2023;21(10):276\u2013291. doi: 10.9734\/ajmah\/2023\/v21i10903. [DOI] [Google Scholar]\n- 68.Morley J, Machado CCV, Burr C, Cowls J, Joshi I, Taddeo M, Floridi L. The ethics of AI in health care: a mapping review. SSRN Journal. 2020 doi: 10.2139\/ssrn.3830408. [DOI] [PubMed] [Google Scholar]\n- 69.Zhang J, Zhang ZM. Ethics and governance of trustworthy medical artificial intelligence. BMC Med Inform Decis Mak. 2023;23(1):7\u20137. doi: 10.1186\/s12911-023-02103-9. [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 70.Kerstan S, Bienefeld N, Grote G. Choosing human over AI doctors? how comparative trust associations and knowledge relate to risk and benefit perceptions of AI in healthcare. Risk Anal. 2024;44(4):939\u2013957. doi: 10.1111\/risa.14216. [DOI] [PubMed] [Google Scholar]\n- 71.Castagno S, Khalifa M. Perceptions of artificial intelligence among healthcare staff: a qualitative survey study. Front Artif Intell. 2020;3:578983. doi: 10.3389\/frai.2020.578983. https:\/\/europepmc.org\/abstract\/MED\/33733219 .578983 [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 72.Macrae C. Governing the safety of artificial intelligence in healthcare. BMJ Qual Saf. 2019;28(6):495\u2013498. doi: 10.1136\/bmjqs-2019-009484.bmjqs-2019-009484 [DOI] [PubMed] [Google Scholar]\n- 73.Tulk Jesso S, Kelliher A, Sanghavi H, Martin T, Henrickson Parker S. Inclusion of clinicians in the development and evaluation of clinical artificial intelligence tools: a systematic literature review. Front Psychol. 2022;13:830345. doi: 10.3389\/fpsyg.2022.830345. https:\/\/europepmc.org\/abstract\/MED\/35465567 . [DOI] [PMC free article] [PubMed] [Google Scholar]\nAssociated Data\nThis section collects any data citations, data availability statements, or supplementary materials included in this article.\nSupplementary Materials\nDetailed search strategy across databases for artificial intelligence (AI) integration in health care.\nData Availability Statement\nLarge amounts of data from various sources are required to train AI algorithms in health care [55]. However, accessing health data can be challenging due to fragmentation across different platforms and systems [55]. Data availability in health care is limited, and there is often a reluctance to share data between hospitals [56]. The continuous availability of data for ongoing improvement of ML-based systems can be difficult due to organizational resistance [57]. Technological advancements and improved algorithms can help address the problem of limited data sets [57].\nAll data generated or analyzed during this study are included in this published paper and its supplementary information files.",
    "scraped_at":"2025-07-07T18:26:01.244191"
  },
  {
    "topic":"AI in healthcare",
    "title":"How AI is Transforming Healthcare: 12 Real-World Use Cases",
    "url":"https:\/\/medwave.io\/2024\/01\/how-ai-is-transforming-healthcare-12-real-world-use-cases\/",
    "domain":"medwave.io",
    "snippet":"Artificial intelligence has moved from hype to mainstream adoption across healthcare, unlocking new possibilities for improving patient outcomes, experiences, and access to care. Below, we\u2019ll explore 12 impactful real-world use cases showing exactly how healthcare providers are leveraging different...",
    "content":"Artificial intelligence has moved from hype to mainstream adoption across healthcare, unlocking new possibilities for improving patient outcomes, experiences, and access to care.\nBelow, we\u2019ll explore 12 impactful real-world use cases showing exactly how healthcare providers are leveraging different AI models to enhance clinical workflows, augment decision making, streamline operational processes, and advance precision medicine.\nWe\u2019ll examine practical AI applications in specialties ranging from oncology to cardiology to radiology and beyond. The tangible examples demonstrate how doctors can incorporate algorithmic insights to drive quality, safety, efficiency, and revenue. Statistics and tangible results will reveal the measurable impact attained by health systems employing AI-powered solutions.\nBy the end of this comprehensive resource, you will have clear understanding of:\n- The categories of AI improving patient care and provider performance\n- 12 applied use cases of AI models aiding clinical specialties\n- How leading health systems are already achieving outcomes using AI\n- The measurable clinical, financial, and operational results attained\n- Practical steps to identify and implement ethical, effective AI technology\nThis detailed evidence quantifies how AI is transitioning from promise to practical tools delivering better care for patients and providers.\nHow AI is Transforming Healthcare Delivery\nApplied AI has stepped to the forefront of digital health innovation, but discussions often remain too theoretical. By examining how real healthcare organizations employ AI models across critical use cases, we move past the hype to quantify real-world enhancements.\nAI solutions are commonly grouped into three capability categories improving care delivery:\n- Clinical Decision Support: AI can analyze patient information against scientific literature, care guidelines, and treatment history to suggest diagnostic and therapeutic options for specific individuals. This augments clinician knowledge.\n- Operational Analytics: Algorithms study complex system, cost, risk, and outcomes data to pinpoint opportunities to intervene upon organizational performance gaps and inefficiencies.\n- Workflow Enhancement: Automating repetitive administrative and documentation tasks allows clinicians to focus on higher-value patient care activities.\nLet\u2019s explore 12 use cases demonstrating AI applicability across prominent medical specialties:\nOncology Use Cases\n- Risk Assessment Models for Cancer Diagnosis\n- Optimizing Chemotherapy Treatment Plans\n- Monitoring Oncology Treatment Response\nCardiology Use Cases\n- Congestive Heart Failure Readmission Risk Prediction\n- ECG Analysis Algorithms to Detect Arrhythmias\n- CT Image Processing for Plaque Detection\nRadiology Use Cases\n- Flagging Critical Findings in Imaging Reports\n- Quantifying Disease Progression Through Imaging Pattern Recognition\n- Automating Follow-up Recommendations from Radiology Reports\nAdditional AI Applications\n- Sepsis Early Warning and Risk Scoring Systems\n- Optimizing Hospital Nursing Staff Models\n- Automating Patient-Reported Outcome Collection\n12 Real-World Healthcare Use Cases of AI\nLet\u2019s explore examples of doctors and health systems seeing success with AI adoption:\nUse Case #1: Risk Assessment Models for Cancer Diagnosis\nCancer takes heavy tolls worldwide, with breast cancer impacting over 250,000 U.S. women annually at a cost of $20 billion. Mammograms serve as a key screening tool but limited radiologist time and expertise constrain oversight. AI-enabled risk assessment models help improve early diagnosis rates to get patients proper treatment sooner.\nResults from Health Systems Using AI Diagnostic Models:\n- Miami Cancer Institute: Computer vision model analyzing mammogram images increased positive predictive value in diagnosing malignancies by 10% compared to clinicians.\n- Sweden\u2019s Karolinska Institute: AI model improved breast cancer risk discrimination by 22% over traditional models by incorporating full patient history data.\n- Owkin and NYU School of Medicine: Algorithm analyzing mammogram images predicted risk scores for breast cancer onset up to 5 years prior to diagnosis.\nBy processing more data points than humanly possible, AI algorithms uncover early signals that advance life-saving diagnosis and interventions for breast cancer patients.\nUse Case #2: Optimizing Chemotherapy Treatment Plans\nOncologists rely on imprecise methods to design chemotherapy regimens, leading to suboptimal medication choices. AI models that assess clinical data, genomic biomarkers, and population outcomes help determine optimal treatment plans for patients.\nResults from Health Systems Using Oncology AI Models:\n- University of North Carolina Lineberger Cancer Center: AI treatment recommendations aligned with oncologist choices in 97% of rectal cancer cases and 95% of bladder cases, improving consistency.\n- Dayton Children\u2019s Hospital: AI model predicted pediatric leukemia patients\u2019 responses to chemotherapy drugs with 92% accuracy to inform care paths.\n- Raghu AI and UCSF: Algorithm analyzing past treatment response data identified more effective drug combinations for breast cancer patients.\nBy predicting optimal medication regimens for patients, AI chemotherapy models enhance consistency in treatment planning while minimizing trial-and-error gaps that delay care.\nUse Case #3: Monitoring Oncology Treatment Response\nCancer treatment plans require frequent adjustment, but quantifying how patients respond to interventions remains challenging. AI imaging algorithms track meaningful changes in tumors over the course of therapy to determine next steps.\nOutcomes from Health Systems Employing AI Treatment Response Monitoring:\n- Johns Hopkins University: Machine learning quantified lung cancer treatment response from CT scans 5 months earlier than traditional clinical criteria.\n- Phathom Analytics and UPMC: AI platform assessed liver lesions over time with 95% accuracy to inform oncology care adjustments.\n- Qure AI and UPMC: Algorithm that autogenerated radiology report impressions improved oncologist productivity by 20%.\nAutomated insights speed critical decision making to enhance cancer care while increasing clinician efficiency.\nUse Case #4: Congestive Heart Failure Readmission Risk Prediction\nHospital readmissions for heart failure require preventive intervention, but stretched cardiology teams struggle predicting who is most at risk. AI algorithms parse clinical and social factors to identify patients prone to bouncing back.\nResults with AI Readmission Risk Scoring:\n- Purposeful AI and Parkland Center for Clinical Innovation: Machine learning model predicted heart failure readmissions within 30 days with 93% recall and 90% precision.\n- Johannes Gutenberg University: Neural network using EMR data autonomously identified of 84% heart failure patients at high readmission risk.\n- Cleveland Clinic: Natural language processing of cardiology notes boosted readmission risk prediction accuracy by 12% over conventional methods.\nPinpointing high-probability readmission patients allows targeting of services like telehealth monitoring to promote intervention before avoidable rehospitalization.\nUse Case #5: ECG Analysis Algorithms to Detect Arrhythmias\nCardiologists interpreting ECG readings look for arrhythmias indicating cardiac issues. But even specialists can overlook subtle patterns in lengthy printouts. AI ECG analysis serves as a validation system to catch potential abnormalities.\nResults from AI-Assisted ECG Analysis:\n- Mayo Clinic: AI detected 10 types of arrhythmia on ECGs with accuracy matching cardiologists, serving as decision support.\n- Cambridge Heart: Machine learning algorithms spotted irregular heart rhythms from wearable data that preceded debilitating strokes.\n- Stanford Medicine: AI model diagnosed pediatric heart arrhythmias on ECGs with 93% accuracy, far faster than manual review.\nAI augments clinicians\u2019 ECG analysis to catch early symptoms of serious heart conditions requiring intervention.\nUse Case #6: CT Image Processing to Identify Plaque Buildup\nCalcified plaque accumulation in arteries can lead to heart attacks and stroke if untreated. But visually inspecting cardiac CT angiogram images for early signs is tedious. AI plaque detection algorithms accelerate analysis.\nResults with Automated Plaque Assessment:\n- Shukra AI and Mount Sinai Hospital: Deep learning detected patients with severe artery plaque buildup with 97% accuracy from CT scans.\n- Entelligence and National Institutes of Health: AI model quantifying coronary artery plaque volume from CT scans matched human experts.\n- Guangzhou Medical University: Machine learning processed cardiac CTs 60x faster than manual review with 93% accuracy distinguishing high-risk plaques.\nAutomating plaque visualization and risk scoring allows cardiologists to diagnose and treat narrowing arteries earlier.\nUse Case #7: Flagging Critical Imaging Findings\nRadiologists face immense burnout from overflowing workloads reviewing scans. AI algorithms serve as a second set of eyes highlighting suspicious lesions and fractures they should urgently review first before more benign cases.\nResults from AI-Assisted Radiology Triage:\n- Qure.AI: AI platform increased critical finding detection on head CTs by 20%.\n- Zebra Medical Vision: Machine learning flagged pneumonia on 10x more chest x-rays than radiologists typically identify.\n- MaxQ AI: Algorithm prioritized likely stroke diagnoses on head scans, improving detection by 35%.\nWorking hand-in-hand with AI ensures radiologists zero in on potentially life-threatening conditions faster.\nUse Case #8: Quantifying Disease Progression through Imaging\nChronic diseases like multiple sclerosis require tracking subtle changes over time to guide treatments. But eyeballing MRI scans makes objectively gauging progression difficult. AI image analysis provides precise measures.\nOutcomes Using AI to Assess Disease Progression:\n- Medical University of South Carolina: Machine learning generated brain lesion measurements from MRI scans that correlated to physical MS symptoms with 90% reliability.\n- Qmenta and Bioxydyn: AI analysis of MRI scans quantified multiple sclerosis brain lesion volumes with 95% accuracy to illustrate disease progression.\n- University of California, San Francisco: AI assessed Alzheimer\u2019s disease brain atrophy rates with 99% accuracy using longitudinal MRI scans.\nSophisticated algorithms reliably quantify previously elusive imaging biomarkers illustrating disease trajectory over time.\nUse Case #9: Automating Follow-up Recommendations from Radiology Reports\nRadiologists\u2019 workload bottlenecks bridge from imaging analysis to communicating actionable findings to care teams. AI techniques can automate next step recommendations by interpreting report texts.\nResults from Automated Radiology Report Mining:\n- Nuance AI: Natural language processing accurately inserted follow-up recommendations into 9% more radiology reports.\n- Qure.ai: Machine learning autogenerated impressions for CT head scans that agreed with radiologists\u2019 conclusions in 89% of cases.\n- Aidoc and Mount Sinai: AI analysis of reports recommended subsequent diagnostic mammograms with 95% precision.\nAutomating rote components of report writing increases radiologist productivity.\nUse Case #10: Sepsis Early Warning and Risk Scoring Systems\nRapid intervention is critical for sepsis patients, but nurses struggle detecting subtle vital sign changes foreshadowing deterioration. AI models provide early warnings by continuously monitoring data.\nOutcomes from Sepsis Prediction Models:\n- Epic AI and UPMC: Machine learning identified inpatient sepsis 6 hours earlier than current protocols, enabling rapid response.\n- Kaiser Permanente: AI sepsis alert system increased recognition of impending severe sepsis cases by 21%.\n- Dascena and Pfizer: Optimized machine learning model predicted sepsis progression with 95% accuracy from EMR data.\nEarly AI-generated sepsis alerts enable rapid initiation of treatment to prevent severe blood infections.\nUse Case #11: Optimizing Hospital Nursing Staff Models\nInefficient nurse staffing lowers care quality and raises costs from overwork and turnover. But finding the right team mix is imprecise. AI-optimized models factor in patient volumes, acuity, and trends for smarter planning.\nResults from AI Nurse Staffing:\n- Optimum Healthcare IT: Hospital units using AI-assisted nurse planning realized 10-15% lower staffing costs and 7.5% higher patient satisfaction rates.\n- GE Healthcare: Machine learning predicted optimal ICU staffing levels resulting in $700,000 hospital cost savings.\n- Mayo Clinic: Natural language processing of nursing notes helped quantify workload levels across units to calibrate teams.\nAI transforms nurse staffing from an estimation exercise to precise, data-driven models benefiting cost, care, and clinician experience.\nUse Case #12: Automating Patient-Reported Outcome Collection\nPatient-reported outcomes are crucial care quality measures but collecting PROMs manually is burdensome. AI chatbots engage patients digitally through tailored question branching while tracking longitudinal progress.\nOutcomes from Automated AI Chatbots for PROMs:\n- Snapdragon Healthcare and Intermountain Healthcare: AI chatbot increased patient engagement on post-discharge PROMs by 45%.\n- Basal Analytics: Machine learning chatbot attained 300% more patient responses on PROM surveys compared to email follow-up.\n- Kaia Health: Digital physiotherapy platform employing AI saw high adherence, with 91% of patients completing exercise PROMs.\nAutomating PROM capture boosts response rates while reducing demands on clinicians.\nSummary: 12 Real-World Use Cases in Healthcare AI\nThese real-world examples showcase AI\u2019s expansive applicability throughout healthcare from clinical specialties to operational and financial functions. Quantifiable outcomes (increased early diagnosis rates, reduced readmissions, higher revenue, accelerated drug development, and more) prove AI is maturing past pilot projects into scalable solutions delivering tangible care improvements.\nWhile integrating any new technology requires adaptivity and expertise, the measurable benefits underscore how AI-enabled tools realize their promises. Through following an ethical approach prioritizing patient wellbeing over profits, health systems can unlock AI\u2019s immense potential to heal and connect at scale. The opportunities of artificial intelligence to boost care quality, experiences, and access are too vast for healthcare to ignore.\nMedwave assists medical providers in their quest to implement effective AI billing and coding.",
    "scraped_at":"2025-07-07T18:26:01.477118"
  },
  {
    "topic":"AI in healthcare",
    "title":"Generative AI in healthcare: Current trends and future outlook",
    "url":"https:\/\/www.mckinsey.com\/industries\/healthcare\/our-insights\/generative-ai-in-healthcare-current-trends-and-future-outlook",
    "domain":"www.mckinsey.com",
    "snippet":"Gen AI is rapidly transforming the healthcare industry. To understand the changing landscape, McKinsey has surveyed healthcare leaders since 2023 about their perspectives and approaches to gen AI (see sidebar, \u201cResearch methodology\u201d). The latest survey, conducted in the fourth quarter of 2024, found...",
    "content":"Gen AI is rapidly transforming the healthcare industry. To understand the changing landscape, McKinsey has surveyed healthcare leaders since 2023 about their perspectives and approaches to gen AI (see sidebar, \u201cResearch methodology\u201d).\nThe latest survey, conducted in the fourth quarter of 2024, found that 85 percent of respondents\u2014healthcare leaders from payers, health systems, and healthcare services and technology (HST) groups\u2014were exploring or had already adopted gen AI capabilities.\nThis survey targeted 150 US healthcare leaders across subsectors and builds on similar samples of 100 leaders from the first and second quarters of 2024 and the fourth quarter of 2023. From the responses, four distinct themes emerged.\nAdoption and implementation\nThe majority of respondents to the fourth quarter 2024 survey said their organizations have either implemented gen AI use cases or begun to develop proofs of concept. More respondents were in the implementation stage than in the proof-of-concept stage, which suggests that organizations are successfully advancing their gen AI investments. However, 15 percent of respondents had not yet started to develop proof-of-concept use cases. These respondents\u2019 organizations could fall behind if they build out their capabilities slowly while early adopters progress their capabilities more quickly and realize the impact from their investments.\nPartnerships and hyperscalers\nAmong respondents who are implementing gen AI, partnerships are the dominant strategy for adoption, with 61 percent saying they intend to pursue partnerships with third-party vendors to develop customized solutions as their primary strategy. In comparison, 20 percent of respondents said they intend to build gen AI capabilities in-house, and 19 percent said they intend to buy off-the-shelf solutions. Of respondents across subsectors choosing to partner, 58 percent are looking to their existing IT solution partners to fill this role, and 46 percent are also exploring partnerships with hyperscalers, driven by these vendors\u2019 expertise in data management.\nThe scope of gen AI\nGen AI may create tremendous value in areas that could fundamentally improve patient experience and streamline operations to generate cost savings. Respondents across subsectors said gen AI\u2019s greatest source of potential could be in improving administrative efficiency and clinical productivity. Many respondents also recognize opportunities in patient or member engagement and IT or infrastructure, suggesting a wide breadth of gen AI use cases.\nQuantifying impact\nMany of the respondents who said their organizations are progressing to implement gen AI capabilities also said they are looking to quantify the impact of their investments. Of respondents that have already implemented gen AI use cases, 64 percent reported that they anticipated or had already quantified positive ROI, suggesting high expectations for gen AI technology.\nStakeholders in the healthcare industry are seeking ways to create value and reduce costs across domains, providing ample opportunity for the use of gen AI. Despite the complexities of evolving regulation, risk compliance, and internal capability gaps, responses from this recent survey suggest that more payers, health systems, and HST organizations are progressing to implement use cases across functions. What\u2019s more, many healthcare leaders are looking to fill the gaps in their capabilities by pursuing partnerships that allow them to bring in outside talent while maintaining flexibility and customization in AI solutions. Partnerships with hyperscalers that have data capabilities could help ensure successful implementations.\nRespondents\u2019 early use cases with gen AI have focused on improving administrative efficiency, addressing IT and infrastructure gaps, and increasing clinical productivity. As competencies mature, more use cases could become worthwhile, including external engagements with patients or members and quality-of-care use cases, which could further improve patient and member experiences overall. Leaders agree that risk management in implementing AI is important, and considering an AI governance approach will be important to advance these efforts safely.\nSo far, organizations that have developed their capabilities and appropriately targeted their gen AI efforts have had the most success achieving at-scale implementation. The development of gen AI remains important to success in the healthcare space, and leaders can consider how to position their organizations for the future. Successful implementations will require a value-driven strategy, strong delivery capabilities, and robust organizational management.",
    "scraped_at":"2025-07-07T18:26:01.762538"
  },
  {
    "topic":"AI in healthcare",
    "title":"How Digital & AI Will Reshape Health Care in 2025 | BCG",
    "url":"https:\/\/www.bcg.com\/publications\/2025\/digital-ai-solutions-reshape-health-care-2025",
    "domain":"www.bcg.com",
    "snippet":"The definition of digital health is evolving. The era spurred on by the Covid-19 pandemic\u2014think telemedicine and digital therapeutics, which have struggled to scale\u2014is giving way to one defined by artificial intelligence (AI) and solutions that strengthen the bond between health care professionals a...",
    "content":"The definition of digital health is evolving. The era spurred on by the Covid-19 pandemic\u2014think telemedicine and digital therapeutics, which have struggled to scale\u2014is giving way to one defined by artificial intelligence (AI) and solutions that strengthen the bond between health care professionals and patients in an integrated manner, with appropriate economics to support them.\nWe see this shift reflected in trends that experts across BCG and BCG X anticipate will shape digital health in 2025. As AI matures, it is rapidly expanding possibilities for patients, providers, and health care organizations alike. New digital solutions are being leveraged to address gaps in care for chronic conditions such as heart failure, diabetes, and mental health. And the growing influence of generative AI (GenAI) on every aspect of health care\u2014from personalized care to automated workflows\u2014is a key theme for the upcoming year, as it was in 2024 .\nLet\u2019s dive deeper into how we expect digital and AI solutions to reshape health care in 2025.\nPatient Support\nThis year, digital health tools will continue to transform patient care, improving their support and access. Smart implants and wearable devices that allow providers to monitor patients\u2019 cardiac activity, blood sugar levels, and other biological functions in real time from remote locations will enable better chronic disease management and improve patients\u2019 quality of life. As sleep continues to gain attention as a crucial biomarker for overall well-being, health tech companies are creating more advanced, accurate sleep-tracking tools.\nA growing number of individually tailored apps and digital platforms will give patients more control over their medical conditions, predict flare-ups, and suggest real-time interventions. We expect consumers to increasingly rely on AI chatbots and virtual assistants for answers to health questions.\nDigital health will continue to offer solutions to address gaps in women\u2019s health care, including femtech innovations to redesign traditional \u201chardware\u201d used for women\u2019s health (such as the speculum), with the female experience at the center. It\u2019s a needed shift: A recent BCG X survey found that fewer than half of women respondents across the globe (41%) agreed that there are sufficient services to address their specific health concerns.\nWe are also beginning to see a maturing of partnerships between femtech health and wellness brands that can lead to interoperable ecosystems that pool women\u2019s health data and ultimately drive improved health outcomes.\nSubscribe to our Health Care Industry E-Alert.\nProvider Empowerment\nProviders will be empowered and enabled by digital technology as well. Artificial intelligence can provide the analytical muscle to process vast quantities of personal patient data, powering highly personalized medical treatment tailored to individuals based on their unique health data from continuous monitoring devices, lifestyle inputs, and individual genetics. This enables providers to adjust treatment dynamically based on feedback in real time.\nArtificial intelligence decision-making tools will become mainstream in 2025, giving doctors immediate access to evidence-based research and treatment guidelines. GenAI applications will accelerate diagnoses and minimize diagnostic errors, while speeding the delivery of patient care and more accurately predicting patient outcomes.\nEmergence of Ecosystems\nAt the organizational level, our experts anticipate that the coming year will see an expansion of the use of AI to organize and automate entire workflows instead of just specific tasks. For example, rather than an AI tool that facilitates physician note-taking or scheduling, intelligent agents will automate an entire patient episode of care, from intake through treatment plan. Working across departments, AI programs will learn as they go, improving efficiency and outcomes at both the patient and system level. Health systems will benefit, but so will other types of health care organizations such as pharmaceutical companies, where GenAI can transform key activities such as clinical trials and regulatory submissions.\nAI-driven data processing will also allow access to data that has until now been considered too disorganized to be useful, such as medical records, clinical notes, and physician\/patient interaction information. Clinicians, payers, and drug companies alike will be able to draw out actionable insights from these data sets to improve patient care and outcomes. At the same time, expanded access will enhance different systems\u2019 ability to interact with one another, facilitating more seamless collaboration.\nWhile GenAI continues to generate tremendous excitement in the digital health care space, it\u2019s not a panacea. Our experts recognize that some of these programs won\u2019t deliver anticipated results in 2025. When that happens, we emphasize the importance of going back to the basics: focusing on business outcomes and tracking key performance indicators. In this way, AI failures can drive more focused, sustainable transformation in the long term.\nClearly, 2025 promises to be a transformative year. We\u2019re excited to see how AI and more digital tools reshape health care.\nRead the full report for more insights from our global team of experts.",
    "scraped_at":"2025-07-07T18:26:03.213517"
  },
  {
    "topic":"AI in healthcare",
    "title":"The potential for artificial intelligence in healthcare - PMC",
    "url":"https:\/\/pmc.ncbi.nlm.nih.gov\/articles\/PMC6616181\/",
    "domain":"pmc.ncbi.nlm.nih.gov",
    "snippet":"ABSTRACT The complexity and rise of data in healthcare means that artificial intelligence (AI) will increasingly be applied within the field. Several types of AI are already being employed by payers and providers of care, and life sciences companies. The key categories of applications involve diagno...",
    "content":"ABSTRACT\nThe complexity and rise of data in healthcare means that artificial intelligence (AI) will increasingly be applied within the field. Several types of AI are already being employed by payers and providers of care, and life sciences companies. The key categories of applications involve diagnosis and treatment recommendations, patient engagement and adherence, and administrative activities. Although there are many instances in which AI can perform healthcare tasks as well or better than humans, implementation factors will prevent large-scale automation of healthcare professional jobs for a considerable period. Ethical issues in the application of AI to healthcare are also discussed.\nKEYWORDS: Artificial intelligence, clinical decision support, electronic health record systems\nIntroduction\nArtificial intelligence (AI) and related technologies are increasingly prevalent in business and society, and are beginning to be applied to healthcare. These technologies have the potential to transform many aspects of patient care, as well as administrative processes within provider, payer and pharmaceutical organisations.\nThere are already a number of research studies suggesting that AI can perform as well as or better than humans at key healthcare tasks, such as diagnosing disease. Today, algorithms are already outperforming radiologists at spotting malignant tumours, and guiding researchers in how to construct cohorts for costly clinical trials. However, for a variety of reasons, we believe that it will be many years before AI replaces humans for broad medical process domains. In this article, we describe both the potential that AI offers to automate aspects of care and some of the barriers to rapid implementation of AI in healthcare.\nTypes of AI of relevance to healthcare\nArtificial intelligence is not one technology, but rather a collection of them. Most of these technologies have immediate relevance to the healthcare field, but the specific processes and tasks they support vary widely. Some particular AI technologies of high importance to healthcare are defined and described below.\nMachine learning \u2013 neural networks and deep learning\nMachine learning is a statistical technique for fitting models to data and to \u2018learn\u2019 by training models with data. Machine learning is one of the most common forms of AI; in a 2018 Deloitte survey of 1,100 US managers whose organisations were already pursuing AI, 63% of companies surveyed were employing machine learning in their businesses.1 It is a broad technique at the core of many approaches to AI and there are many versions of it.\nIn healthcare, the most common application of traditional machine learning is precision medicine \u2013 predicting what treatment protocols are likely to succeed on a patient based on various patient attributes and the treatment context.2 The great majority of machine learning and precision medicine applications require a training dataset for which the outcome variable (eg onset of disease) is known; this is called supervised learning.\nA more complex form of machine learning is the neural network \u2013 a technology that has been available since the 1960s has been well established in healthcare research for several decades3 and has been used for categorisation applications like determining whether a patient will acquire a particular disease. It views problems in terms of inputs, outputs and weights of variables or \u2018features\u2019 that associate inputs with outputs. It has been likened to the way that neurons process signals, but the analogy to the brain's function is relatively weak.\nThe most complex forms of machine learning involve deep learning, or neural network models with many levels of features or variables that predict outcomes. There may be thousands of hidden features in such models, which are uncovered by the faster processing of today's graphics processing units and cloud architectures. A common application of deep learning in healthcare is recognition of potentially cancerous lesions in radiology images.4 Deep learning is increasingly being applied to radiomics, or the detection of clinically relevant features in imaging data beyond what can be perceived by the human eye.5 Both radiomics and deep learning are most commonly found in oncology-oriented image analysis. Their combination appears to promise greater accuracy in diagnosis than the previous generation of automated tools for image analysis, known as computer-aided detection or CAD.\nDeep learning is also increasingly used for speech recognition and, as such, is a form of natural language processing (NLP), described below. Unlike earlier forms of statistical analysis, each feature in a deep learning model typically has little meaning to a human observer. As a result, the explanation of the model's outcomes may be very difficult or impossible to interpret.\nNatural language processing\nMaking sense of human language has been a goal of AI researchers since the 1950s. This field, NLP, includes applications such as speech recognition, text analysis, translation and other goals related to language. There are two basic approaches to it: statistical and semantic NLP. Statistical NLP is based on machine learning (deep learning neural networks in particular) and has contributed to a recent increase in accuracy of recognition. It requires a large \u2018corpus\u2019 or body of language from which to learn.\nIn healthcare, the dominant applications of NLP involve the creation, understanding and classification of clinical documentation and published research. NLP systems can analyse unstructured clinical notes on patients, prepare reports (eg on radiology examinations), transcribe patient interactions and conduct conversational AI.\nRule-based expert systems\nExpert systems based on collections of \u2018if-then\u2019 rules were the dominant technology for AI in the 1980s and were widely used commercially in that and later periods. In healthcare, they were widely employed for \u2018clinical decision support\u2019 purposes over the last couple of decades5 and are still in wide use today. Many electronic health record (EHR) providers furnish a set of rules with their systems today.\nExpert systems require human experts and knowledge engineers to construct a series of rules in a particular knowledge domain. They work well up to a point and are easy to understand. However, when the number of rules is large (usually over several thousand) and the rules begin to conflict with each other, they tend to break down. Moreover, if the knowledge domain changes, changing the rules can be difficult and time-consuming. They are slowly being replaced in healthcare by more approaches based on data and machine learning algorithms.\nPhysical robots\nPhysical robots are well known by this point, given that more than 200,000 industrial robots are installed each year around the world. They perform pre-defined tasks like lifting, repositioning, welding or assembling objects in places like factories and warehouses, and delivering supplies in hospitals. More recently, robots have become more collaborative with humans and are more easily trained by moving them through a desired task. They are also becoming more intelligent, as other AI capabilities are being embedded in their \u2018brains\u2019 (really their operating systems). Over time, it seems likely that the same improvements in intelligence that we've seen in other areas of AI would be incorporated into physical robots.\nSurgical robots, initially approved in the USA in 2000, provide \u2018superpowers\u2019 to surgeons, improving their ability to see, create precise and minimally invasive incisions, stitch wounds and so forth.6 Important decisions are still made by human surgeons, however. Common surgical procedures using robotic surgery include gynaecologic surgery, prostate surgery and head and neck surgery.\nRobotic process automation\nThis technology performs structured digital tasks for administrative purposes, ie those involving information systems, as if they were a human user following a script or rules. Compared to other forms of AI they are inexpensive, easy to program and transparent in their actions. Robotic process automation (RPA) doesn't really involve robots \u2013 only computer programs on servers. It relies on a combination of workflow, business rules and \u2018presentation layer\u2019 integration with information systems to act like a semi-intelligent user of the systems. In healthcare, they are used for repetitive tasks like prior authorisation, updating patient records or billing. When combined with other technologies like image recognition, they can be used to extract data from, for example, faxed images in order to input it into transactional systems.7\nWe've described these technologies as individual ones, but increasingly they are being combined and integrated; robots are getting AI-based \u2018brains\u2019, image recognition is being integrated with RPA. Perhaps in the future these technologies will be so intermingled that composite solutions will be more likely or feasible.\nDiagnosis and treatment applications\nDiagnosis and treatment of disease has been a focus of AI since at least the 1970s, when MYCIN was developed at Stanford for diagnosing blood-borne bacterial infections.8 This and other early rule-based systems showed promise for accurately diagnosing and treating disease, but were not adopted for clinical practice. They were not substantially better than human diagnosticians, and they were poorly integrated with clinician workflows and medical record systems.\nMore recently, IBM's Watson has received considerable attention in the media for its focus on precision medicine, particularly cancer diagnosis and treatment. Watson employs a combination of machine learning and NLP capabilities. However, early enthusiasm for this application of the technology has faded as customers realised the difficulty of teaching Watson how to address particular types of cancer9 and of integrating Watson into care processes and systems.10 Watson is not a single product but a set of \u2018cognitive services\u2019 provided through application programming interfaces (APIs), including speech and language, vision, and machine learning-based data-analysis programs. Most observers feel that the Watson APIs are technically capable, but taking on cancer treatment was an overly ambitious objective. Watson and other proprietary programs have also suffered from competition with free \u2018open source\u2019 programs provided by some vendors, such as Google's TensorFlow.\nImplementation issues with AI bedevil many healthcare organisations. Although rule-based systems incorporated within EHR systems are widely used, including at the NHS,11 they lack the precision of more algorithmic systems based on machine learning. These rule-based clinical decision support systems are difficult to maintain as medical knowledge changes and are often not able to handle the explosion of data and knowledge based on genomic, proteomic, metabolic and other \u2018omic-based\u2019 approaches to care.\nThis situation is beginning to change, but it is mostly present in research labs and in tech firms, rather than in clinical practice. Scarcely a week goes by without a research lab claiming that it has developed an approach to using AI or big data to diagnose and treat a disease with equal or greater accuracy than human clinicians. Many of these findings are based on radiological image analysis,12 though some involve other types of images such as retinal scanning13 or genomic-based precision medicine.14 Since these types of findings are based on statistically-based machine learning models, they are ushering in an era of evidence- and probability-based medicine, which is generally regarded as positive but brings with it many challenges in medical ethics and patient\/clinician relationships.15\nTech firms and startups are also working assiduously on the same issues. Google, for example, is collaborating with health delivery networks to build prediction models from big data to warn clinicians of high-risk conditions, such as sepsis and heart failure.16 Google, Enlitic and a variety of other startups are developing AI-derived image interpretation algorithms. Jvion offers a \u2018clinical success machine\u2019 that identifies the patients most at risk as well as those most likely to respond to treatment protocols. Each of these could provide decision support to clinicians seeking to find the best diagnosis and treatment for patients.\nThere are also several firms that focus specifically on diagnosis and treatment recommendations for certain cancers based on their genetic profiles. Since many cancers have a genetic basis, human clinicians have found it increasingly complex to understand all genetic variants of cancer and their response to new drugs and protocols. Firms like Foundation Medicine and Flatiron Health, both now owned by Roche, specialise in this approach.\nBoth providers and payers for care are also using \u2018population health\u2019 machine learning models to predict populations at risk of particular diseases17 or accidents18 or to predict hospital readmission.19 These models can be effective at prediction, although they sometimes lack all the relevant data that might add predictive capability, such as patient socio-economic status.\nBut whether rules-based or algorithmic in nature, AI-based diagnosis and treatment recommendations are sometimes challenging to embed in clinical workflows and EHR systems. Such integration issues have probably been a greater barrier to broad implementation of AI than any inability to provide accurate and effective recommendations; and many AI-based capabilities for diagnosis and treatment from tech firms are standalone in nature or address only a single aspect of care. Some EHR vendors have begun to embed limited AI functions (beyond rule-based clinical decision support) into their offerings,20 but these are in the early stages. Providers will either have to undertake substantial integration projects themselves or wait until EHR vendors add more AI capabilities.\nPatient engagement and adherence applications\nPatient engagement and adherence has long been seen as the \u2018last mile\u2019 problem of healthcare \u2013 the final barrier between ineffective and good health outcomes. The more patients proactively participate in their own well-being and care, the better the outcomes \u2013 utilisation, financial outcomes and member experience. These factors are increasingly being addressed by big data and AI.\nProviders and hospitals often use their clinical expertise to develop a plan of care that they know will improve a chronic or acute patient's health. However, that often doesn't matter if the patient fails to make the behavioural adjustment necessary, eg losing weight, scheduling a follow-up visit, filling prescriptions or complying with a treatment plan. Noncompliance \u2013 when a patient does not follow a course of treatment or take the prescribed drugs as recommended \u2013 is a major problem.\nIn a survey of more than 300 clinical leaders and healthcare executives, more than 70% of the respondents reported having less than 50% of their patients highly engaged and 42% of respondents said less than 25% of their patients were highly engaged.21\nIf deeper involvement by patients results in better health outcomes, can AI-based capabilities be effective in personalising and contextualising care? There is growing emphasis on using machine learning and business rules engines to drive nuanced interventions along the care continuum.22 Messaging alerts and relevant, targeted content that provoke actions at moments that matter is a promising field in research.\nAnother growing focus in healthcare is on effectively designing the \u2018choice architecture\u2019 to nudge patient behaviour in a more anticipatory way based on real-world evidence. Through information provided by provider EHR systems, biosensors, watches, smartphones, conversational interfaces and other instrumentation, software can tailor recommendations by comparing patient data to other effective treatment pathways for similar cohorts. The recommendations can be provided to providers, patients, nurses, call-centre agents or care delivery coordinators.\nAdministrative applications\nThere are also a great many administrative applications in healthcare. The use of AI is somewhat less potentially revolutionary in this domain as compared to patient care, but it can provide substantial efficiencies. These are needed in healthcare because, for example, the average US nurse spends 25% of work time on regulatory and administrative activities.23 The technology that is most likely to be relevant to this objective is RPA. It can be used for a variety of applications in healthcare, including claims processing, clinical documentation, revenue cycle management and medical records management.24\nSome healthcare organisations have also experimented with chatbots for patient interaction, mental health and wellness, and telehealth. These NLP-based applications may be useful for simple transactions like refilling prescriptions or making appointments. However, in a survey of 500 US users of the top five chatbots used in healthcare, patients expressed concern about revealing confidential information, discussing complex health conditions and poor usability.25\nAnother AI technology with relevance to claims and payment administration is machine learning, which can be used for probabilistic matching of data across different databases. Insurers have a duty to verify whether the millions of claims are correct. Reliably identifying, analysing and correcting coding issues and incorrect claims saves all stakeholders \u2013 health insurers, governments and providers alike \u2013 a great deal of time, money and effort. Incorrect claims that slip through the cracks constitute significant financial potential waiting to be unlocked through data-matching and claims audits.\nImplications for the healthcare workforce\nThere has been considerable attention to the concern that AI will lead to automation of jobs and substantial displacement of the workforce. A Deloitte collaboration with the Oxford Martin Institute26 suggested that 35% of UK jobs could be automated out of existence by AI over the next 10 to 20 years. Other studies have suggested that while some automation of jobs is possible, a variety of external factors other than technology could limit job loss, including the cost of automation technologies, labour market growth and cost, benefits of automation beyond simple labour substitution, and regulatory and social acceptance.27 These factors might restrict actual job loss to 5% or less.\nTo our knowledge thus far there have been no jobs eliminated by AI in health care. The limited incursion of AI into the industry thus far, and the difficulty of integrating AI into clinical workflows and EHR systems, have been somewhat responsible for the lack of job impact. It seems likely that the healthcare jobs most likely to be automated would be those that involve dealing with digital information, radiology and pathology for example, rather than those with direct patient contact.28\nBut even in jobs like radiologist and pathologist, the penetration of AI into these fields is likely to be slow. Even though, as we have argued, technologies like deep learning are making inroads into the capability to diagnose and categorise images, there are several reasons why radiology jobs, for example, will not disappear soon.29\nFirst, radiologists do more than read and interpret images. Like other AI systems, radiology AI systems perform single tasks. Deep learning models in labs and startups are trained for specific image recognition tasks (such as nodule detection on chest computed tomography or hemorrhage on brain magnetic resonance imaging). However, thousands of such narrow detection tasks are necessary to fully identify all potential findings in medical images, and only a few of these can be done by AI today. Radiologists also consult with other physicians on diagnosis and treatment, treat diseases (for example providing local ablative therapies) and perform image-guided medical interventions such as cancer biopsies and vascular stents (interventional radiology), define the technical parameters of imaging examinations to be performed (tailored to the patient's condition), relate findings from images to other medical records and test results, discuss procedures and results with patients, and many other activities.\nSecond, clinical processes for employing AI-based image work are a long way from being ready for daily use. Different imaging technology vendors and deep learning algorithms have different foci: the probability of a lesion, the probability of cancer, a nodule's feature or its location. These distinct foci would make it very difficult to embed deep learning systems into current clinical practice.\nThird, deep learning algorithms for image recognition require \u2018labelled data\u2019 \u2013 millions of images from patients who have received a definitive diagnosis of cancer, a broken bone or other pathology. However, there is no aggregated repository of radiology images, labelled or otherwise.\nFinally, substantial changes will be required in medical regulation and health insurance for automated image analysis to take off.\nSimilar factors are present for pathology and other digitally-oriented aspects of medicine. Because of them, we are unlikely to see substantial change in healthcare employment due to AI over the next 20 years or so. There is also the possibility that new jobs will be created to work with and to develop AI technologies. But static or increasing human employment also mean, of course, that AI technologies are not likely to substantially reduce the costs of medical diagnosis and treatment over that timeframe.\nEthical implications\nFinally, there are also a variety of ethical implications around the use of AI in healthcare. Healthcare decisions have been made almost exclusively by humans in the past, and the use of smart machines to make or assist with them raises issues of accountability, transparency, permission and privacy.\nPerhaps the most difficult issue to address given today's technologies is transparency. Many AI algorithms \u2013 particularly deep learning algorithms used for image analysis \u2013 are virtually impossible to interpret or explain. If a patient is informed that an image has led to a diagnosis of cancer, he or she will likely want to know why. Deep learning algorithms, and even physicians who are generally familiar with their operation, may be unable to provide an explanation.\nMistakes will undoubtedly be made by AI systems in patient diagnosis and treatment and it may be difficult to establish accountability for them. There are also likely to be incidents in which patients receive medical information from AI systems that they would prefer to receive from an empathetic clinician. Machine learning systems in healthcare may also be subject to algorithmic bias, perhaps predicting greater likelihood of disease on the basis of gender or race when those are not actually causal factors.30\nWe are likely to encounter many ethical, medical, occupational and technological changes with AI in healthcare. It is important that healthcare institutions, as well as governmental and regulatory bodies, establish structures to monitor key issues, react in a responsible manner and establish governance mechanisms to limit negative implications. This is one of the more powerful and consequential technologies to impact human societies, so it will require continuous attention and thoughtful policy for many years.\nThe future of AI in healthcare\nWe believe that AI has an important role to play in the healthcare offerings of the future. In the form of machine learning, it is the primary capability behind the development of precision medicine, widely agreed to be a sorely needed advance in care. Although early efforts at providing diagnosis and treatment recommendations have proven challenging, we expect that AI will ultimately master that domain as well. Given the rapid advances in AI for imaging analysis, it seems likely that most radiology and pathology images will be examined at some point by a machine. Speech and text recognition are already employed for tasks like patient communication and capture of clinical notes, and their usage will increase.\nThe greatest challenge to AI in these healthcare domains is not whether the technologies will be capable enough to be useful, but rather ensuring their adoption in daily clinical practice. For widespread adoption to take place, AI systems must be approved by regulators, integrated with EHR systems, standardised to a sufficient degree that similar products work in a similar fashion, taught to clinicians, paid for by public or private payer organisations and updated over time in the field. These challenges will ultimately be overcome, but they will take much longer to do so than it will take for the technologies themselves to mature. As a result, we expect to see limited use of AI in clinical practice within 5 years and more extensive use within 10.\nIt also seems increasingly clear that AI systems will not replace human clinicians on a large scale, but rather will augment their efforts to care for patients. Over time, human clinicians may move toward tasks and job designs that draw on uniquely human skills like empathy, persuasion and big-picture integration. Perhaps the only healthcare providers who will lose their jobs over time may be those who refuse to work alongside artificial intelligence.\nReferences\n- 1.Deloitte Insights State of AI in the enterprise. Deloitte, 2018. www2.deloitte.com\/content\/dam\/insights\/us\/articles\/4780_State-of-AI-in-the-enterprise\/AICognitiveSurvey2018_Infographic.pdf. [Google Scholar]\n- 2.Lee SI, Celik S, Logsdon BA, et al. A machine learning approach to integrate big data for precision medicine in acute myeloid leukemia. Nat Commun 2018;9:42. [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 3.Sordo M. Introduction to neural networks in healthcare. OpenClinical, 2002. www.openclinical.org\/docs\/int\/neuralnetworks011.pdf [Google Scholar]\n- 4.Fakoor R, Ladhak F, Nazi A, Huber M. Using deep learning to enhance cancer diagnosis and classification. A conference presentation The 30th International Conference on Machine Learning, 2013. [Google Scholar]\n- 5.Vial A, Stirling D, Field M, et al. The role of deep learning and radiomic feature extraction in cancer-specific predictive modelling: a review. Transl Cancer Res 2018;7:803\u201316. [Google Scholar]\n- 6.Davenport TH, Glaser J. Just-in-time delivery comes to knowledge management. Harvard Business Review 2002. https:\/\/hbr.org\/2002\/07\/just-in-time-delivery-comes-to-knowledge-management. [PubMed] [Google Scholar]\n- 7.Hussain A, Malik A, Halim MU, Ali AM. The use of robotics in surgery: a review. Int J Clin Pract 2014;68:1376\u201382. [DOI] [PubMed] [Google Scholar]\n- 8.Bush J. How AI is taking the scut work out of health care. Harvard Business Review 2018. https:\/\/hbr.org\/2018\/03\/how-ai-is-taking-the-scut-work-out-of-health-care. [Google Scholar]\n- 9.Buchanan BG, Shortliffe EH. Rule-based expert systems: The MYCIN experiments of the Stanford heuristic programming project. Reading: Addison Wesley, 1984. [Google Scholar]\n- 10.Ross C, Swetlitz I. IBM pitched its Watson supercomputer as a revolution in cancer care. It's nowhere close. Stat 2017. www.statnews.com\/2017\/09\/05\/watson-ibm-cancer. [Google Scholar]\n- 11.Davenport TH. The AI Advantage. Cambridge: MIT Press, 2018. [Google Scholar]\n- 12.Right Care Shared Decision Making Programme, Capita. Measuring shared decision making: A review of research evidence. NHS, 2012. www.england.nhs.uk\/wp-content\/uploads\/2013\/08\/7sdm-report.pdf. [Google Scholar]\n- 13.Loria K. Putting the AI in radiology. Radiology Today 2018;19:10 www.radiologytoday.net\/archive\/rt0118p10.shtml. [Google Scholar]\n- 14.Schmidt-Erfurth U, Bogunovic H, Sadeghipour A, et al. Machine learning to analyze the prognostic value of current imaging biomarkers in neovascular age-related macular degeneration. Opthamology Retina 2018;2:24\u201330. [DOI] [PubMed] [Google Scholar]\n- 15.Aronson S, Rehm H. Building the foundation for genomic-based precision medicine. Nature 2015;526:336\u201342. [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 16.Rysavy M. Evidence-based medicine: A science of uncertainty and an art of probability. Virtual Mentor 2013;15:4\u20138. [DOI] [PubMed] [Google Scholar]\n- 17.Rajkomar A, Oren E, Chen K, et al. Scalable and accurate deep learning with electronic health records. npj Digital Medicine 2018;1:18 www.nature.com\/articles\/s41746-018-0029-1. [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 18.Shimabukuro D, Barton CW, Feldman MD, Mataraso SJ, Das R. Effect of a machine learning-based severe sepsis prediction algorithm on patient survival and hospital length of stay: a randomised clinical trial. BMJ Open Respir Res 2017;4:e000234. [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 19.Aicha AN, Englebienne G, van Schooten KS, Pijnappels M, Kr\u00f6se B. Deep learning to predict falls in older adults based on daily-Life trunk accelerometry. Sensors 2018;18:1654. [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 20.Low LL, Lee KH, Ong MEH, et al. Predicting 30-Day readmissions: performance of the LACE index compared with a regression model among general medicine patients in Singapore. Biomed Research International 2015;2015;169870. [DOI] [PMC free article] [PubMed] [Google Scholar]\n- 21.Davenport TH, Hongsermeier T, Mc Cord KA. Using AI to improve electronic health records. Harvard Business Review 2018. https:\/\/hbr.org\/2018\/12\/using-ai-to-improve-electronic-health-records. [Google Scholar]\n- 22.Volpp K, Mohta S. Improved engagement leads to better outcomes, but better tools are needed. Insights Report. NEJM Catalyst, 2016, https:\/\/catalyst.nejm.org\/patient-engagement-report-improved-engagement-leads-better-outcomes-better-tools-needed. [Google Scholar]\n- 23.Berg S. Nudge theory explored to boost medication adherence. Chicago: American Medical Association, 2018. www.ama-assn.org\/delivering-care\/patient-support-advocacy\/nudge-theory-explored-boost-medication-adherence. [Google Scholar]\n- 24.Commins J. Nurses say distractions cut bedside time by 25%. HealthLeaders, 2010. www.healthleadersmedia.com\/nursing\/nurses-say-distractions-cut-bedside-time-25. [Google Scholar]\n- 25.Utermohlen K. Four robotic process automation (RPA) applications in the healthcare industry. Medium, 2018. https:\/\/medium.com\/@karl.utermohlen\/4-robotic-process-automation-rpa-applications-in-the-healthcare-industry-4d449b24b613 [Google Scholar]\n- 26.UserTesting Healthcare chatbot apps are on the rise but the overall customer experience (cx) falls short according to a UserTesting report. San Francisco: UserTesting, 2019. [Google Scholar]\n- 27.Deloitte From brawn to brains: The impact of technology on jobs in the UK. Deloitte, 2015. www2.deloitte.com\/content\/dam\/Deloitte\/uk\/Documents\/Growth\/deloitte-uk-insights-from-brawns-to-brain.pdf. [Google Scholar]\n- 28.McKinsey Global Institute A future that works: automation, employment, and productivity. McKinsey Global Institute, 2017. www.mckinsey.com\/\u223c\/media\/mckinsey\/featured%20insights\/Digital%20Disruption\/Harnessing%20automation%20for%20a%20future%20that%20works\/MGI-A-future-that-works-Executive-summary.ashx. [Google Scholar]\n- 29.Davenport TH, Kirby J. Only humans need apply: Winners and losers in the age of smart machines. New York: HarperBusiness, 2016. [Google Scholar]\n- 30.Davenport TH, Dreyer K. AI will change radiology, but it won't replace radiologists. Harvard Business Review 2018. https:\/\/hbr.org\/2018\/03\/ai-will-change-radiology-but-it-wont-replace-radiologists. [Google Scholar]\n- 31.Char DS, Shah NH, Magnus D. Implementing machine learning in health care \u2013 addressing ethical challenges. N Engl J Med 2018;378:981\u20133. [DOI] [PMC free article] [PubMed] [Google Scholar]",
    "scraped_at":"2025-07-07T18:26:03.470084"
  },
  {
    "topic":"AI in healthcare",
    "title":"Transformative Potential of AI in Healthcare: Definitions, \u2026",
    "url":"https:\/\/pubmed.ncbi.nlm.nih.gov\/38255014\/",
    "domain":"pubmed.ncbi.nlm.nih.gov",
    "snippet":"Transformative Potential of AI in Healthcare: Definitions, Applications, and Navigating the Ethical Landscape and Public Perspectives - PMID: 38255014 - PMCID: PMC10815906 - DOI: 10.3390\/healthcare12020125 Transformative Potential of AI in Healthcare: Definitions, Applications, and Navigating the Et...",
    "content":"Transformative Potential of AI in Healthcare: Definitions, Applications, and Navigating the Ethical Landscape and Public Perspectives\n- PMID: 38255014\n- PMCID: PMC10815906\n- DOI: 10.3390\/healthcare12020125\nTransformative Potential of AI in Healthcare: Definitions, Applications, and Navigating the Ethical Landscape and Public Perspectives\nAbstract\nArtificial intelligence (AI) has emerged as a crucial tool in healthcare with the primary aim of improving patient outcomes and optimizing healthcare delivery. By harnessing machine learning algorithms, natural language processing, and computer vision, AI enables the analysis of complex medical data. The integration of AI into healthcare systems aims to support clinicians, personalize patient care, and enhance population health, all while addressing the challenges posed by rising costs and limited resources. As a subdivision of computer science, AI focuses on the development of advanced algorithms capable of performing complex tasks that were once reliant on human intelligence. The ultimate goal is to achieve human-level performance with improved efficiency and accuracy in problem-solving and task execution, thereby reducing the need for human intervention. Various industries, including engineering, media\/entertainment, finance, and education, have already reaped significant benefits by incorporating AI systems into their operations. Notably, the healthcare sector has witnessed rapid growth in the utilization of AI technology. Nevertheless, there remains untapped potential for AI to truly revolutionize the industry. It is important to note that despite concerns about job displacement, AI in healthcare should not be viewed as a threat to human workers. Instead, AI systems are designed to augment and support healthcare professionals, freeing up their time to focus on more complex and critical tasks. By automating routine and repetitive tasks, AI can alleviate the burden on healthcare professionals, allowing them to dedicate more attention to patient care and meaningful interactions. However, legal and ethical challenges must be addressed when embracing AI technology in medicine, alongside comprehensive public education to ensure widespread acceptance.\nKeywords: artificial intelligence; computational models; forecasting; future; medicine; predictive modeling.\nConflict of interest statement\nThe authors declare no conflicts of interest.\nFigures\nSimilar articles\n-\nArtificial Intelligence, the Digital Surgeon: Unravelling Its Emerging Footprint in Healthcare - The Narrative Review.J Multidiscip Healthc. 2024 Aug 15;17:4011-4022. doi: 10.2147\/JMDH.S482757. eCollection 2024. J Multidiscip Healthc. 2024. PMID: 39165254 Free PMC article. Review.\n-\nSmart Smile: Revolutionizing Dentistry With Artificial Intelligence.Cureus. 2023 Jun 30;15(6):e41227. doi: 10.7759\/cureus.41227. eCollection 2023 Jun. Cureus. 2023. PMID: 37529520 Free PMC article. Review.\n-\nLarge Language Models and User Trust: Consequence of Self-Referential Learning Loop and the Deskilling of Health Care Professionals.J Med Internet Res. 2024 Apr 25;26:e56764. doi: 10.2196\/56764. J Med Internet Res. 2024. PMID: 38662419 Free PMC article.\n-\nUnraveling the Ethical Enigma: Artificial Intelligence in Healthcare.Cureus. 2023 Aug 10;15(8):e43262. doi: 10.7759\/cureus.43262. eCollection 2023 Aug. Cureus. 2023. PMID: 37692617 Free PMC article. Review.\n-\nThe Medicine Revolution Through Artificial Intelligence: Ethical Challenges of Machine Learning Algorithms in Decision-Making.Cureus. 2024 Sep 14;16(9):e69405. doi: 10.7759\/cureus.69405. eCollection 2024 Sep. Cureus. 2024. PMID: 39411643 Free PMC article. Review.\nCited by\n-\nAssessing ChatGPT4 with and without retrieval-augmented generation in anticoagulation management for gastrointestinal procedures.Ann Gastroenterol. 2024 Sep-Oct;37(5):514-526. doi: 10.20524\/aog.2024.0907. Epub 2024 Aug 19. Ann Gastroenterol. 2024. PMID: 39238788 Free PMC article.\n-\nAutomated cutaneous squamous cell carcinoma grading using deep learning with transfer learning.Rom J Morphol Embryol. 2024 Apr-Jun;65(2):243-250. doi: 10.47162\/RJME.65.2.10. Rom J Morphol Embryol. 2024. PMID: 39020538 Free PMC article.\n-\nFrom Data Integration to Precision Medicine: A Value-Based Healthcare Approach for Sarcoma Care.J Clin Med. 2024 Oct 30;13(21):6500. doi: 10.3390\/jcm13216500. J Clin Med. 2024. PMID: 39518639 Free PMC article. Review.\n-\nRisk, Revelation, and Reflection: A Personal Journey Through Ethics, Risk Literacy, and Informed Consent.Circ Cardiovasc Qual Outcomes. 2024 Nov;17(11):e010894. doi: 10.1161\/CIRCOUTCOMES.124.010894. Epub 2024 Nov 19. Circ Cardiovasc Qual Outcomes. 2024. PMID: 39561233 No abstract available.\n-\nHarnessing Artificial Intelligence to Enhance Global Breast Cancer Care: A Scoping Review of Applications, Outcomes, and Challenges.Cancers (Basel). 2025 Jan 9;17(2):197. doi: 10.3390\/cancers17020197. Cancers (Basel). 2025. PMID: 39857979 Free PMC article. Review.\nReferences\n-\n- Haenlein M., Kaplan A. A Brief History of Artificial Intelligence: On the Past, Present, and Future of Artificial Intelligence. Calif. Manag. Rev. 2019;61:5\u201314. doi: 10.1177\/0008125619864925. - DOI\n-\n- Monett D., Lewis C.W.P., Th\u00f3risson K.R., Bach J., Baldassarre G., Granato G., Berkeley I.S.N., Chollet F., Crosby M., Shevlin H., et al. Special Issue \u201cOn Defining Artificial Intelligence\u201d\u2014Commentaries and Author\u2019s Response. J. Artif. Gen. Intell. 2020;11:1\u2013100. doi: 10.2478\/jagi-2020-0003. - DOI\n-\n- Gasparetto A., Scalera L. Explorations in the History and Heritage of Machines and Mechanisms. Springer International Publishing; Berlin\/Heidelberg, Germany: 2018. From the Unimate to the Delta Robot: The Early Decades of Industrial Robotics; pp. 284\u2013295. - DOI\n-\n- Shum H., He X., Li D. From Eliza to XiaoIce: Challenges and opportunities with social chatbots. Front. Inf. Technol. Electron. Eng. 2018;19:10\u201326. doi: 10.1631\/FITEE.1700826. - DOI\nPublication types\nLinkOut - more resources\nFull Text Sources\nResearch Materials",
    "scraped_at":"2025-07-07T18:26:04.251864"
  },
  {
    "topic":"Natural Language Processing",
    "title":"Natural Language Processing (NLP) - A Complete Guide",
    "url":"https:\/\/www.deeplearning.ai\/resources\/natural-language-processing\/",
    "domain":"www.deeplearning.ai",
    "snippet":"Natural Language Processing Introduction Natural Language Processing (NLP) is one of the hottest areas of artificial intelligence (AI) thanks to applications like text generators that compose coherent essays, chatbots that fool people into thinking they\u2019re sentient, and text-to-image programs that p...",
    "content":"Natural Language Processing\nIntroduction\nNatural Language Processing (NLP) is one of the hottest areas of artificial intelligence (AI) thanks to applications like text generators that compose coherent essays, chatbots that fool people into thinking they\u2019re sentient, and text-to-image programs that produce photorealistic images of anything you can describe. Recent years have brought a revolution in the ability of computers to understand human languages, programming languages, and even biological and chemical sequences, such as DNA and protein structures, that resemble language. The latest AI models are unlocking these areas to analyze the meanings of input text and generate meaningful, expressive output.\nWhat is Natural Language Processing (NLP)\nNatural language processing (NLP) is the discipline of building machines that can manipulate human language \u2014 or data that resembles human language \u2014 in the way that it is written, spoken, and organized. It evolved from computational linguistics, which uses computer science to understand the principles of language, but rather than developing theoretical frameworks, NLP is an engineering discipline that seeks to build technology to accomplish useful tasks. NLP can be divided into two overlapping subfields: natural language understanding (NLU), which focuses on semantic analysis or determining the intended meaning of text, and natural language generation (NLG), which focuses on text generation by a machine. NLP is separate from \u2014 but often used in conjunction with \u2014 speech recognition, which seeks to parse spoken language into words, turning sound into text and vice versa.\nWhy Does Natural Language Processing (NLP) Matter?\nNLP is an integral part of everyday life and becoming more so as language technology is applied to diverse fields like retailing (for instance, in customer service chatbots) and medicine (interpreting or summarizing electronic health records). Conversational agents such as Amazon\u2019s Alexa and Apple\u2019s Siri utilize NLP to listen to user queries and find answers. The most sophisticated such agents \u2014 such as GPT-3, which was recently opened for commercial applications \u2014 can generate sophisticated prose on a wide variety of topics as well as power chatbots that are capable of holding coherent conversations. Google uses NLP to improve its search engine results, and social networks like Facebook use it to detect and filter hate speech.\nNLP is growing increasingly sophisticated, yet much work remains to be done. Current systems are prone to bias and incoherence, and occasionally behave erratically. Despite the challenges, machine learning engineers have many opportunities to apply NLP in ways that are ever more central to a functioning society.\nWhat is Natural Language Processing (NLP) Used For?\nNLP is used for a wide variety of language-related tasks, including answering questions, classifying text in a variety of ways, and conversing with users.\nHere are 11 tasks that can be solved by NLP:\n- Sentiment analysis is the process of classifying the emotional intent of text. Generally, the input to a sentiment classification model is a piece of text, and the output is the probability that the sentiment expressed is positive, negative, or neutral. Typically, this probability is based on either hand-generated features, word n-grams, TF-IDF features, or using deep learning models to capture sequential long- and short-term dependencies. Sentiment analysis is used to classify customer reviews on various online platforms as well as for niche applications like identifying signs of mental illness in online comments.\n- Toxicity classification is a branch of sentiment analysis where the aim is not just to classify hostile intent but also to classify particular categories such as threats, insults, obscenities, and hatred towards certain identities. The input to such a model is text, and the output is generally the probability of each class of toxicity. Toxicity classification models can be used to moderate and improve online conversations by silencing offensive comments, detecting hate speech, or scanning documents for defamation.\n- Machine translation automates translation between different languages. The input to such a model is text in a specified source language, and the output is the text in a specified target language. Google Translate is perhaps the most famous mainstream application. Such models are used to improve communication between people on social-media platforms such as Facebook or Skype. Effective approaches to machine translation can distinguish between words with similar meanings. Some systems also perform language identification; that is, classifying text as being in one language or another.\n- Named entity recognition aims to extract entities in a piece of text into predefined categories such as personal names, organizations, locations, and quantities. The input to such a model is generally text, and the output is the various named entities along with their start and end positions. Named entity recognition is useful in applications such as summarizing news articles and combating disinformation. For example, here is what a named entity recognition model could provide:\n- Spam detection is a prevalent binary classification problem in NLP, where the purpose is to classify emails as either spam or not. Spam detectors take as input an email text along with various other subtexts like title and sender\u2019s name. They aim to output the probability that the mail is spam. Email providers like Gmail use such models to provide a better user experience by detecting unsolicited and unwanted emails and moving them to a designated spam folder.\n- Grammatical error correction models encode grammatical rules to correct the grammar within text. This is viewed mainly as a sequence-to-sequence task, where a model is trained on an ungrammatical sentence as input and a correct sentence as output. Online grammar checkers like Grammarly and word-processing systems like Microsoft Word use such systems to provide a better writing experience to their customers. Schools also use them to grade student essays.\n- Topic modeling is an unsupervised text mining task that takes a corpus of documents and discovers abstract topics within that corpus. The input to a topic model is a collection of documents, and the output is a list of topics that defines words for each topic as well as assignment proportions of each topic in a document. Latent Dirichlet Allocation (LDA), one of the most popular topic modeling techniques, tries to view a document as a collection of topics and a topic as a collection of words. Topic modeling is being used commercially to help lawyers find evidence in legal documents.\n- Text generation, more formally known as natural language generation (NLG), produces text that\u2019s similar to human-written text. Such models can be fine-tuned to produce text in different genres and formats \u2014 including tweets, blogs, and even computer code. Text generation has been performed using Markov processes, LSTMs, BERT, GPT-2, LaMDA, and other approaches. It\u2019s particularly useful for autocomplete and chatbots.\n- Autocomplete predicts what word comes next, and autocomplete systems of varying complexity are used in chat applications like WhatsApp. Google uses autocomplete to predict search queries. One of the most famous models for autocomplete is GPT-2, which has been used to write articles, song lyrics, and much more.\n- Chatbots automate one side of a conversation while a human conversant generally supplies the other side. They can be divided into the following two categories:\n- Database query: We have a database of questions and answers, and we would like a user to query it using natural language.\n- Conversation generation: These chatbots can simulate dialogue with a human partner. Some are capable of engaging in wide-ranging conversations. A high-profile example is Google\u2019s LaMDA, which provided such human-like answers to questions that one of its developers was convinced that it had feelings.\n- Information retrieval finds the documents that are most relevant to a query. This is a problem every search and recommendation system faces. The goal is not to answer a particular query but to retrieve, from a collection of documents that may be numbered in the millions, a set that is most relevant to the query. Document retrieval systems mainly execute two processes: indexing and matching. In most modern systems, indexing is done by a vector space model through Two-Tower Networks, while matching is done using similarity or distance scores. Google recently integrated its search function with a multimodal information retrieval model that works with text, image, and video data.\n- Summarization is the task of shortening text to highlight the most relevant information. Researchers at Salesforce developed a summarizer that also evaluates factual consistency to ensure that its output is accurate. Summarization is divided into two method classes:\n- Extractive summarization focuses on extracting the most important sentences from a long text and combining these to form a summary. Typically, extractive summarization scores each sentence in an input text and then selects several sentences to form the summary.\n- Abstractive summarization produces a summary by paraphrasing. This is similar to writing the abstract that includes words and sentences that are not present in the original text. Abstractive summarization is usually modeled as a sequence-to-sequence task, where the input is a long-form text and the output is a summary.\n- Question answering deals with answering questions posed by humans in a natural language. One of the most notable examples of question answering was Watson, which in 2011 played the television game-show Jeopardy against human champions and won by substantial margins. Generally, question-answering tasks come in two flavors:\n- Multiple choice: The multiple-choice question problem is composed of a question and a set of possible answers. The learning task is to pick the correct answer.\n- Open domain: In open-domain question answering, the model provides answers to questions in natural language without any options provided, often by querying a large number of texts.\nHow Does Natural Language Processing (NLP) Work?\nNLP models work by finding relationships between the constituent parts of language \u2014 for example, the letters, words, and sentences found in a text dataset. NLP architectures use various methods for data preprocessing, feature extraction, and modeling. Some of these processes are:\n- Data preprocessing: Before a model processes text for a specific task, the text often needs to be preprocessed to improve model performance or to turn words and characters into a format the model can understand. Data-centric AI is a growing movement that prioritizes data preprocessing. Various techniques may be used in this data preprocessing:\n- Stemming and lemmatization: Stemming is an informal process of converting words to their base forms using heuristic rules. For example, \u201cuniversity,\u201d \u201cuniversities,\u201d and \u201cuniversity\u2019s\u201d might all be mapped to the base univers. (One limitation in this approach is that \u201cuniverse\u201d may also be mapped to univers, even though universe and university don\u2019t have a close semantic relationship.) Lemmatization is a more formal way to find roots by analyzing a word\u2019s morphology using vocabulary from a dictionary. Stemming and lemmatization are provided by libraries like spaCy and NLTK.\n- Sentence segmentation breaks a large piece of text into linguistically meaningful sentence units. This is obvious in languages like English, where the end of a sentence is marked by a period, but it is still not trivial. A period can be used to mark an abbreviation as well as to terminate a sentence, and in this case, the period should be part of the abbreviation token itself. The process becomes even more complex in languages, such as ancient Chinese, that don\u2019t have a delimiter that marks the end of a sentence.\n- Stop word removal aims to remove the most commonly occurring words that don\u2019t add much information to the text. For example, \u201cthe,\u201d \u201ca,\u201d \u201can,\u201d and so on.\n- Tokenization splits text into individual words and word fragments. The result generally consists of a word index and tokenized text in which words may be represented as numerical tokens for use in various deep learning methods. A method that instructs language models to ignore unimportant tokens can improve efficiency.\n- Feature extraction: Most conventional machine-learning techniques work on the features \u2013 generally numbers that describe a document in relation to the corpus that contains it \u2013 created by either Bag-of-Words, TF-IDF, or generic feature engineering such as document length, word polarity, and metadata (for instance, if the text has associated tags or scores). More recent techniques include Word2Vec, GLoVE, and learning the features during the training process of a neural network.\n- Bag-of-Words: Bag-of-Words counts the number of times each word or n-gram (combination of n words) appears in a document. For example, below, the Bag-of-Words model creates a numerical representation of the dataset based on how many of each word in the word_index occur in the document.\n- TF-IDF: In Bag-of-Words, we count the occurrence of each word or n-gram in a document. In contrast, with TF-IDF, we weight each word by its importance. To evaluate a word\u2019s significance, we consider two things:\n- Term Frequency: How important is the word in the document?\nTF(word in a document)= Number of occurrences of that word in document \/ Number of words in document\n- Inverse Document Frequency: How important is the term in the whole corpus?\nIDF(word in a corpus)=log(number of documents in the corpus \/ number of documents that include the word)\nA word is important if it occurs many times in a document. But that creates a problem. Words like \u201ca\u201d and \u201cthe\u201d appear often. And as such, their TF score will always be high. We resolve this issue by using Inverse Document Frequency, which is high if the word is rare and low if the word is common across the corpus. The TF-IDF score of a term is the product of TF and IDF.\n- Word2Vec, introduced in 2013, uses a vanilla neural network to learn high-dimensional word embeddings from raw text. It comes in two variations: Skip-Gram, in which we try to predict surrounding words given a target word, and Continuous Bag-of-Words (CBOW), which tries to predict the target word from surrounding words. After discarding the final layer after training, these models take a word as input and output a word embedding that can be used as an input to many NLP tasks. Embeddings from Word2Vec capture context. If particular words appear in similar contexts, their embeddings will be similar.\n- GLoVE is similar to Word2Vec as it also learns word embeddings, but it does so by using matrix factorization techniques rather than neural learning. The GLoVE model builds a matrix based on the global word-to-word co-occurrence counts.\n- Modeling: After data is preprocessed, it is fed into an NLP architecture that models the data to accomplish a variety of tasks.\n- Numerical features extracted by the techniques described above can be fed into various models depending on the task at hand. For example, for classification, the output from the TF-IDF vectorizer could be provided to logistic regression, naive Bayes, decision trees, or gradient boosted trees. Or, for named entity recognition, we can use hidden Markov models along with n-grams.\n- Deep neural networks typically work without using extracted features, although we can still use TF-IDF or Bag-of-Words features as an input.\n- Language Models: In very basic terms, the objective of a language model is to predict the next word when given a stream of input words. Probabilistic models that use Markov assumption are one example:\nP(Wn)=P(Wn|Wn\u22121)\nDeep learning is also used to create such language models. Deep-learning models take as input a word embedding and, at each time state, return the probability distribution of the next word as the probability for every word in the dictionary. Pre-trained language models learn the structure of a particular language by processing a large corpus, such as Wikipedia. They can then be fine-tuned for a particular task. For instance, BERT has been fine-tuned for tasks ranging from fact-checking to writing headlines.\nTop Natural Language Processing (NLP) Techniques\nMost of the NLP tasks discussed above can be modeled by a dozen or so general techniques. It\u2019s helpful to think of these techniques in two categories: Traditional machine learning methods and deep learning methods.\nTraditional Machine learning NLP techniques:\n- Logistic regression is a supervised classification algorithm that aims to predict the probability that an event will occur based on some input. In NLP, logistic regression models can be applied to solve problems such as sentiment analysis, spam detection, and toxicity classification.\n- Naive Bayes is a supervised classification algorithm that finds the conditional probability distribution P(label | text) using the following Bayes formula:\nP(label | text) = P(label) x P(text|label) \/ P(text)\nand predicts based on which joint distribution has the highest probability. The naive assumption in the Naive Bayes model is that the individual words are independent. Thus:\nP(text|label) = P(word_1|label)*P(word_2|label)*\u2026P(word_n|label)\nIn NLP, such statistical methods can be applied to solve problems such as spam detection or finding bugs in software code.\n- Decision trees are a class of supervised classification models that split the dataset based on different features to maximize information gain in those splits.\n- Latent Dirichlet Allocation (LDA) is used for topic modeling. LDA tries to view a document as a collection of topics and a topic as a collection of words. LDA is a statistical approach. The intuition behind it is that we can describe any topic using only a small set of words from the corpus.\n- Hidden Markov models: Markov models are probabilistic models that decide the next state of a system based on the current state. For example, in NLP, we might suggest the next word based on the previous word. We can model this as a Markov model where we might find the transition probabilities of going from word1 to word2, that is, P(word1|word2). Then we can use a product of these transition probabilities to find the probability of a sentence. The hidden Markov model (HMM) is a probabilistic modeling technique that introduces a hidden state to the Markov model. A hidden state is a property of the data that isn\u2019t directly observed. HMMs are used for part-of-speech (POS) tagging where the words of a sentence are the observed states and the POS tags are the hidden states. The HMM adds a concept called emission probability; the probability of an observation given a hidden state. In the prior example, this is the probability of a word, given its POS tag. HMMs assume that this probability can be reversed: Given a sentence, we can calculate the part-of-speech tag from each word based on both how likely a word was to have a certain part-of-speech tag and the probability that a particular part-of-speech tag follows the part-of-speech tag assigned to the previous word. In practice, this is solved using the Viterbi algorithm.\nDeep learning NLP Techniques:\n- Convolutional Neural Network (CNN): The idea of using a CNN to classify text was first presented in the paper \u201cConvolutional Neural Networks for Sentence Classification\u201d by Yoon Kim. The central intuition is to see a document as an image. However, instead of pixels, the input is sentences or documents represented as a matrix of words.\n- Recurrent Neural Network (RNN): Many techniques for text classification that use deep learning process words in close proximity using n-grams or a window (CNNs). They can see \u201cNew York\u201d as a single instance. However, they can\u2019t capture the context provided by a particular text sequence. They don\u2019t learn the sequential structure of the data, where every word is dependent on the previous word or a word in the previous sentence. RNNs remember previous information using hidden states and connect it to the current task. The architectures known as Gated Recurrent Unit (GRU) and long short-term memory (LSTM) are types of RNNs designed to remember information for an extended period. Moreover, the bidirectional LSTM\/GRU keeps contextual information in both directions, which is helpful in text classification. RNNs have also been used to generate mathematical proofs and translate human thoughts into words.\n- Autoencoders are deep learning encoder-decoders that approximate a mapping from X to X, i.e., input=output. They first compress the input features into a lower-dimensional representation (sometimes called a latent code, latent vector, or latent representation) and learn to reconstruct the input. The representation vector can be used as input to a separate model, so this technique can be used for dimensionality reduction. Among specialists in many other fields, geneticists have applied autoencoders to spot mutations associated with diseases in amino acid sequences.\n- Encoder-decoder sequence-to-sequence: The encoder-decoder seq2seq architecture is an adaptation to autoencoders specialized for translation, summarization, and similar tasks. The encoder encapsulates the information in a text into an encoded vector. Unlike an autoencoder, instead of reconstructing the input from the encoded vector, the decoder\u2019s task is to generate a different desired output, like a translation or summary.\n- Transformers: The transformer, a model architecture first described in the 2017 paper \u201cAttention Is All You Need\u201d (Vaswani, Shazeer, Parmar, et al.), forgoes recurrence and instead relies entirely on a self-attention mechanism to draw global dependencies between input and output. Since this mechanism processes all words at once (instead of one at a time) that decreases training speed and inference cost compared to RNNs, especially since it is parallelizable. The transformer architecture has revolutionized NLP in recent years, leading to models including BLOOM, Jurassic-X, and Turing-NLG. It has also been successfully applied to a variety of different vision tasks, including making 3D images.\nSix Important Natural Language Processing (NLP) Models\nOver the years, many NLP models have made waves within the AI community, and some have even made headlines in the mainstream news. The most famous of these have been chatbots and language models. Here are some of them:\n- Eliza was developed in the mid-1960s to try to solve the Turing Test; that is, to fool people into thinking they\u2019re conversing with another human being rather than a machine. Eliza used pattern matching and a series of rules without encoding the context of the language.\n- Tay was a chatbot that Microsoft launched in 2016. It was supposed to tweet like a teen and learn from conversations with real users on Twitter. The bot adopted phrases from users who tweeted sexist and racist comments, and Microsoft deactivated it not long afterward. Tay illustrates some points made by the \u201cStochastic Parrots\u201d paper, particularly the danger of not debiasing data.\n- BERT and his Muppet friends: Many deep learning models for NLP are named after Muppet characters, including ELMo, BERT, Big BIRD, ERNIE, Kermit, Grover, RoBERTa, and Rosita. Most of these models are good at providing contextual embeddings and enhanced knowledge representation.\n- Generative Pre-Trained Transformer 3 (GPT-3) is a 175 billion parameter model that can write original prose with human-equivalent fluency in response to an input prompt. The model is based on the transformer architecture. The previous version, GPT-2, is open source. Microsoft acquired an exclusive license to access GPT-3\u2019s underlying model from its developer OpenAI, but other users can interact with it via an application programming interface (API). Several groups including EleutherAI and Meta have released open source interpretations of GPT-3.\n- Language Model for Dialogue Applications (LaMDA) is a conversational chatbot developed by Google. LaMDA is a transformer-based model trained on dialogue rather than the usual web text. The system aims to provide sensible and specific responses to conversations. Google developer Blake Lemoine came to believe that LaMDA is sentient. Lemoine had detailed conversations with AI about his rights and personhood. During one of these conversations, the AI changed Lemoine\u2019s mind about Isaac Asimov\u2019s third law of robotics. Lemoine claimed that LaMDA was sentient, but the idea was disputed by many observers and commentators. Subsequently, Google placed Lemoine on administrative leave for distributing proprietary information and ultimately fired him.\n- Mixture of Experts (MoE): While most deep learning models use the same set of parameters to process every input, MoE models aim to provide different parameters for different inputs based on efficient routing algorithms to achieve higher performance. Switch Transformer is an example of the MoE approach that aims to reduce communication and computational costs.\nProgramming Languages, Libraries, And Frameworks For Natural Language Processing (NLP)\nMany languages and libraries support NLP. Here are a few of the most useful.\n- Python is the most-used programming language to tackle NLP tasks. Most libraries and frameworks for deep learning are written for Python. Here are a few that practitioners may find helpful:\n- Natural Language Toolkit (NLTK) is one of the first NLP libraries written in Python. It provides easy-to-use interfaces to corpora and lexical resources such as WordNet. It also provides a suite of text-processing libraries for classification, tagging, stemming, parsing, and semantic reasoning.\n- spaCy is one of the most versatile open source NLP libraries. It supports more than 66 languages. spaCy also provides pre-trained word vectors and implements many popular models like BERT. spaCy can be used for building production-ready systems for named entity recognition, part-of-speech tagging, dependency parsing, sentence segmentation, text classification, lemmatization, morphological analysis, entity linking, and so on.\n- Deep Learning libraries: Popular deep learning libraries include TensorFlow and PyTorch, which make it easier to create models with features like automatic differentiation. These libraries are the most common tools for developing NLP models.\n- Hugging Face offers open-source implementations and weights of over 135 state-of-the-art models. The repository enables easy customization and training of the models.\n- Gensim provides vector space modeling and topic modeling algorithms.\n- R: Many early NLP models were written in R, and R is still widely used by data scientists and statisticians. Libraries in R for NLP include TidyText, Weka, Word2Vec, SpaCyR, TensorFlow, and PyTorch.\n- Many other languages including JavaScript, Java, and Julia have libraries that implement NLP methods.\nControversies Surrounding Natural Language Processing (NLP)\nNLP has been at the center of a number of controversies. Some are centered directly on the models and their outputs, others on second-order concerns, such as who has access to these systems, and how training them impacts the natural world.\n- Stochastic parrots: A 2021 paper titled \u201cOn the Dangers of Stochastic Parrots: Can Language Models Be Too Big?\u201d by Emily Bender, Timnit Gebru, Angelina McMillan-Major, and Margaret Mitchell examines how language models may repeat and amplify biases found in their training data. The authors point out that huge, uncurated datasets scraped from the web are bound to include social biases and other undesirable information, and models that are trained on them will absorb these flaws. They advocate greater care in curating and documenting datasets, evaluating a model\u2019s potential impact prior to development, and encouraging research in directions other than designing ever-larger architectures to ingest ever-larger datasets.\n- Coherence versus sentience: Recently, a Google engineer tasked with evaluating the LaMDA language model was so impressed by the quality of its chat output that he believed it to be sentient. The fallacy of attributing human-like intelligence to AI dates back to some of the earliest NLP experiments.\n- Environmental impact: Large language models require a lot of energy during both training and inference. One study estimated that training a single large language model can emit five times as much carbon dioxide as a single automobile over its operational lifespan. Another study found that models consume even more energy during inference than training. As for solutions, researchers have proposed using cloud servers located in countries with lots of renewable energy as one way to offset this impact.\n- High cost leaves out non-corporate researchers: The computational requirements needed to train or deploy large language models are too expensive for many small companies. Some experts worry that this could block many capable engineers from contributing to innovation in AI.\n- Black box: When a deep learning model renders an output, it\u2019s difficult or impossible to know why it generated that particular result. While traditional models like logistic regression enable engineers to examine the impact on the output of individual features, neural network methods in natural language processing are essentially black boxes. Such systems are said to be \u201cnot explainable,\u201d since we can\u2019t explain how they arrived at their output. An effective approach to achieve explainability is especially important in areas like banking, where regulators want to confirm that a natural language processing system doesn\u2019t discriminate against some groups of people, and law enforcement, where models trained on historical data may perpetuate historical biases against certain groups.\n\u201cNonsense on stilts\u201d: Writer Gary Marcus has criticized deep learning-based NLP for generating sophisticated language that misleads users to believe that natural language algorithms understand what they are saying and mistakenly assume they are capable of more sophisticated reasoning than is currently possible.\nHow To Get Started In Natural Language Processing (NLP)\nIf you are just starting out, many excellent courses can help.\nIf you want to learn more about NLP, try reading research papers. Work through the papers that introduced the models and techniques described in this article. Most are easy to find on arxiv.org. You might also take a look at these resources:\n- The Batch: A weekly newsletter that tells you what matters in AI. It\u2019s the best way to keep up with developments in deep learning.\n- NLP News: A newsletter from Sebastian Ruder, a research scientist at Google, focused on what\u2019s new in NLP.\n- Papers with Code: A web repository of machine learning research, tasks, benchmarks, and datasets.\nWe highly recommend learning to implement basic algorithms (linear and logistic regression, Naive Bayes, decision trees, and vanilla neural networks) in Python. The next step is to take an open-source implementation and adapt it to a new dataset or task.\nConclusion\nNLP is one of the fast-growing research domains in AI, with applications that involve tasks including translation, summarization, text generation, and sentiment analysis. Businesses use NLP to power a growing number of applications, both internal \u2014 like detecting insurance fraud, determining customer sentiment, and optimizing aircraft maintenance \u2014 and customer-facing, like Google Translate.\nAspiring NLP practitioners can begin by familiarizing themselves with foundational AI skills: performing basic mathematics, coding in Python, and using algorithms like decision trees, Naive Bayes, and logistic regression. Online courses can help you build your foundation. They can also help as you proceed into specialized topics. Specializing in NLP requires a working knowledge of things like neural networks, frameworks like PyTorch and TensorFlow, and various data preprocessing techniques. The transformer architecture, which has revolutionized the field since it was introduced in 2017, is an especially important architecture.\nNLP is an exciting and rewarding discipline, and has potential to profoundly impact the world in many positive ways. Unfortunately, NLP is also the focus of several controversies, and understanding them is also part of being a responsible practitioner. For instance, researchers have found that models will parrot biased language found in their training data, whether they\u2019re counterfactual, racist, or hateful. Moreover, sophisticated language models can be used to generate disinformation. A broader concern is that training large models produces substantial greenhouse gas emissions.\nThis page is only a brief overview of what NLP is all about. If you have an appetite for more, DeepLearning.AI offers courses for everyone in their NLP journey, from AI beginners and those who are ready to specialize. No matter your current level of expertise or aspirations, remember to keep learning!",
    "scraped_at":"2025-07-07T18:26:06.852078"
  },
  {
    "topic":"Natural Language Processing",
    "title":"Natural language processing - Wikipedia",
    "url":"https:\/\/en.wikipedia.org\/wiki\/Natural_language_processing",
    "domain":"en.wikipedia.org",
    "snippet":"Natural language processing This article needs additional citations for verification. (May 2024) | Natural language processing (NLP) is a subfield of computer science and especially artificial intelligence. It is primarily concerned with providing computers with the ability to process data encoded i...",
    "content":"Natural language processing\nThis article needs additional citations for verification. (May 2024) |\nNatural language processing (NLP) is a subfield of computer science and especially artificial intelligence. It is primarily concerned with providing computers with the ability to process data encoded in natural language and is thus closely related to information retrieval, knowledge representation and computational linguistics, a subfield of linguistics.\nMajor tasks in natural language processing are speech recognition, text classification, natural language understanding, and natural language generation.\nHistory\n[edit]Natural language processing has its roots in the 1950s.[1] Already in 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence, though at the time that was not articulated as a problem separate from artificial intelligence. The proposed test includes a task that involves the automated interpretation and generation of natural language.\nSymbolic NLP (1950s \u2013 early 1990s)\n[edit]The premise of symbolic NLP is well-summarized by John Searle's Chinese room experiment: Given a collection of rules (e.g., a Chinese phrasebook, with questions and matching answers), the computer emulates natural language understanding (or other NLP tasks) by applying those rules to the data it confronts.\n- 1950s: The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian sentences into English. The authors claimed that within three or five years, machine translation would be a solved problem.[2] However, real progress was much slower, and after the ALPAC report in 1966, which found that ten years of research had failed to fulfill the expectations, funding for machine translation was dramatically reduced. Little further research in machine translation was conducted in America (though some research continued elsewhere, such as Japan and Europe[3]) until the late 1980s when the first statistical machine translation systems were developed.\n- 1960s: Some notably successful natural language processing systems developed in the 1960s were SHRDLU, a natural language system working in restricted \"blocks worlds\" with restricted vocabularies, and ELIZA, a simulation of a Rogerian psychotherapist, written by Joseph Weizenbaum between 1964 and 1966. Using almost no information about human thought or emotion, ELIZA sometimes provided a startlingly human-like interaction. When the \"patient\" exceeded the very small knowledge base, ELIZA might provide a generic response, for example, responding to \"My head hurts\" with \"Why do you say your head hurts?\". Ross Quillian's successful work on natural language was demonstrated with a vocabulary of only twenty words, because that was all that would fit in a computer memory at the time.[4]\n- 1970s: During the 1970s, many programmers began to write \"conceptual ontologies\", which structured real-world information into computer-understandable data. Examples are MARGIE (Schank, 1975), SAM (Cullingford, 1978), PAM (Wilensky, 1978), TaleSpin (Meehan, 1976), QUALM (Lehnert, 1977), Politics (Carbonell, 1979), and Plot Units (Lehnert 1981). During this time, the first chatterbots were written (e.g., PARRY).\n- 1980s: The 1980s and early 1990s mark the heyday of symbolic methods in NLP. Focus areas of the time included research on rule-based parsing (e.g., the development of HPSG as a computational operationalization of generative grammar), morphology (e.g., two-level morphology[5]), semantics (e.g., Lesk algorithm), reference (e.g., within Centering Theory[6]) and other areas of natural language understanding (e.g., in the Rhetorical Structure Theory). Other lines of research were continued, e.g., the development of chatterbots with Racter and Jabberwacky. An important development (that eventually led to the statistical turn in the 1990s) was the rising importance of quantitative evaluation in this period.[7]\nStatistical NLP (1990s\u2013present)\n[edit]Up until the 1980s, most natural language processing systems were based on complex sets of hand-written rules. Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing. This was due to both the steady increase in computational power (see Moore's law) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.[8]\n- 1990s: Many of the notable early successes in statistical methods in NLP occurred in the field of machine translation, due especially to work at IBM Research, such as IBM alignment models. These systems were able to take advantage of existing multilingual textual corpora that had been produced by the Parliament of Canada and the European Union as a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government. However, most other systems depended on corpora specifically developed for the tasks implemented by these systems, which was (and often continues to be) a major limitation in the success of these systems. As a result, a great deal of research has gone into methods of more effectively learning from limited amounts of data.\n- 2000s: With the growth of the web, increasing amounts of raw (unannotated) language data have become available since the mid-1990s. Research has thus increasingly focused on unsupervised and semi-supervised learning algorithms. Such algorithms can learn from data that has not been hand-annotated with the desired answers or using a combination of annotated and non-annotated data. Generally, this task is much more difficult than supervised learning, and typically produces less accurate results for a given amount of input data. However, there is an enormous amount of non-annotated data available (including, among other things, the entire content of the World Wide Web), which can often make up for the worse efficiency if the algorithm used has a low enough time complexity to be practical.\n- 2003: word n-gram model, at the time the best statistical algorithm, is outperformed by a multi-layer perceptron (with a single hidden layer and context length of several words, trained on up to 14 million words, by Bengio et al.)[9]\n- 2010: Tom\u00e1\u0161 Mikolov (then a PhD student at Brno University of Technology) with co-authors applied a simple recurrent neural network with a single hidden layer to language modelling,[10] and in the following years he went on to develop Word2vec. In the 2010s, representation learning and deep neural network-style (featuring many hidden layers) machine learning methods became widespread in natural language processing. That popularity was due partly to a flurry of results showing that such techniques[11][12] can achieve state-of-the-art results in many natural language tasks, e.g., in language modeling[13] and parsing.[14][15] This is increasingly important in medicine and healthcare, where NLP helps analyze notes and text in electronic health records that would otherwise be inaccessible for study when seeking to improve care[16] or protect patient privacy.[17]\nApproaches: Symbolic, statistical, neural networks\n[edit]Symbolic approach, i.e., the hand-coding of a set of rules for manipulating symbols, coupled with a dictionary lookup, was historically the first approach used both by AI in general and by NLP in particular:[18][19] such as by writing grammars or devising heuristic rules for stemming.\nMachine learning approaches, which include both statistical and neural networks, on the other hand, have many advantages over the symbolic approach:\n- both statistical and neural networks methods can focus more on the most common cases extracted from a corpus of texts, whereas the rule-based approach needs to provide rules for both rare cases and common ones equally.\n- language models, produced by either statistical or neural networks methods, are more robust to both unfamiliar (e.g. containing words or structures that have not been seen before) and erroneous input (e.g. with misspelled words or words accidentally omitted) in comparison to the rule-based systems, which are also more costly to produce.\n- the larger such a (probabilistic) language model is, the more accurate it becomes, in contrast to rule-based systems that can gain accuracy only by increasing the amount and complexity of the rules leading to intractability problems.\nRule-based systems are commonly used:\n- when the amount of training data is insufficient to successfully apply machine learning methods, e.g., for the machine translation of low-resource languages such as provided by the Apertium system,\n- for preprocessing in NLP pipelines, e.g., tokenization, or\n- for postprocessing and transforming the output of NLP pipelines, e.g., for knowledge extraction from syntactic parses.\nStatistical approach\n[edit]In the late 1980s and mid-1990s, the statistical approach ended a period of AI winter, which was caused by the inefficiencies of the rule-based approaches.[20][21]\nThe earliest decision trees, producing systems of hard if\u2013then rules, were still very similar to the old rule-based approaches. Only the introduction of hidden Markov models, applied to part-of-speech tagging, announced the end of the old rule-based approach.\nNeural networks\n[edit]A major drawback of statistical methods is that they require elaborate feature engineering. Since 2015,[22] the statistical approach has been replaced by the neural networks approach, using semantic networks[23] and word embeddings to capture semantic properties of words.\nIntermediate tasks (e.g., part-of-speech tagging and dependency parsing) are not needed anymore.\nNeural machine translation, based on then-newly invented sequence-to-sequence transformations, made obsolete the intermediate steps, such as word alignment, previously necessary for statistical machine translation.\nCommon NLP tasks\n[edit]The following is a list of some of the most commonly researched tasks in natural language processing. Some of these tasks have direct real-world applications, while others more commonly serve as subtasks that are used to aid in solving larger tasks.\nThough natural language processing tasks are closely intertwined, they can be subdivided into categories for convenience. A coarse division is given below.\nText and speech processing\n[edit]- Optical character recognition (OCR)\n- Given an image representing printed text, determine the corresponding text.\n- Speech recognition\n- Given a sound clip of a person or people speaking, determine the textual representation of the speech. This is the opposite of text to speech and is one of the extremely difficult problems colloquially termed \"AI-complete\" (see above). In natural speech there are hardly any pauses between successive words, and thus speech segmentation is a necessary subtask of speech recognition (see below). In most spoken languages, the sounds representing successive letters blend into each other in a process termed coarticulation, so the conversion of the analog signal to discrete characters can be a very difficult process. Also, given that words in the same language are spoken by people with different accents, the speech recognition software must be able to recognize the wide variety of input as being identical to each other in terms of its textual equivalent.\n- Speech segmentation\n- Given a sound clip of a person or people speaking, separate it into words. A subtask of speech recognition and typically grouped with it.\n- Text-to-speech\n- Given a text, transform those units and produce a spoken representation. Text-to-speech can be used to aid the visually impaired.[24]\n- Word segmentation (Tokenization)\n- Tokenization is a process used in text analysis that divides text into individual words or word fragments. This technique results in two key components: a word index and tokenized text. The word index is a list that maps unique words to specific numerical identifiers, and the tokenized text replaces each word with its corresponding numerical token. These numerical tokens are then used in various deep learning methods.[25]\n- For a language like English, this is fairly trivial, since words are usually separated by spaces. However, some written languages like Chinese, Japanese and Thai do not mark word boundaries in such a fashion, and in those languages text segmentation is a significant task requiring knowledge of the vocabulary and morphology of words in the language. Sometimes this process is also used in cases like bag of words (BOW) creation in data mining.[citation needed]\nMorphological analysis\n[edit]- Lemmatization\n- The task of removing inflectional endings only and to return the base dictionary form of a word which is also known as a lemma. Lemmatization is another technique for reducing words to their normalized form. But in this case, the transformation actually uses a dictionary to map words to their actual form.[26]\n- Morphological segmentation\n- Separate words into individual morphemes and identify the class of the morphemes. The difficulty of this task depends greatly on the complexity of the morphology (i.e., the structure of words) of the language being considered. English has fairly simple morphology, especially inflectional morphology, and thus it is often possible to ignore this task entirely and simply model all possible forms of a word (e.g., \"open, opens, opened, opening\") as separate words. In languages such as Turkish or Meitei, a highly agglutinated Indian language, however, such an approach is not possible, as each dictionary entry has thousands of possible word forms.[27]\n- Part-of-speech tagging\n- Given a sentence, determine the part of speech (POS) for each word. Many words, especially common ones, can serve as multiple parts of speech. For example, \"book\" can be a noun (\"the book on the table\") or verb (\"to book a flight\"); \"set\" can be a noun, verb or adjective; and \"out\" can be any of at least five different parts of speech.\n- Stemming\n- The process of reducing inflected (or sometimes derived) words to a base form (e.g., \"close\" will be the root for \"closed\", \"closing\", \"close\", \"closer\" etc.). Stemming yields similar results as lemmatization, but does so on grounds of rules, not a dictionary.\nSyntactic analysis\n[edit]| Part of a series on |\n| Formal languages |\n|---|\n- Grammar induction[28]\n- Generate a formal grammar that describes a language's syntax.\n- Sentence breaking (also known as \"sentence boundary disambiguation\")\n- Given a chunk of text, find the sentence boundaries. Sentence boundaries are often marked by periods or other punctuation marks, but these same characters can serve other purposes (e.g., marking abbreviations).\n- Parsing\n- Determine the parse tree (grammatical analysis) of a given sentence. The grammar for natural languages is ambiguous and typical sentences have multiple possible analyses: perhaps surprisingly, for a typical sentence there may be thousands of potential parses (most of which will seem completely nonsensical to a human). There are two primary types of parsing: dependency parsing and constituency parsing. Dependency parsing focuses on the relationships between words in a sentence (marking things like primary objects and predicates), whereas constituency parsing focuses on building out the parse tree using a probabilistic context-free grammar (PCFG) (see also stochastic grammar).\nLexical semantics (of individual words in context)\n[edit]- Lexical semantics\n- What is the computational meaning of individual words in context?\n- Distributional semantics\n- How can we learn semantic representations from data?\n- Named entity recognition (NER)\n- Given a stream of text, determine which items in the text map to proper names, such as people or places, and what the type of each such name is (e.g. person, location, organization). Although capitalization can aid in recognizing named entities in languages such as English, this information cannot aid in determining the type of named entity, and in any case, is often inaccurate or insufficient. For example, the first letter of a sentence is also capitalized, and named entities often span several words, only some of which are capitalized. Furthermore, many other languages in non-Western scripts (e.g. Chinese or Arabic) do not have any capitalization at all, and even languages with capitalization may not consistently use it to distinguish names. For example, German capitalizes all nouns, regardless of whether they are names, and French and Spanish do not capitalize names that serve as adjectives. Another name for this task is token classification.[29]\n- Sentiment analysis (see also Multimodal sentiment analysis)\n- Sentiment analysis is a computational method used to identify and classify the emotional intent behind text. This technique involves analyzing text to determine whether the expressed sentiment is positive, negative, or neutral. Models for sentiment classification typically utilize inputs such as word n-grams, Term Frequency-Inverse Document Frequency (TF-IDF) features, hand-generated features, or employ deep learning models designed to recognize both long-term and short-term dependencies in text sequences. The applications of sentiment analysis are diverse, extending to tasks such as categorizing customer reviews on various online platforms.[25]\n- Terminology extraction\n- The goal of terminology extraction is to automatically extract relevant terms from a given corpus.\n- Word-sense disambiguation (WSD)\n- Many words have more than one meaning; we have to select the meaning which makes the most sense in context. For this problem, we are typically given a list of words and associated word senses, e.g. from a dictionary or an online resource such as WordNet.\n- Entity linking\n- Many words\u2014typically proper names\u2014refer to named entities; here we have to select the entity (a famous individual, a location, a company, etc.) which is referred to in context.\nRelational semantics (semantics of individual sentences)\n[edit]- Relationship extraction\n- Given a chunk of text, identify the relationships among named entities (e.g. who is married to whom).\n- Semantic parsing\n- Given a piece of text (typically a sentence), produce a formal representation of its semantics, either as a graph (e.g., in AMR parsing) or in accordance with a logical formalism (e.g., in DRT parsing). This challenge typically includes aspects of several more elementary NLP tasks from semantics (e.g., semantic role labelling, word-sense disambiguation) and can be extended to include full-fledged discourse analysis (e.g., discourse analysis, coreference; see Natural language understanding below).\n- Semantic role labelling (see also implicit semantic role labelling below)\n- Given a single sentence, identify and disambiguate semantic predicates (e.g., verbal frames), then identify and classify the frame elements (semantic roles).\nDiscourse (semantics beyond individual sentences)\n[edit]- Coreference resolution\n- Given a sentence or larger chunk of text, determine which words (\"mentions\") refer to the same objects (\"entities\"). Anaphora resolution is a specific example of this task, and is specifically concerned with matching up pronouns with the nouns or names to which they refer. The more general task of coreference resolution also includes identifying so-called \"bridging relationships\" involving referring expressions. For example, in a sentence such as \"He entered John's house through the front door\", \"the front door\" is a referring expression and the bridging relationship to be identified is the fact that the door being referred to is the front door of John's house (rather than of some other structure that might also be referred to).\n- Discourse analysis\n- This rubric includes several related tasks. One task is discourse parsing, i.e., identifying the discourse structure of a connected text, i.e. the nature of the discourse relationships between sentences (e.g. elaboration, explanation, contrast). Another possible task is recognizing and classifying the speech acts in a chunk of text (e.g. yes\u2013no question, content question, statement, assertion, etc.).\n- Implicit semantic role labelling\n- Given a single sentence, identify and disambiguate semantic predicates (e.g., verbal frames) and their explicit semantic roles in the current sentence (see Semantic role labelling above). Then, identify semantic roles that are not explicitly realized in the current sentence, classify them into arguments that are explicitly realized elsewhere in the text and those that are not specified, and resolve the former against the local text. A closely related task is zero anaphora resolution, i.e., the extension of coreference resolution to pro-drop languages.\n- Recognizing textual entailment\n- Given two text fragments, determine if one being true entails the other, entails the other's negation, or allows the other to be either true or false.[30]\n- Topic segmentation and recognition\n- Given a chunk of text, separate it into segments each of which is devoted to a topic, and identify the topic of the segment.\n- Argument mining\n- The goal of argument mining is the automatic extraction and identification of argumentative structures from natural language text with the aid of computer programs.[31] Such argumentative structures include the premise, conclusions, the argument scheme and the relationship between the main and subsidiary argument, or the main and counter-argument within discourse.[32][33]\nHigher-level NLP applications\n[edit]- Automatic summarization (text summarization)\n- Produce a readable summary of a chunk of text. Often used to provide summaries of the text of a known type, such as research papers, articles in the financial section of a newspaper.\n- Grammatical error correction\n- Grammatical error detection and correction involves a great band-width of problems on all levels of linguistic analysis (phonology\/orthography, morphology, syntax, semantics, pragmatics). Grammatical error correction is impactful since it affects hundreds of millions of people that use or acquire English as a second language. It has thus been subject to a number of shared tasks since 2011.[34][35][36] As far as orthography, morphology, syntax and certain aspects of semantics are concerned, and due to the development of powerful neural language models such as GPT-2, this can now (2019) be considered a largely solved problem and is being marketed in various commercial applications.\n- Logic translation\n- Translate a text from a natural language into formal logic.\n- Machine translation (MT)\n- Automatically translate text from one human language to another. This is one of the most difficult problems, and is a member of a class of problems colloquially termed \"AI-complete\", i.e. requiring all of the different types of knowledge that humans possess (grammar, semantics, facts about the real world, etc.) to solve properly.\n- Natural language understanding (NLU)\n- Convert chunks of text into more formal representations such as first-order logic structures that are easier for computer programs to manipulate. Natural language understanding involves the identification of the intended semantic from the multiple possible semantics which can be derived from a natural language expression which usually takes the form of organized notations of natural language concepts. Introduction and creation of language metamodel and ontology are efficient however empirical solutions. An explicit formalization of natural language semantics without confusions with implicit assumptions such as closed-world assumption (CWA) vs. open-world assumption, or subjective Yes\/No vs. objective True\/False is expected for the construction of a basis of semantics formalization.[37]\n- Natural language generation (NLG):\n- Convert information from computer databases or semantic intents into readable human language.\n- Book generation\n- Not an NLP task proper but an extension of natural language generation and other NLP tasks is the creation of full-fledged books. The first machine-generated book was created by a rule-based system in 1984 (Racter, The policeman's beard is half-constructed).[38] The first published work by a neural network was published in 2018, 1 the Road, marketed as a novel, contains sixty million words. Both these systems are basically elaborate but non-sensical (semantics-free) language models. The first machine-generated science book was published in 2019 (Beta Writer, Lithium-Ion Batteries, Springer, Cham).[39] Unlike Racter and 1 the Road, this is grounded on factual knowledge and based on text summarization.\n- Document AI\n- A Document AI platform sits on top of the NLP technology enabling users with no prior experience of artificial intelligence, machine learning or NLP to quickly train a computer to extract the specific data they need from different document types. NLP-powered Document AI enables non-technical teams to quickly access information hidden in documents, for example, lawyers, business analysts and accountants.[40]\n- Dialogue management\n- Computer systems intended to converse with a human.\n- Question answering\n- Given a human-language question, determine its answer. Typical questions have a specific right answer (such as \"What is the capital of Canada?\"), but sometimes open-ended questions are also considered (such as \"What is the meaning of life?\").\n- Text-to-image generation\n- Given a description of an image, generate an image that matches the description.[41]\n- Text-to-scene generation\n- Given a description of a scene, generate a 3D model of the scene.[42][43]\n- Text-to-video\n- Given a description of a video, generate a video that matches the description.[44][45]\nGeneral tendencies and (possible) future directions\n[edit]Based on long-standing trends in the field, it is possible to extrapolate future directions of NLP. As of 2020, three trends among the topics of the long-standing series of CoNLL Shared Tasks can be observed:[46]\n- Interest on increasingly abstract, \"cognitive\" aspects of natural language (1999\u20132001: shallow parsing, 2002\u201303: named entity recognition, 2006\u201309\/2017\u201318: dependency syntax, 2004\u201305\/2008\u201309 semantic role labelling, 2011\u201312 coreference, 2015\u201316: discourse parsing, 2019: semantic parsing).\n- Increasing interest in multilinguality, and, potentially, multimodality (English since 1999; Spanish, Dutch since 2002; German since 2003; Bulgarian, Danish, Japanese, Portuguese, Slovenian, Swedish, Turkish since 2006; Basque, Catalan, Chinese, Greek, Hungarian, Italian, Turkish since 2007; Czech since 2009; Arabic since 2012; 2017: 40+ languages; 2018: 60+\/100+ languages)\n- Elimination of symbolic representations (rule-based over supervised towards weakly supervised methods, representation learning and end-to-end systems)\nCognition\n[edit]Most higher-level NLP applications involve aspects that emulate intelligent behaviour and apparent comprehension of natural language. More broadly speaking, the technical operationalization of increasingly advanced aspects of cognitive behaviour represents one of the developmental trajectories of NLP (see trends among CoNLL shared tasks above).\nCognition refers to \"the mental action or process of acquiring knowledge and understanding through thought, experience, and the senses.\"[47] Cognitive science is the interdisciplinary, scientific study of the mind and its processes.[48] Cognitive linguistics is an interdisciplinary branch of linguistics, combining knowledge and research from both psychology and linguistics.[49] Especially during the age of symbolic NLP, the area of computational linguistics maintained strong ties with cognitive studies.\nAs an example, George Lakoff offers a methodology to build natural language processing (NLP) algorithms through the perspective of cognitive science, along with the findings of cognitive linguistics,[50] with two defining aspects:\n- Apply the theory of conceptual metaphor, explained by Lakoff as \"the understanding of one idea, in terms of another\" which provides an idea of the intent of the author.[51] For example, consider the English word big. When used in a comparison (\"That is a big tree\"), the author's intent is to imply that the tree is physically large relative to other trees or the authors experience. When used metaphorically (\"Tomorrow is a big day\"), the author's intent to imply importance. The intent behind other usages, like in \"She is a big person\", will remain somewhat ambiguous to a person and a cognitive NLP algorithm alike without additional information.\n- Assign relative measures of meaning to a word, phrase, sentence or piece of text based on the information presented before and after the piece of text being analyzed, e.g., by means of a probabilistic context-free grammar (PCFG). The mathematical equation for such algorithms is presented in US Patent 9269353:[52]\n- Where\n- RMM is the relative measure of meaning\n- token is any block of text, sentence, phrase or word\n- N is the number of tokens being analyzed\n- PMM is the probable measure of meaning based on a corpora\n- d is the non zero location of the token along the sequence of N tokens\n- PF is the probability function specific to a language\n- Where\nTies with cognitive linguistics are part of the historical heritage of NLP, but they have been less frequently addressed since the statistical turn during the 1990s. Nevertheless, approaches to develop cognitive models towards technically operationalizable frameworks have been pursued in the context of various frameworks, e.g., of cognitive grammar,[53] functional grammar,[54] construction grammar,[55] computational psycholinguistics and cognitive neuroscience (e.g., ACT-R), however, with limited uptake in mainstream NLP (as measured by presence on major conferences[56] of the ACL). More recently, ideas of cognitive NLP have been revived as an approach to achieve explainability, e.g., under the notion of \"cognitive AI\".[57] Likewise, ideas of cognitive NLP are inherent to neural models multimodal NLP (although rarely made explicit)[58] and developments in artificial intelligence, specifically tools and technologies using large language model approaches[59] and new directions in artificial general intelligence based on the free energy principle[60] by British neuroscientist and theoretician at University College London Karl J. Friston.\nSee also\n[edit]- 1 the Road\n- Artificial intelligence detection software\n- Automated essay scoring\n- Biomedical text mining\n- Compound term processing\n- Computational linguistics\n- Computer-assisted reviewing\n- Controlled natural language\n- Deep learning\n- Deep linguistic processing\n- Distributional semantics\n- Foreign language reading aid\n- Foreign language writing aid\n- Information extraction\n- Information retrieval\n- Language and Communication Technologies\n- Language model\n- Language technology\n- Latent semantic indexing\n- Multi-agent system\n- Native-language identification\n- Natural-language programming\n- Natural-language understanding\n- Natural-language search\n- Outline of natural language processing\n- Query expansion\n- Query understanding\n- Reification (linguistics)\n- Speech processing\n- Spoken dialogue systems\n- Text-proofing\n- Text simplification\n- Transformer (machine learning model)\n- Truecasing\n- Question answering\n- Word2vec\nReferences\n[edit]- ^ \"NLP\".\n- ^ Hutchins, J. (2005). \"The history of machine translation in a nutshell\" (PDF).[self-published source]\n- ^ \"ALPAC: the (in)famous report\", John Hutchins, MT News International, no. 14, June 1996, pp. 9\u201312.\n- ^ Crevier 1993, pp. 146\u2013148 , see also Buchanan 2005, p. 56 : \"Early programs were necessarily limited in scope by the size and speed of memory\"\n- ^ Koskenniemi, Kimmo (1983), Two-level morphology: A general computational model of word-form recognition and production (PDF), Department of General Linguistics, University of Helsinki\n- ^ Joshi, A. K., & Weinstein, S. (1981, August). Control of Inference: Role of Some Aspects of Discourse Structure-Centering. In IJCAI (pp. 385\u2013387).\n- ^ Guida, G.; Mauri, G. (July 1986). \"Evaluation of natural language processing systems: Issues and approaches\". Proceedings of the IEEE. 74 (7): 1026\u20131035. doi:10.1109\/PROC.1986.13580. ISSN 1558-2256. S2CID 30688575.\n- ^ Chomskyan linguistics encourages the investigation of \"corner cases\" that stress the limits of its theoretical models (comparable to pathological phenomena in mathematics), typically created using thought experiments, rather than the systematic investigation of typical phenomena that occur in real-world data, as is the case in corpus linguistics. The creation and use of such corpora of real-world data is a fundamental part of machine-learning algorithms for natural language processing. In addition, theoretical underpinnings of Chomskyan linguistics such as the so-called \"poverty of the stimulus\" argument entail that general learning algorithms, as are typically used in machine learning, cannot be successful in language processing. As a result, the Chomskyan paradigm discouraged the application of such models to language processing.\n- ^ Bengio, Yoshua; Ducharme, R\u00e9jean; Vincent, Pascal; Janvin, Christian (March 1, 2003). \"A neural probabilistic language model\". The Journal of Machine Learning Research. 3: 1137\u20131155 \u2013 via ACM Digital Library.\n- ^ Mikolov, Tom\u00e1\u0161; Karafi\u00e1t, Martin; Burget, Luk\u00e1\u0161; \u010cernock\u00fd, Jan; Khudanpur, Sanjeev (26 September 2010). \"Recurrent neural network based language model\" (PDF). Interspeech 2010. pp. 1045\u20131048. doi:10.21437\/Interspeech.2010-343. S2CID 17048224.\n{{cite book}}\n:|journal=\nignored (help) - ^ Goldberg, Yoav (2016). \"A Primer on Neural Network Models for Natural Language Processing\". Journal of Artificial Intelligence Research. 57: 345\u2013420. arXiv:1807.10854. doi:10.1613\/jair.4992. S2CID 8273530.\n- ^ Goodfellow, Ian; Bengio, Yoshua; Courville, Aaron (2016). Deep Learning. MIT Press.\n- ^ Jozefowicz, Rafal; Vinyals, Oriol; Schuster, Mike; Shazeer, Noam; Wu, Yonghui (2016). Exploring the Limits of Language Modeling. arXiv:1602.02410. Bibcode:2016arXiv160202410J.\n- ^ Choe, Do Kook; Charniak, Eugene. \"Parsing as Language Modeling\". Emnlp 2016. Archived from the original on 2018-10-23. Retrieved 2018-10-22.\n- ^ Vinyals, Oriol; et al. (2014). \"Grammar as a Foreign Language\" (PDF). Nips2015. arXiv:1412.7449. Bibcode:2014arXiv1412.7449V.\n- ^ Turchin, Alexander; Florez Builes, Luisa F. (2021-03-19). \"Using Natural Language Processing to Measure and Improve Quality of Diabetes Care: A Systematic Review\". Journal of Diabetes Science and Technology. 15 (3): 553\u2013560. doi:10.1177\/19322968211000831. ISSN 1932-2968. PMC 8120048. PMID 33736486.\n- ^ Lee, Jennifer; Yang, Samuel; Holland-Hall, Cynthia; Sezgin, Emre; Gill, Manjot; Linwood, Simon; Huang, Yungui; Hoffman, Jeffrey (2022-06-10). \"Prevalence of Sensitive Terms in Clinical Notes Using Natural Language Processing Techniques: Observational Study\". JMIR Medical Informatics. 10 (6): e38482. doi:10.2196\/38482. ISSN 2291-9694. PMC 9233261. PMID 35687381.\n- ^ Winograd, Terry (1971). Procedures as a Representation for Data in a Computer Program for Understanding Natural Language (Thesis).\n- ^ Schank, Roger C.; Abelson, Robert P. (1977). Scripts, Plans, Goals, and Understanding: An Inquiry Into Human Knowledge Structures. Hillsdale: Erlbaum. ISBN 0-470-99033-3.\n- ^ Mark Johnson. How the statistical revolution changes (computational) linguistics. Proceedings of the EACL 2009 Workshop on the Interaction between Linguistics and Computational Linguistics.\n- ^ Philip Resnik. Four revolutions. Language Log, February 5, 2011.\n- ^ Socher, Richard. \"Deep Learning For NLP-ACL 2012 Tutorial\". www.socher.org. Retrieved 2020-08-17. This was an early Deep Learning tutorial at the ACL 2012 and met with both interest and (at the time) skepticism by most participants. Until then, neural learning was basically rejected because of its lack of statistical interpretability. Until 2015, deep learning had evolved into the major framework of NLP. [Link is broken, try http:\/\/web.stanford.edu\/class\/cs224n\/]\n- ^ Segev, Elad (2022). Semantic Network Analysis in Social Sciences. London: Routledge. ISBN 9780367636524. Archived from the original on 5 December 2021. Retrieved 5 December 2021.\n- ^ Yi, Chucai; Tian, Yingli (2012), \"Assistive Text Reading from Complex Background for Blind Persons\", Camera-Based Document Analysis and Recognition, Lecture Notes in Computer Science, vol. 7139, Springer Berlin Heidelberg, pp. 15\u201328, CiteSeerX 10.1.1.668.869, doi:10.1007\/978-3-642-29364-1_2, ISBN 9783642293634\n- ^ a b \"Natural Language Processing (NLP) - A Complete Guide\". www.deeplearning.ai. 2023-01-11. Retrieved 2024-05-05.\n- ^ \"What is Natural Language Processing? Intro to NLP in Machine Learning\". GyanSetu!. 2020-12-06. Retrieved 2021-01-09.\n- ^ Kishorjit, N.; Vidya, Raj RK.; Nirmal, Y.; Sivaji, B. (2012). \"Manipuri Morpheme Identification\" (PDF). Proceedings of the 3rd Workshop on South and Southeast Asian Natural Language Processing (SANLP). COLING 2012, Mumbai, December 2012: 95\u2013108.\n{{cite journal}}\n: CS1 maint: location (link) - ^ Klein, Dan; Manning, Christopher D. (2002). \"Natural language grammar induction using a constituent-context model\" (PDF). Advances in Neural Information Processing Systems.\n- ^ Kariampuzha, William; Alyea, Gioconda; Qu, Sue; Sanjak, Jaleal; Math\u00e9, Ewy; Sid, Eric; Chatelaine, Haley; Yadaw, Arjun; Xu, Yanji; Zhu, Qian (2023). \"Precision information extraction for rare disease epidemiology at scale\". Journal of Translational Medicine. 21 (1): 157. doi:10.1186\/s12967-023-04011-y. PMC 9972634. PMID 36855134.\n- ^ PASCAL Recognizing Textual Entailment Challenge (RTE-7) https:\/\/tac.nist.gov\/\/2011\/RTE\/\n- ^ Lippi, Marco; Torroni, Paolo (2016-04-20). \"Argumentation Mining: State of the Art and Emerging Trends\". ACM Transactions on Internet Technology. 16 (2): 1\u201325. doi:10.1145\/2850417. hdl:11585\/523460. ISSN 1533-5399. S2CID 9561587.\n- ^ \"Argument Mining \u2013 IJCAI2016 Tutorial\". www.i3s.unice.fr. Retrieved 2021-03-09.\n- ^ \"NLP Approaches to Computational Argumentation \u2013 ACL 2016, Berlin\". Retrieved 2021-03-09.\n- ^ Administration. \"Centre for Language Technology (CLT)\". Macquarie University. Retrieved 2021-01-11.\n- ^ \"Shared Task: Grammatical Error Correction\". www.comp.nus.edu.sg. Retrieved 2021-01-11.\n- ^ \"Shared Task: Grammatical Error Correction\". www.comp.nus.edu.sg. Retrieved 2021-01-11.\n- ^ Duan, Yucong; Cruz, Christophe (2011). \"Formalizing Semantic of Natural Language through Conceptualization from Existence\". International Journal of Innovation, Management and Technology. 2 (1): 37\u201342. Archived from the original on 2011-10-09.\n- ^ \"U B U W E B :: Racter\". www.ubu.com. Retrieved 2020-08-17.\n- ^ Writer, Beta (2019). Lithium-Ion Batteries. doi:10.1007\/978-3-030-16800-1. ISBN 978-3-030-16799-8. S2CID 155818532.\n- ^ \"Document Understanding AI on Google Cloud (Cloud Next '19) \u2013 YouTube\". www.youtube.com. 11 April 2019. Archived from the original on 2021-10-30. Retrieved 2021-01-11.\n- ^ Robertson, Adi (2022-04-06). \"OpenAI's DALL-E AI image generator can now edit pictures, too\". The Verge. Retrieved 2022-06-07.\n- ^ \"The Stanford Natural Language Processing Group\". nlp.stanford.edu. Retrieved 2022-06-07.\n- ^ Coyne, Bob; Sproat, Richard (2001-08-01). \"WordsEye\". Proceedings of the 28th annual conference on Computer graphics and interactive techniques. SIGGRAPH '01. New York, NY, USA: Association for Computing Machinery. pp. 487\u2013496. doi:10.1145\/383259.383316. ISBN 978-1-58113-374-5. S2CID 3842372.\n- ^ \"Google announces AI advances in text-to-video, language translation, more\". VentureBeat. 2022-11-02. Retrieved 2022-11-09.\n- ^ Vincent, James (2022-09-29). \"Meta's new text-to-video AI generator is like DALL-E for video\". The Verge. Retrieved 2022-11-09.\n- ^ \"Previous shared tasks | CoNLL\". www.conll.org. Retrieved 2021-01-11.\n- ^ \"Cognition\". Lexico. Oxford University Press and Dictionary.com. Archived from the original on July 15, 2020. Retrieved 6 May 2020.\n- ^ \"Ask the Cognitive Scientist\". American Federation of Teachers. 8 August 2014.\nCognitive science is an interdisciplinary field of researchers from Linguistics, psychology, neuroscience, philosophy, computer science, and anthropology that seek to understand the mind.\n- ^ Robinson, Peter (2008). Handbook of Cognitive Linguistics and Second Language Acquisition. Routledge. pp. 3\u20138. ISBN 978-0-805-85352-0.\n- ^ Lakoff, George (1999). Philosophy in the Flesh: The Embodied Mind and Its Challenge to Western Philosophy; Appendix: The Neural Theory of Language Paradigm. New York Basic Books. pp. 569\u2013583. ISBN 978-0-465-05674-3.\n- ^ Strauss, Claudia (1999). A Cognitive Theory of Cultural Meaning. Cambridge University Press. pp. 156\u2013164. ISBN 978-0-521-59541-4.\n- ^ US patent 9269353\n- ^ \"Universal Conceptual Cognitive Annotation (UCCA)\". Universal Conceptual Cognitive Annotation (UCCA). Retrieved 2021-01-11.\n- ^ Rodr\u00edguez, F. C., & Mairal-Us\u00f3n, R. (2016). Building an RRG computational grammar. Onomazein, (34), 86\u2013117.\n- ^ \"Fluid Construction Grammar \u2013 A fully operational processing system for construction grammars\". Retrieved 2021-01-11.\n- ^ \"ACL Member Portal | The Association for Computational Linguistics Member Portal\". www.aclweb.org. Retrieved 2021-01-11.\n- ^ \"Chunks and Rules\". W3C. Retrieved 2021-01-11.\n- ^ Socher, Richard; Karpathy, Andrej; Le, Quoc V.; Manning, Christopher D.; Ng, Andrew Y. (2014). \"Grounded Compositional Semantics for Finding and Describing Images with Sentences\". Transactions of the Association for Computational Linguistics. 2: 207\u2013218. doi:10.1162\/tacl_a_00177. S2CID 2317858.\n- ^ Dasgupta, Ishita; Lampinen, Andrew K.; Chan, Stephanie C. Y.; Creswell, Antonia; Kumaran, Dharshan; McClelland, James L.; Hill, Felix (2022). \"Language models show human-like content effects on reasoning, Dasgupta, Lampinen et al\". arXiv:2207.07051 [cs.CL].\n- ^ Friston, Karl J. (2022). Active Inference: The Free Energy Principle in Mind, Brain, and Behavior; Chapter 4 The Generative Models of Active Inference. The MIT Press. ISBN 978-0-262-36997-8.\nFurther reading\n[edit]- Bates, M (1995). \"Models of natural language understanding\". Proceedings of the National Academy of Sciences of the United States of America. 92 (22): 9977\u20139982. Bibcode:1995PNAS...92.9977B. doi:10.1073\/pnas.92.22.9977. PMC 40721. PMID 7479812.\n- Steven Bird, Ewan Klein, and Edward Loper (2009). Natural Language Processing with Python. O'Reilly Media. ISBN 978-0-596-51649-9.\n- Kenna Hughes-Castleberry, \"A Murder Mystery Puzzle: The literary puzzle Cain's Jawbone, which has stumped humans for decades, reveals the limitations of natural-language-processing algorithms\", Scientific American, vol. 329, no. 4 (November 2023), pp. 81\u201382. \"This murder mystery competition has revealed that although NLP (natural-language processing) models are capable of incredible feats, their abilities are very much limited by the amount of context they receive. This [...] could cause [difficulties] for researchers who hope to use them to do things such as analyze ancient languages. In some cases, there are few historical records on long-gone civilizations to serve as training data for such a purpose.\" (p. 82.)\n- Daniel Jurafsky and James H. Martin (2008). Speech and Language Processing, 2nd edition. Pearson Prentice Hall. ISBN 978-0-13-187321-6.\n- Mohamed Zakaria Kurdi (2016). Natural Language Processing and Computational Linguistics: speech, morphology, and syntax, Volume 1. ISTE-Wiley. ISBN 978-1848218482.\n- Mohamed Zakaria Kurdi (2017). Natural Language Processing and Computational Linguistics: semantics, discourse, and applications, Volume 2. ISTE-Wiley. ISBN 978-1848219212.\n- Christopher D. Manning, Prabhakar Raghavan, and Hinrich Sch\u00fctze (2008). Introduction to Information Retrieval. Cambridge University Press. ISBN 978-0-521-86571-5. Official html and pdf versions available without charge.\n- Christopher D. Manning and Hinrich Sch\u00fctze (1999). Foundations of Statistical Natural Language Processing. The MIT Press. ISBN 978-0-262-13360-9.\n- David M. W. Powers and Christopher C. R. Turk (1989). Machine Learning of Natural Language. Springer-Verlag. ISBN 978-0-387-19557-5.\nExternal links\n[edit]- Media related to Natural language processing at Wikimedia Commons",
    "scraped_at":"2025-07-07T18:26:07.417258"
  },
  {
    "topic":"Natural Language Processing",
    "title":"What is Natural Language Processing? Definition and Exa\u2026",
    "url":"https:\/\/www.coursera.org\/articles\/natural-language-processing",
    "domain":"www.coursera.org",
    "snippet":"Written by Coursera Staff \u2022 Updated on Natural language processing ensures that AI can understand the natural human languages people speak every day. Learn more about this impactful AI subfield. Natural language processing (NLP) is a form of artificial intelligence (AI) that allows computers to unde...",
    "content":"Written by Coursera Staff \u2022 Updated on\nNatural language processing ensures that AI can understand the natural human languages people speak every day. Learn more about this impactful AI subfield.\nNatural language processing (NLP) is a form of artificial intelligence (AI) that allows computers to understand human language, whether you write it, speak it, or even scribble it. As AI-powered devices and services become increasingly more intertwined with your daily life and the world, so too does the impact that NLP has on ensuring a seamless human-computer experience.\nIn this article, you'll learn more about what NLP is, the techniques used to create it, and some of the benefits it provides consumers and businesses. Afterward, if you'd like to master cutting-edge NLP techniques yourself, consider enrolling in DeepLearning.AI's Natural Language Processing Specialization.\nNatural language processing (NLP) is a subset of artificial intelligence, computer science, and linguistics focused on making human communication, such as speech and text, comprehensible to computers.\nNLP is used in a wide variety of everyday products and services. Some of the most common technologies that use NLP are voice-activated digital assistants on smartphones, email-scanning programs used to identify spam, and translation apps that decipher foreign languages.\nNLP encompasses a wide range of techniques to analyze human language. Some of the most common techniques you will likely encounter in the field include:\nSentiment analysis: An NLP technique that analyzes text to identify its sentiments, such as \u201cpositive,\u201d \u201cnegative,\u201d or \u201cneutral.\u201d Sentiment analysis is commonly used by businesses to better understand customer feedback.\nSummarization: An NLP technique that summarizes a longer text in order to make it more manageable for time-sensitive readers. Some common texts this technology can summarize include reports and articles.\nKeyword extraction: An NLP technique that analyzes a text to identify the most important keywords or phrases. Keyword extraction is commonly used for search engine optimization (SEO), social media monitoring, and business intelligence purposes.\nTokenization: The process of breaking characters, words, or subwords down into \u201ctokens\u201d that the program can analyze. Tokenization undergirds common NLP tasks like word modeling, vocabulary building, and frequent word occurrence.\nWhether it\u2019s being used to quickly translate a text from one language to another or producing business insights by running sentiment analysis on hundreds of reviews, NLP provides both businesses and consumers with a variety of benefits.\nUnsurprisingly, then, you can expect to see more of it in the coming years. According to research by Fortune Business Insights, they project the global market for NLP to grow from $29.71 billion in 2024 to $158.04 billion in 2032 [1].\nSome common benefits of NLP include:\nThe ability to analyze both structured and unstructured data, such as speech, text messages, and social media posts.\nImproving customer satisfaction and experience by identifying insights using sentiment analysis.\nReducing costs by employing NLP-enabled AI to perform specific tasks, such as chatting with customers via chatbots or analyzing large amounts of text data.\nBetter understanding a target market or brand by conducting NLP analysis on relevant data like social media posts, focus group surveys, and reviews.\nNLP can be used for a wide variety of applications, but it's far from perfect. In fact, many NLP tools struggle to interpret sarcasm, emotion, slang, context, errors, and other types of ambiguous statements. This means that NLP is mostly limited to unambiguous situations that don't require a significant amount of interpretation.\nAlthough natural language processing might sound like something out of a science fiction novel, the truth is that NLP examples already exist in your everyday life as you interact with countless NLP-powered devices and services every day.\nOnline chatbots, for example, use NLP to engage with consumers and direct them toward appropriate resources or products. While chatbots can\u2019t answer every question that customers may have, businesses like them because they offer cost-effective ways to troubleshoot common problems or questions that consumers have about their products.\nAnother common use of NLP is for text prediction and autocorrect, which you\u2019ve likely encountered many times before while messaging a friend or drafting a document. This technology allows texters and writers alike to speed up their writing process and correct common typos.\nChatGPT\u2014a chatbot powered by AI and natural language processing\u2014produces unusually human-like responses. Recently, it has dominated headlines due to its ability to produce responses that far outperform what was previously commercially possible.\nIf you'd like to learn more, the University of Michigan's ChatGPT Teach Out brings together experts on communication technology, the economy, artificial intelligence, natural language processing, health care delivery, and law to discuss the impacts of the technology now and into the future.\nNLP has a wide array of applications across various sectors, such as finance, insurance, and health care. Prominent applications for NLP technology include voice-activated assistants, machine translation, sentiment analysis, chatbots, virtual customer support, classification and categorization, content recommendation systems, text summarization, speech recognition, and natural language generation. Here are just some of the ways natural language processing is used in the real world:\nNLP powers virtual assistants, so if you ever use Apple\u2019s Siri, Amazon\u2019s Alexa, and IBM\u2019s watsonx Assistant, you\u2019ve already experienced NLP. This technology enables them to understand and respond to voice commands. It allows you to interact with your device using natural language to perform tasks, search for information, and control smart home devices.\nNLP is the driving force behind machine translation services such as Google Translate. It allows for the automatic translation of text and speech between languages, making global communication more accessible. NLP allows an online translator to understand the individual rules of grammar and language structure between two languages and effectively decode one into the other.\nYour business can use NLP for sentiment analysis to gauge a customer\u2019s opinion, their satisfaction, and the market\u2019s response to your products by analyzing social media posts, customer reviews, and survey responses. This can help your company make better decisions, especially when formulating future strategies.\nNLP enables chatbots to understand and respond to customers' questions and comments in a conversational manner. This application is widely used in customer service to provide instant assistance, book appointments, and resolve common issues.\nPlatforms like T-Mobile, Spotify, and Disney+ use NLP-based recommendation systems to analyze user preferences and provide personalized content suggestions based on previous interactions and the content's textual data. Using sentiment analysis\u2014also powered by natural language processing\u2014recommendation systems can even recommend movies, music, or other media based on how users have reviewed those products.\nSpeech recognition assists with converting spoken language into text in real-time, which is essential for dictation software, hands-free computing, and real-time transcription services. Everybody talks a little differently: At different speeds, in varying tones, with accents and regional dialects, and with differing pronunciations. After the speech recognition software transcribes your words, natural language processing analyzes those words, determines the meaning behind them, and then formulates an appropriate response.\nThis involves using NLP to generate natural language text from data, enabling applications like automated report generation, personalized content creation, and article writing. NLG can also craft stories. With natural language generation, you can ask an AI language model like Amazon\u2019s Alexa or Apple\u2019s Siri a question as if speaking to another person. The model will respond similarly.\nThese applications demonstrate the versatility and impact of NLP in simplifying interactions, enhancing accessibility, and providing deeper insights from textual data across diverse domains.\nYou can choose from the numerous natural language processing tools and services available to help you start working with NLP today. Some of the most common tools and services you might encounter include the following:\nGoogle Cloud NLP API\nIBM Watson\nAmazon Comprehend\nPython is a programming language well-suited to NLP. Some common Python libraries and toolkits you can use to start exploring NLP include NLTK, Stanford CoreNLP, and Genism.\nNatural language processing helps computers understand human language in all its forms, from handwritten notes to typed snippets of text and spoken instructions. Start exploring the field in greater depth by taking a cost-effective, flexible Specialization on Coursera.\nDeepLearning.AI\u2019s Natural Language Processing Specialization can help you prepare to design NLP applications that perform question-answering and sentiment analysis, create tools to translate languages and summarize text, and build chatbots.\nIn DeepLearning.AI\u2019s Machine Learning Specialization, meanwhile, you can have the opportunity to master fundamental AI concepts and develop practical machine learning skills in the beginner-friendly, three-course program by AI visionary (and Coursera co-founder) Andrew Ng.\nFortune Business Insights. \u201cThe global natural language processing (NLP) market, https:\/\/www.fortunebusinessinsights.com\/industry-reports\/natural-language-processing-nlp-market-101933.\u201d Accessed May 22, 2025.\nUpdated on\nWritten by:Coursera Staff\nC\nEditorial Team\nCoursera\u2019s editorial team is comprised of highly experienced professional editors, writers, and fact...\nThis content has been made available for informational purposes only. Learners are advised to conduct additional research to ensure that courses and other credentials pursued meet their personal, professional, and financial goals.",
    "scraped_at":"2025-07-07T18:26:07.922533"
  },
  {
    "topic":"Natural Language Processing",
    "title":"Natural Language Processing (NLP) Tutorial - GeeksforGeeks",
    "url":"https:\/\/www.geeksforgeeks.org\/natural-language-processing-nlp-tutorial\/",
    "domain":"www.geeksforgeeks.org",
    "snippet":"Natural Language Processing (NLP) Tutorial Natural Language Processing (NLP) is a branch of Artificial Intelligence (AI) that helps machines to understand and process human languages either in text or audio form. It is used across a variety of applications from speech recognition to language transla...",
    "content":"Natural Language Processing (NLP) Tutorial\nNatural Language Processing (NLP) is a branch of Artificial Intelligence (AI) that helps machines to understand and process human languages either in text or audio form. It is used across a variety of applications from speech recognition to language translation and text summarization.\nNatural Language Processing can be categorized into two components:\n1. Natural Language Understanding: It involves interpreting the meaning of the text.\n2. Natural Language Generation: It involves generating human-like text based on processed data.\nPhases of Natural Language Processing\nIt involves a series of phases that work together to process and interpret language with each phase contributing to understanding its structure and meaning.\nFor more details you can refer to: Phases of NLP\nLibraries for NLP\nSome of natural language processing libraries include:\n- NLTK (Natural Language Toolkit)\n- spaCy\n- TextBlob\n- Transformers (by Hugging Face)\n- Gensim\n- NLP Libraries in Python.\nNormalizing Textual Data in NLP\nText Normalization transforms text into a consistent format improves the quality and makes it easier to process in NLP tasks.\nKey steps in text normalization includes:\n1. Regular Expressions (RE) are sequences of characters that define search patterns.\n- Text Normalization\n- Regular Expressions (RE)\n- How to write Regular Expressions?\n- Properties of Regular Expressions\n- Email Extraction using RE\n2. Tokenization is a process of splitting text into smaller units called tokens.\n- Tokenization\n- Word Tokenization\n- Rule-based Tokenization\n- Subword Tokenization\n- Dictionary-Based Tokenization\n- Whitespace Tokenization\n- WordPiece Tokenization\n3. Lemmatization reduces words to their base or root form.\n4. Stemming reduces works to their root by removing suffixes. Types of stemmers include:\n5. Stopword removal is a process to remove common words from the document.\n6. Parts of Speech (POS) Tagging assigns a part of speech to each word in sentence based on definition and context.\nText Representation and Embedding Techniques in NLP\nLets see how these techniques works in NLP.\nText representation Techniques\nIt converts textual data into numerical vectors that are processed by the following methods:\n- One-Hot Encoding\n- Bag of Words (BOW)\n- Term Frequency-Inverse Document Frequency (TF-IDF)\n- N-Gram Language Modeling with NLTK\n- Latent Semantic Analysis (LSA)\n- Latent Dirichlet Allocation (LDA)\nText Embedding Techniques\nIt refers to methods that create dense vector representations of text, capturing semantic meaning including advanced approaches like:\n1. Word Embedding\n- Word2Vec (SkipGram, Continuous Bag of Words - CBOW)\n- GloVe (Global Vectors for Word Representation)\n- fastText\n2. Pre-Trained Embedding\n- ELMo (Embeddings from Language Models)\n- BERT (Bidirectional Encoder Representations from Transformers)\n3. Document Embedding\n4. Advanced Embeddings\nDeep Learning Techniques for NLP\nDeep learning has revolutionized Natural Language Processing by helping models to automatically learn complex patterns from raw text.\nKey deep learning techniques in NLP include:\n- Deep learning\n- Artificial Neural Networks (ANNs)\n- Recurrent Neural Networks (RNNs)\n- Long Short-Term Memory (LSTM)\n- Gated Recurrent Unit (GRU)\n- Seq2Seq Models\n- Transformer Models\nPre-Trained Language Models\nPre-trained models can be fine-tuned for specific tasks:\n- Pre-trained models\n- GPT (Generative Pre-trained Transformer)\n- Transformers XL\n- T5 (Text-to-Text Transfer Transformer)\n- Transfer Learning with Fine-tuning\nNatural Language Processing Tasks\nCore NLP tasks that help machines understand, interpret and generate human language.\n1. Text Classification\n- Dataset for Text Classification\n- Text Classification using Naive Bayes\n- Text Classification using Logistic Regression\n- Text Classification using RNNs\n- Text Classification using CNNs\n2. Information Extraction\n- Named Entity Recognition (NER) using SpaCy\n- Named Entity Recognition (NER) using NLTK\n- Relationship Extraction\n3. Sentiment Analysis\n- What is Sentiment Analysis?\n- Sentiment Analysis using VADER\n- Sentiment Analysis using Recurrent Neural Networks (RNN)\n4. Machine Translation\n5. Text Summarization\n- What is Text Summarization?\n- Text Summarizations using Hugging Face Model\n- Text Summarization using Sumy\n6. Text Generation\n- Text Generation using Fnet\n- Text Generation using Recurrent Long Short Term Memory Network\n- Text2Text Generations using HuggingFace Model\nNatural Language Processing Chatbots\nNLP chatbots are computer programs designed to interact with users in natural language helps in seamless communication between humans and machines. By using NLP techniques, these chatbots understand, interpret and generate human language.\nApplications of NLP\n- Voice Assistants: Alexa, Siri and Google Assistant use NLP for voice recognition and interaction.\n- Grammar and Text Analysis: Tools like Grammarly, Microsoft Word and Google Docs apply NLP for grammar checking.\n- Information Extraction: Search engines like Google and DuckDuckGo use NLP to extract relevant information.\n- Chatbots: Website bots and customer support chatbots leverage NLP for automated conversations.\nFor more details you can refer to: Applications of NLP\nImportance of NLP\nNatural Language Processing (NLP) plays an important role in transforming how we interact with technology and understand data. Below are reasons why it\u2019s so important:\n- Information Extraction: Extracts useful data from unstructured content.\n- Sentiment Analysis: Analyzes customer opinions for businesses.\n- Automation: Streamlines tasks like customer service and document processing.\n- Language Translation: Breaks down language barriers with tools like Google Translate.\n- Healthcare: Assists in analyzing medical records and research.\nFor more details you can refer to: Why is NLP important?",
    "scraped_at":"2025-07-07T18:26:08.183360"
  },
  {
    "topic":"Natural Language Processing",
    "title":"What is Natural Language Processing (NLP)? A Beginner\u2019\u2026",
    "url":"https:\/\/www.datacamp.com\/blog\/what-is-natural-language-processing",
    "domain":"www.datacamp.com",
    "snippet":"Track Natural Language Processing (NLP) stands as a pivotal technology in the realm of artificial intelligence, bridging the gap between human communication and computer understanding. It is a multidisciplinary domain that empowers computers to interpret, analyze, and generate human language, enabli...",
    "content":"Track\nNatural Language Processing (NLP) stands as a pivotal technology in the realm of artificial intelligence, bridging the gap between human communication and computer understanding. It is a multidisciplinary domain that empowers computers to interpret, analyze, and generate human language, enabling seamless interaction between humans and machines. The significance of NLP is evident in its widespread applications, ranging from automated customer support to real-time language translation.\nThis article aims to provide newcomers with a comprehensive overview of NLP, its workings, applications, challenges, and future outlook.\nWhat is Natural Language Processing?\nNatural Language Processing (NLP) is a branch of artificial intelligence that focuses on the interaction between computers and humans through natural language. The objective is to program computers to process and analyze large amounts of natural language data.\nNLP involves enabling machines to understand, interpret, and produce human language in a way that is both valuable and meaningful. OpenAI, known for developing advanced language models like ChatGPT, highlights the importance of NLP in creating intelligent systems that can understand, respond to, and generate text, making technology more user-friendly and accessible.\nHow Does NLP Work?\nLet\u2019s take a look at some of the mechanisms at work behind natural language processing. We\u2019ve provided links to resources that can help you learn more about some of these key areas. For a detailed exploration, check out our Natural Language Processing in Python skill track.\nComponents of NLP\nNatural Language Processing is not a monolithic, singular approach, but rather, it is composed of several components, each contributing to the overall understanding of language. The main components that NLP strives to understand are Syntax, Semantics, Pragmatics, and Discourse.\nSyntax\n- Definition: Syntax pertains to the arrangement of words and phrases to create well-structured sentences in a language.\n- Example: Consider the sentence \"The cat sat on the mat.\" Syntax involves analyzing the grammatical structure of this sentence, ensuring that it adheres to the grammatical rules of English, such as subject-verb agreement and proper word order\nSemantics\n- Definition: Semantics is concerned with understanding the meaning of words and how they create meaning when combined in sentences.\n- Example: In the sentence \"The panda eats shoots and leaves,\" semantics helps distinguish whether the panda eats plants (shoots and leaves) or is involved in a violent act (shoots) and then departs (leaves), based on the meaning of the words and the context.\nPragmatics\n- Definition: Pragmatics deals with understanding language in various contexts, ensuring that the intended meaning is derived based on the situation, speaker\u2019s intent, and shared knowledge.\n- Example: If someone says, \"Can you pass the salt?\" Pragmatics involves understanding that this is a request rather than a question about one's ability to pass the salt, interpreting the speaker\u2019s intent based on the dining context.\nDiscourse\n- Definition: Discourse focuses on the analysis and interpretation of language beyond the sentence level, considering how sentences relate to each other in texts and conversations.\n- Example: In a conversation where one person says, \"I\u2019m freezing,\" and another responds, \"I\u2019ll close the window,\" discourse involves understanding the coherence between the two statements, recognizing that the second statement is a response to the implied request in the first.\nUnderstanding these components is crucial for anyone delving into NLP, as they form the backbone of how NLP models interpret and generate human language.\nNLP techniques and methods\nTo analyze and understand human language, NLP employs a variety of techniques and methods. Here are some fundamental techniques used in NLP:\n- Tokenization. This is the process of breaking text into words, phrases, symbols, or other meaningful elements, known as tokens.\n- Parsing. Parsing involves analyzing the grammatical structure of a sentence to extract meaning.\n- Lemmatization. This technique reduces words to their base or root form, allowing for the grouping of different forms of the same word.\n- Named Entity Recognition (NER). NER is used to identify entities such as persons, organizations, locations, and other named items in the text.\n- Sentiment analysis. This method is used to gain an understanding of the sentiment or emotion conveyed in a piece of text.\nEach of these techniques plays a vital role in enabling computers to process and understand human language, forming the building blocks of more advanced NLP applications.\nWhat is NLP Used For?\nNow that we have some of the basic concepts defined, let\u2019s take a look at how natural language processing is used in the modern world.\nIndustry applications\nNatural Language Processing has found extensive applications across various industries, revolutionizing the way businesses operate and interact with users. Here are some of the key industry applications of NLP.\nHealthcare\nNLP assists in transcribing and organizing clinical notes, ensuring accurate and efficient documentation of patient information. For instance, a physician might dictate their notes, which NLP systems transcribe into text. Advanced NLP models can further categorize the information, identifying symptoms, diagnoses, and prescribed treatments, thereby streamlining the documentation process, minimizing manual data entry, and enhancing the accuracy of electronic health records.\nFinance\nFinancial institutions leverage NLP to perform sentiment analysis on various text data like news articles, financial reports, and social media posts to gauge market sentiment regarding specific stocks or the market in general. Algorithms analyze the frequency of positive or negative words, and through machine learning models, predict potential impacts on stock prices or market movements, aiding traders and investors in making informed decisions.\nCustomer Service\nNLP-powered chatbots have revolutionized customer support by providing instant, 24\/7 responses to customer inquiries. These chatbots understand customer queries through text or voice, interpret the underlying intent, and provide accurate responses or solutions. For instance, a customer might inquire about their order status, and the chatbot, integrating with the order management system, retrieves and delivers the real-time status, enhancing customer experience and reducing support workload.\nE-Commerce\nNLP significantly enhances on-site search functionality in e-commerce platforms by understanding and interpreting user queries, even if they are phrased in a conversational manner or contain typos. For example, if a user searches for \u201cblu jeens,\u201d NLP algorithms correct the typos and understand the intent, providing relevant results for \u201cblue jeans,\u201d thereby ensuring that users find what they are looking for, even with imprecise queries.\nLegal\nIn the legal sector, NLP is utilized to automate document review processes, significantly reducing the manual effort involved in sifting through vast volumes of legal documents. For instance, during litigation, legal professionals need to review numerous documents to identify relevant information. NLP algorithms can scan through these documents, identify and highlight pertinent information, such as specific terms, dates, or clauses, thereby expediting the review process and ensuring that no critical information is overlooked.\nEveryday applications\nBeyond industry-specific applications, NLP is ingrained in our daily lives, making technology more accessible and user-friendly. Here are some everyday applications of NLP:\n- Search engines. NLP is fundamental to the functioning of search engines, enabling them to understand user queries and provide relevant results.\n- Virtual assistants. Siri, Alexa, and Google Assistant are examples of virtual assistants that use NLP to understand and respond to user commands.\n- Translation services. Services like Google Translate employ NLP to provide real-time language translation, breaking down language barriers and fostering communication.\n- Email filtering. NLP is used in email services to filter out spam and categorize emails, helping users manage their inboxes more effectively.\n- Social media monitoring. NLP enables the analysis of social media content to gauge public opinion, track trends, and manage online reputation.\nThe applications of NLP are diverse and pervasive, impacting various industries and our daily interactions with technology. Understanding these applications provides a glimpse into the transformative potential of NLP in shaping the future of technology and human interaction.\nChallenges and The Future of NLP\nAlthough natural language processing is an incredibly useful tool, it\u2019s not without it flaws. Here, we look at some of the challenges we need to overcome, as well as what the future holds for NLP.\nOvercoming NLP challenges\nNatural Language Processing, despite its advancements, faces several challenges due to the inherent complexities and nuances of human language. Here are some of the challenges in NLP:\n- Ambiguity. Human language is often ambiguous, with words having multiple meanings, making it challenging for NLP models to interpret the correct meaning in different contexts.\n- Context. Understanding the context in which words are used is crucial for accurate interpretation, and it remains a significant challenge for NLP.\n- Sarcasm and irony. Detecting sarcasm and irony is particularly challenging as it requires understanding the intended meaning, which may be opposite to the literal meaning.\n- Cultural nuances. Language is deeply intertwined with culture, and understanding cultural nuances and idioms is essential for effective NLP.\nResearchers and developers are continually working to overcome these challenges, employing advanced machine learning and deep learning techniques to enhance the capabilities of NLP models and make them more adept at understanding human language.\nCheck out our advanced NLP with spaCy course to discover how to build advanced natural language understanding systems using machine learning approaches.\nThe spaCy cheat sheet shows some advanced NLP techniques\nThe future of NLP\nThe future of Natural Language Processing is promising, with ongoing research and developments poised to further enhance its capabilities and applications. Here are some emerging trends and future developments in NLP:\n- Transfer learning. The application of transfer learning in NLP allows models to apply knowledge learned from one task to another, improving efficiency and learning capability.\n- Multimodal NLP. Integrating NLP with visual and auditory inputs will lead to the development of more versatile and comprehensive models capable of multimodal understanding.\n- Real-time processing. Advancements in NLP will enable real-time language processing, allowing for more dynamic and interactive applications.\n- Ethical and responsible AI. The focus on ethical considerations and responsible AI will shape the development of NLP models, ensuring fairness, transparency, and accountability.\nThe exploration of challenges provides insights into the complexities of NLP, while the glimpse into the future highlights the potential advancements and the evolving landscape of Natural Language Processing.\nGetting Started with NLP\nLearning resources\nFor those eager to delve into Natural Language Processing, DataCamp offers a range of courses and tutorials specifically designed to provide in-depth knowledge and hands-on experience in NLP. Here are some examples:\n- Introduction to Natural Language Processing in Python Course. This course covers NLP basics such as identifying and separating words and extracting topics in a text.\n- Introduction to Natural Language Processing in R. Another course covering NLP, this time with a focus on the R Programming language.\n- Natural Language Processing in Python Track. This track helps you gain the core NLP skills needed to convert unstructured data into valuable insights.\n- Advanced NLP with spaCy Course. This course is ideal for learning how to build advanced natural language understanding systems using both rule-based and machine learning approaches with spaCy.\n- NLP With PyTorch: A Comprehensive guide. This tutorial covers NLP in PyTorch, a popular open-source machine learning library which provides robust tools for NLP tasks.\n- NLP Tutorial with Google BERT. This tutorial covers the basics of NLP and how to use Google BERT to process text datasets.\n- Deep Learning with PyTorch course. Here, you\u2019ll start with an introduction to PyTorch, exploring the PyTorch library and its applications for neural networks and deep learning, essential parts of NLP.\n- NLP Projects. This article provides NLP project suggestions for all levels.\nThese courses, along with other tutorials available on DataCamp, can provide newcomers with the foundational knowledge and practical skills needed to explore and contribute to the field of Natural Language Processing.\nFinal Thoughts\nNatural Language Processing is a revolutionary field in artificial intelligence, enabling computers to understand, interpret, and generate human language, thereby fostering seamless interactions between humans and machines.\nThis article has traversed the realms of NLP, providing insights into its definition, components, techniques, applications, challenges, and the future landscape. The applications of NLP are multifaceted, spanning across various industries and embedding into our daily technological interactions, making it a crucial aspect of modern AI.\nFor those intrigued by the capabilities and potential of NLP, a journey of exploration and learning awaits. DataCamp\u2019s Natural Language Processing in Python Track is an excellent starting point to delve deeper into this transformative domain.\nA senior editor in the AI and edtech space. Committed to exploring data and AI trends.\nFAQs\nWhat is Natural Language Processing (NLP) in one sentence?\nNLP is a field of artificial intelligence that focuses on enabling machines to understand, interpret, and respond to human language in a valuable way.\nHow is NLP different from AI?\nNLP is a subset of AI focused specifically on enabling computers to understand, interpret, and generate human language in a meaningful way. While AI encompasses a broad range of technologies that allow machines to simulate human intelligence, including learning, reasoning, and problem-solving, NLP deals with linguistic elements. The main difference lies in their scope: AI is the broader discipline that aims to create intelligent machines, and NLP is a specialized area within AI dedicated to bridging the gap between human communication and computer understanding.\nDo search engines like Google use NLP?\nYes, search engines like Google use NLP extensively to understand and process user queries, as well as to index and retrieve web content more effectively. NLP allows these search engines to grasp the context of words in search queries, improving the accuracy of search results.\nDoes ChatGPT use NLP?\nYes, ChatGPT uses advanced NLP technologies to understand and generate human-like text responses. It's built on models that analyze vast amounts of text data, learning patterns and nuances of language to simulate natural conversation.\nWhat are the ethical considerations in using NLP?\nEthical issues include ensuring privacy, avoiding bias in language models, and ensuring that NLP applications do not misinterpret or manipulate human communication.\nHow do multilingual and dialect-specific challenges affect NLP?\nHandling multiple languages and dialects increases the complexity of NLP solutions, requiring more sophisticated models that can understand and adapt to linguistic diversity.\nWhat role does NLP play in emotional AI or sentiment analysis?\nNLP is central to emotional AI and affective computing, enabling machines to understand and respond to human emotions conveyed through text or speech, which is widely used in customer service and social media monitoring.",
    "scraped_at":"2025-07-07T18:26:08.408774"
  },
  {
    "topic":"Natural Language Processing",
    "title":"Natural Language Processing Definition | DeepAI",
    "url":"https:\/\/deepai.org\/machine-learning-glossary-and-terms\/natural-language-processing",
    "domain":"deepai.org",
    "snippet":"Introduction to Natural Language Processing Natural Language Processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human (natural) languages. It involves enabling computers to understand, interpret, and gene...",
    "content":"Introduction to Natural Language Processing\nNatural Language Processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human (natural) languages. It involves enabling computers to understand, interpret, and generate human language in a valuable way. As a bridge between human communication and digital data, NLP encompasses many problems and techniques that allow computers to process and analyze large amounts of natural language data.\nCore Challenges in NLP\nThe complexity of human language makes NLP a challenging domain within AI. Some of the core challenges include:\n- Syntax and Grammar: Understanding the structure of language and the rules that govern the composition of phrases and sentences.\n- Semantics: Interpreting meaning from the words and sentences, which involves understanding the concepts and relationships between different elements of the text.\n- Pragmatics: Understanding the intended effect of a sentence, which may depend on the context in which it is spoken or written.\n- Discourse: Comprehending the larger context that surrounds spoken or written language, such as understanding a series of sentences that form a paragraph.\n- Ambiguity: Resolving ambiguities in language, such as words with multiple meanings or sentences that can be interpreted in different ways.\nKey Areas of NLP\nNLP encompasses a wide range of techniques and applications. Some of the key areas include:\n- Machine Translation: Translating text or speech from one language to another.\n- Information Retrieval: Finding relevant information in large datasets, often used in search engines.\n- Information Extraction: Automatically extracting structured information from unstructured text.\n- Text Mining: Deriving high-quality information from text through analytical methods.\n- Sentiment Analysis: Determining the emotional tone behind a series of words to gain an understanding of the attitudes, opinions, and emotions expressed.\n- Speech Recognition: Converting spoken language into text.\n- Chatbots and Virtual Assistants: Developing systems that can converse with humans in natural language.\nTechniques in NLP\nTo tackle the challenges and applications within NLP, a variety of techniques are employed, including:\n- Tokenization: Breaking down text into individual words or phrases.\n- Part-of-Speech Tagging: Identifying the grammatical parts of speech in text, such as nouns, verbs, adjectives, etc.\n- Parsing: Analyzing the grammatical structure of sentences.\n- Named Entity Recognition (NER): Identifying and classifying named entities mentioned in text into pre-defined categories such as the names of persons, organizations, locations, expressions of times, quantities, monetary values, percentages, etc.\n- Language Modeling: Developing models that can predict the probability of a sequence of words.\n- Word Embeddings: Representing words in a dense vector form that captures semantic meaning and relationships.\n- Deep Learning: Using neural networks with multiple layers to learn representations of data for various NLP tasks.\nNLP Tools and Libraries\nThere are numerous tools and libraries available that facilitate NLP tasks. Some of the most popular include:\n- NLTK (Natural Language Toolkit): A leading platform for building Python programs to work with human language data.\n- spaCy: An open-source software library for advanced NLP in Python.\n- Apache OpenNLP: A machine learning-based toolkit for processing natural language text.\n- Stanford NLP: A suite of NLP tools provided by the Stanford NLP Group.\n- Transformers: A state-of-the-art library for NLP which provides numerous pre-trained models.\nThe Future of NLP\nAs technology advances, NLP continues to grow in importance and capability. The future of NLP is likely to involve more sophisticated algorithms that can handle the nuances and complexities of human language with greater accuracy. This includes advancements in areas such as unsupervised learning, where the system learns to understand language patterns without explicit instruction, and in handling multilingual and dialectal variations of language. Furthermore, as voice-activated interfaces and virtual assistants become more prevalent, the demand for advanced NLP systems will continue to rise.\nOverall, NLP stands as a testament to the progress of artificial intelligence and its ability to bridge the gap between human communication and computational understanding. With its wide array of applications and the ongoing research in the field, NLP remains a vibrant and critical area of study within AI.",
    "scraped_at":"2025-07-07T18:26:08.593241"
  },
  {
    "topic":"Natural Language Processing",
    "title":"Exploring Natural Language Processing Techniques - Cour\u2026",
    "url":"https:\/\/www.coursera.org\/articles\/natural-language-processing-techniques",
    "domain":"www.coursera.org",
    "snippet":"Written by Coursera Staff \u2022 Updated on Natural language processing techniques like tokenization, part-of-speech tagging, and syntax analysis make it possible for NLP applications to complete many helpful tasks. Explore NLP techniques and natural language processing applications capabilities. Natural...",
    "content":"Written by Coursera Staff \u2022 Updated on\nNatural language processing techniques like tokenization, part-of-speech tagging, and syntax analysis make it possible for NLP applications to complete many helpful tasks. Explore NLP techniques and natural language processing applications capabilities.\nNatural language processing (NLP) is an artificial intelligence technique that combines computational linguistics with deep learning to understand natural human languages, such as English, Mandarin, or Swahili. As a form of artificial intelligence, NLP allows a computer to analyze text and speech using a variety of techniques to understand a natural language and respond accordingly.\nResearchers and computer scientists have been thinking about and working on natural language processing for as long as computers have been around. Fortunately, advances in statistical models, deep learning, and pre-trained language models are making natural language processing techniques and tasks more relevant and popular in areas like linguistics, cybersecurity, and even fields you might not expect, like gender studies, dentistry, and quantum mechanics.\nIf you enjoy learning about aspects of artificial intelligence, you could consider a career in the NLP industry. Statista estimates that the market size for NLP will increase from 12.88 billion dollars in 2025 to 41.79 billion dollars by 2030, an annual growth rate of 27.54 percent [1]. This data suggests robust growth that can benefit from professionals with the skills and interest needed to work in the field.\nExplore how organizations and companies use natural language processing techniques like supervised and unsupervised learning to perform machine translation, sentiment analysis, information retrieval, and more.\nNatural language processing is a technology that allows computers, machines, and other artificial intelligence models to understand, process, and respond to natural human language. A natural language develops naturally, like any language you use to communicate with another person. These languages are natural instead of languages like Python, C++, or HTML, which programmers use to communicate with computers. Using computational techniques like text preprocessing, feature extraction, and text analysis, computers can use NLP to automate tasks, analyze customer sentiments, provide virtual customer service, and accomplish more tasks.\nNatural language processing is important because it changes how you can interact with computers and machines and allows robots and artificial intelligence to work in new ways. For example, early forms of search engines only indexed pages by topic. When you wanted to search for a topic, you would type the keyword into the search engine and return a list of pages indexed to that topic.\nNatural language processing techniques have evolved over time to allow search engines a better understanding of what you really want to find when you type a query into the website. Today, NLP can understand you so well that you don\u2019t have to type anything into a search engine to look for information; you can simply ask your voice assistant\u2014Google Assistant, Siri, or Alexa\u2014a question, which will respond in kind.\nFrom voice search to 24-hour customer service chatbots to content moderation, you are likely already benefiting from advances in NLP technology. The more scientists and researchers improve and adapt natural language processing, the more companies and organizations can harness its power for task automation, data analysis, information retrieval, content generation, and more.\nNatural language processing works by understanding and analyzing text through several computational processes, including tokenization, stemming, stop word removal, feature extraction, part-of-speech tagging, sentiment analysis, and named entity recognition.\nTokenization: The AI algorithm breaks down text into words or phrases and in some instances, represents these fragments as numerical expressions.\nStemming: The model reduces words to their root form to make it easier to work with languages by grouping similar words together. For example, you can reduce \u201ceating,\u201d \u201ceats,\u201d and \u201cate\u201d to the word \u201ceat\u201d.\nStop word removal: The NLP model filters out words like \u201cis\u201d and \u201cthe,\u201d which are important for understanding natural language, but they don\u2019t add significant meaning to the text.\nFeature extraction: In terms of NLP, feature extraction is the process that transforms raw text into numerical data that computers can analyze and comprehend.\nPart-of-speech tagging: The algorithm analyzes text to tag each word or phrase\u2014each token\u2014as what part of speech it is, such as a noun, verb, or adjective.\nNamed entity recognition (NER): This process allows NLP algorithms to identify named entities or items with proper names, such as The Mona Lisa, Betty White, or New York.\nSentiment analysis: AI models can use sentiment analysis to understand the emotions and feelings people use when typing or speaking, labeling the text as either positive, negative, or neutral.\nYou can also use various other techniques to customize natural language processing applications for many different purposes; some of these techniques include supervised, unsupervised, and semi-supervised learning, syntax and semantic analysis, and rules-based, statistical, or deep learning NLP.\nThese natural language processing techniques describe how much of the algorithm\u2019s training data you label. Essentially, in terms of NLP, supervised learning utilizes data that is labeled, while unsupervised learning uses data that is not. AI models require training data to help them analyze text by comparing new input to that training data, which can be labeled (supervised) or unlabeled (unsupervised).\nIn supervised learning, you will label training data and provide the algorithm with more information about what you want it to do with new inputs.\nIn unsupervised learning, the statistical language model provides those labels by analyzing what the most likely label should be, predicting patterns, and adjusting its estimates with new information.\nSemi-supervised learning is a combination of techniques that can help provide specific instructions to the algorithm while saving time spent training the model. In this type of machine learning, you will use a training data set that typically contains a small amount of labeled data and a large portion of unlabelled data.\nNatural language processing applications use syntax and semantic analysis to determine the meaning of individual words and how words change meaning based on where they appear in a sentence. Syntax analysis deconstructs a sentence into its basic grammatical components to assist in comprehension, while semantic analysis helps NLP models understand what individual words mean when placed in a sentence. These types of analysis are especially critical in machine translation where one language's semantics differ from another's. For example, when translating between English and Spanish, you would change some word order: \u201cThe red car\u201d would become \u201cel auto rojo,\u201d or \u201cthe car red.\u201d\nOver time, computer scientists and researchers have developed three main frameworks for natural language processing models: Rules-based, statistical, or deep learning. Rules-based frameworks were some of the first to develop and required developers to designate a series of preprogrammed rules for the natural language model to follow, such as segmenting sentences by punctuation. As a programmer, you would typically add the rules manually, and the model would offer limited functionality without the need for machine learning.\nNext came statistical models, which used statistical probabilities to analyze, classify, and map text to determine meaning. The technology requires machine learning because the algorithmic model identifies patterns and uses training data to understand and interact with language.\nDeep learning models represent the most recent advance in natural language processing applications and can process much larger amounts of data, allowing for increased accuracy and functionality. You can now access several different pre-trained language models, such as BERT and GPT, to adapt your own natural language processing application without starting from scratch.\nAltogether, these natural language processing techniques power a wide menu of tasks NLP applications can perform. Consider how you can use NLP for natural language generation, machine translation, and more:\nNatural language generation: AI models like GPT-4 can use natural language processing to generate text responding to a prompt, such as writing a product description, essay, or creative writing.\nMachine translation: NLP can empower a machine to translate from one natural language to another by understanding and applying each language's grammatical rules.\nInformation retrieval and semantic search: You can use NLP to find information within a vast database, similar to how a search engine combs the internet to answer your query. NLP allows you to use this technology in your local files or network to ask your NLP-controlled search engine to track down certain information.\nSpeech recognition: NLP models can transcribe verbal language to written text and are commonly used for automated customer service and dictation software.\nSentiment analysis: Companies can use NLP to conduct sentiment analysis, also called opinion mining, to understand how people discuss their brands or products on social media and other online places.\nContent moderation: One form of sentiment analysis is content moderation, where websites with a lot of user-generated content, such as forums or social media, can monitor the types of content and sentiments that users express online. This allows filtering out hateful, violent, or otherwise malicious content in community forums.\nNatural language processing allows computers to understand, analyze, and respond in a natural language that\u2019s easier for humans to understand, allowing AI to accomplish various tasks.\nTo learn more about natural language processing techniques, check out some of the courses on Coursera. For example, you could consider Natural Language Processing in Microsoft Azure offered by Microsoft. You could also complete a series of classes and earn a specialization, like the Natural Language Processing Specialization or Deep Learning Specialization, both offered by DeepLearning.AI.\nStatista. \u201cNatural Language Processing - United States, https:\/\/www.statista.com\/outlook\/tmo\/artificial-intelligence\/natural-language-processing\/united-states.\u201d Accessed February 3, 2025.\nUpdated on\nWritten by:Coursera Staff\nC\nEditorial Team\nCoursera\u2019s editorial team is comprised of highly experienced professional editors, writers, and fact...\nThis content has been made available for informational purposes only. Learners are advised to conduct additional research to ensure that courses and other credentials pursued meet their personal, professional, and financial goals.",
    "scraped_at":"2025-07-07T18:26:09.282393"
  },
  {
    "topic":"Natural Language Processing",
    "title":"Natural Language Processing Tutorial - Online Tutorials Library",
    "url":"https:\/\/www.tutorialspoint.com\/natural_language_processing\/index.htm",
    "domain":"www.tutorialspoint.com",
    "snippet":"- NLP - Home - NLP - Introduction - NLP - Linguistic Resources - NLP - Word Level Analysis - NLP - Syntactic Analysis - NLP - Semantic Analysis - NLP - Word Sense Disambiguation - NLP - Discourse Processing - NLP - Part of Speech (PoS) Tagging - NLP - Inception - NLP - Information Retrieval - NLP -...",
    "content":"- NLP - Home\n- NLP - Introduction\n- NLP - Linguistic Resources\n- NLP - Word Level Analysis\n- NLP - Syntactic Analysis\n- NLP - Semantic Analysis\n- NLP - Word Sense Disambiguation\n- NLP - Discourse Processing\n- NLP - Part of Speech (PoS) Tagging\n- NLP - Inception\n- NLP - Information Retrieval\n- NLP - Applications of NLP\n- NLP - Python\n- Natural Language Processing Resources\n- NLP - Quick Guide\n- NLP - Useful Resources\n- NLP - Discussion\nNatural Language Processing Tutorial\nLanguage is a method of communication with the help of which we can speak, read and write. Natural Language Processing (NLP) is a subfield of Computer Science that deals with Artificial Intelligence (AI), which enables computers to understand and process human language.\nAudience\nThis tutorial is designed to benefit graduates, postgraduates, and research students who either have an interest in this subject or have this subject as a part of their curriculum. The reader can be a beginner or an advanced learner.\nPrerequisites\nThe reader must have basic knowledge about Artificial Intelligence. He\/she should also be aware about basic terminologies used in English grammar and Python programming concepts.\nAdvertisements",
    "scraped_at":"2025-07-07T18:26:09.466682"
  },
  {
    "topic":"Natural Language Processing",
    "title":"Introduction to Natural Language Processing (NLP)",
    "url":"https:\/\/builtin.com\/data-science\/introduction-nlp",
    "domain":"builtin.com",
    "snippet":"Natural language processing (NLP) is an area of computer science and artificial intelligence concerned with the interaction between computers and humans in natural language. The ultimate goal of NLP is to help computers understand language as well as we do. It is the driving force behind things like...",
    "content":"Natural language processing (NLP) is an area of computer science and artificial intelligence concerned with the interaction between computers and humans in natural language. The ultimate goal of NLP is to help computers understand language as well as we do. It is the driving force behind things like virtual assistants, speech recognition, sentiment analysis, automatic text summarization, machine translation and much more. In this post, we\u2019ll cover the basics of natural language processing, dive into some of its techniques and also learn how NLP has benefited from recent advances in deep learning.\nTable of Contents\n- Introduction to NLP\n- Why NLP is difficult\n- Syntactic and semantic analysis\n- NLP techniques\n- Benefits of NLP\n- NLP Use Cases\n- Deep learning and NLP\n- References\n1. Introduction to Natural Language Processing\nNatural language processing (NLP) is the intersection of computer science, linguistics and machine learning. The field focuses on communication between computers and humans in natural language and NLP is all about making computers understand and generate human language. Applications of NLP techniques include voice assistants like Amazon\u2019s Alexa and Apple\u2019s Siri, but also things like machine translation and text-filtering.\nWhat Is Natural Language Processing?\nNatural language processing has heavily benefited from recent advances in machine learning, especially from deep learning techniques. The field is divided into the three parts:\n- Speech recognition \u2014 the translation of spoken language into text.\n- Natural language understanding \u2014 a computer\u2019s ability to understand language.\n- Natural language generation \u2014 the generation of natural language by a computer.\n2. Why Natural Language Processing Is Difficult\nHuman language is special for several reasons. It is specifically constructed to convey the speaker\/writer\u2019s meaning. It is a complex system, although little children can learn it pretty quickly.\nAnother remarkable thing about human language is that it is all about symbols. According to Chris Manning, a machine learning professor at Stanford, it is a discrete, symbolic, categorical signaling system. This means we can convey the same meaning in different ways (i.e., speech, gesture, signs, etc.) The encoding by the human brain is a continuous pattern of activation by which the symbols are transmitted via continuous signals of sound and vision.\nUnderstanding human language is considered a difficult task due to its complexity. For example, there are an infinite number of different ways to arrange words in a sentence. Also, words can have several meanings and contextual information is necessary to correctly interpret sentences. Every language is more or less unique and ambiguous. Just take a look at the following newspaper headline \u201cThe Pope\u2019s baby steps on gays.\u201d This sentence clearly has two very different interpretations, which is a pretty good example of the challenges in natural language processing.\n3. Syntactic and Semantic Analysis\nSyntactic analysis (syntax) and semantic analysis (semantic) are the two primary techniques that lead to the understanding of natural language. Language is a set of valid sentences, but what makes a sentence valid? Syntax and semantics.\nSyntax is the grammatical structure of the text, whereas semantics is the meaning being conveyed. A sentence that is syntactically correct, however, is not always semantically correct. For example, \u201ccows flow supremely\u201d is grammatically valid (subject \u2014 verb \u2014 adverb) but it doesn\u2019t make any sense.\nSyntactic Analysis\nSyntactic analysis, also referred to as syntax analysis or parsing, is the process of analyzing natural language with the rules of a formal grammar. Grammatical rules are applied to categories and groups of words, not individual words. Syntactic analysis basically assigns a semantic structure to text.\nFor example, a sentence includes a subject and a predicate where the subject is a noun phrase and the predicate is a verb phrase. Take a look at the following sentence: \u201cThe dog (noun phrase) went away (verb phrase).\u201d Note how we can combine every noun phrase with a verb phrase. Again, it\u2019s important to reiterate that a sentence can be syntactically correct but not make sense.\nSemantic Analysis\nThe way we understand what someone has said is an unconscious process relying on our intuition and knowledge about language itself. In other words, the way we understand language is heavily based on meaning and context. Computers need a different approach, however. The word \u201csemantic\u201d is a linguistic term and means \u201crelated to meaning or logic.\u201d\nSemantic analysis is the process of understanding the meaning and interpretation of words, signs and sentence structure. This lets computers partly understand natural language the way humans do. I say this partly because semantic analysis is one of the toughest parts of natural language processing and it\u2019s not fully solved yet.\nSpeech recognition, for example, has gotten very good and works almost flawlessly, but we still lack this kind of proficiency in natural language understanding. Your phone basically understands what you have said, but often can\u2019t do anything with it because it doesn\u2019t understand the meaning behind it. Also, some of the technologies out there only make you think they understand the meaning of a text. An approach based on keywords or statistics or even pure machine learning may be using a matching or frequency technique for clues as to what the text is \u201cabout.\u201d But, because they don\u2019t understand the deeper relationships within the text, these methods are limited.\n4. Natural Language Processing Techniques for Understanding Text\nLet\u2019s look at some of the most popular techniques used in natural language processing. Note how some of them are closely intertwined and only serve as subtasks for solving larger problems.\nNatural Language Processing Techniques\n- Parsing\n- Stemming\n- Text Segmentation\n- Named Entity Recognition\n- Relationship Extraction\n- Sentiment Analysis\nParsing\nWhat is parsing? According to the dictionary, to parse is to \u201cresolve a sentence into its component parts and describe their syntactic roles.\u201d\nThat actually nailed it but it could be a little more comprehensive. Parsing refers to the formal analysis of a sentence by a computer into its constituents, which results in a parse tree showing their syntactic relation to one another in visual form, which can be used for further processing and understanding.\nBelow is a parse tree for the sentence \u201cThe thief robbed the apartment.\u201d Included is a description of the three different information types conveyed by the sentence.\nThe letters directly above the single words show the parts of speech for each word (noun, verb and determiner). One level higher is some hierarchical grouping of words into phrases. For example, \u201cthe thief\u201d is a noun phrase, \u201crobbed the apartment\u201d is a verb phrase and when put together the two phrases form a sentence, which is marked one level higher.\nBut what is actually meant by a noun or verb phrase? Noun phrases are one or more words that contain a noun and maybe some descriptors, verbs or adverbs. The idea is to group nouns with words that are in relation to them.\nA parse tree also provides us with information about the grammatical relationships of the words due to the structure of their representation. For example, we can see in the structure that \u201cthe thief\u201d is the subject of \u201crobbed.\u201d\nWith structure I mean that we have the verb (\u201crobbed\u201d), which is marked with a \u201cV\u201d above it and a \u201cVP\u201d above that, which is linked with a \u201cS\u201d to the subject (\u201cthe thief\u201d), which has a \u201cNP\u201d above it. This is like a template for a subject-verb relationship and there are many others for other types of relationships.\nStemming\nStemming is a technique that comes from morphology and information retrieval which is used in natural language processing for pre-processing and efficiency purposes. It\u2019s defined by the dictionary as to \u201coriginate in or be caused by.\u201d\nBasically, stemming is the process of reducing words to their word stem. A \u201cstem\u201d is the part of a word that remains after the removal of all affixes. For example, the stem for the word \u201ctouched\u201d is \u201ctouch.\u201d \u201cTouch\u201d is also the stem of \u201ctouching,\u201d and so on.\nYou may be asking yourself, why do we even need the stem? Well, the stem is needed because we\u2019re going to encounter different variations of words that actually have the same stem and the same meaning. For example:\nI was taking a ride in the car.\nI was riding in the car.\nThese two sentences mean the exact same thing and the use of the word is identical.\nNow, imagine all the English words in the vocabulary with all their different fixations at the end of them. To store them all would require a huge database containing many words that actually have the same meaning. This is solved by focusing only on a word\u2019s stem. Popular algorithms for stemming include the Porter stemming algorithm from 1979, which still works well.\nText Segmentation\nText segmentation in natural language processing is the process of transforming text into meaningful units like words, sentences, different topics, the underlying intent and more. Mostly, the text is segmented into its component words, which can be a difficult task, depending on the language. This is again due to the complexity of human language. For example, it works relatively well in English to separate words by spaces, except for words like \u201cicebox\u201d that belong together but are separated by a space. The problem is that people sometimes also write it as \u201cice-box.\u201d\nNamed Entity Recognition\nNamed entity recognition (NER) concentrates on determining which items in a text (i.e. the \u201cnamed entities\u201d) can be located and classified into predefined categories. These categories can range from the names of persons, organizations and locations to monetary values and percentages.\nFor example:\nBefore NER: Martin bought 300 shares of SAP in 2016.\nAfter NER: [Martin]Person bought 300 shares of [SAP]Organization in [2016]Time.\nRelationship Extraction\nRelationship extraction takes the named entities of NER and tries to identify the semantic relationships between them. This could mean, for example, finding out who is married to whom, that a person works for a specific company and so on. This problem can also be transformed into a classification problem and a machine learning model can be trained for every relationship type.\nSentiment Analysis\nWith sentiment analysis we want to determine the attitude (i.e. the sentiment) of a speaker or writer with respect to a document, interaction or event. Therefore it is a natural language processing problem where text needs to be understood in order to predict the underlying intent. The sentiment is mostly categorized into positive, negative and neutral categories.\nWith the use of sentiment analysis, for example, we may want to predict a customer\u2019s opinion and attitude about a product based on a review they wrote. Sentiment analysis is widely applied to reviews, surveys, documents and much more.\nIf you\u2019re interested in using some of these techniques with Python, take a look at the Jupyter Notebook about Python\u2019s natural language toolkit (NLTK) that I created. You can also check out my blog post about building neural networks with Keras where I train a neural network to perform sentiment analysis.\n5. Benefits of Natural Language Processing\nNow that we\u2019ve learned about how natural language processing works, it\u2019s important to understand what it can do for businesses.\nEnhanced Data Analysis\nWhile NLP and other forms of AI aren\u2019t perfect, natural language processing can bring objectivity to data analysis, providing more accurate and consistent results.\nFaster Insights\nWith the Internet of Things and other advanced technologies compiling more data than ever, some data sets are simply too overwhelming for humans to comb through. Natural language processing can quickly process massive volumes of data, gleaning insights that may have taken weeks or even months for humans to extract.\nIncreased Employee Productivity\nNLP handles mundane tasks like sifting through data sets, sorting emails and assessing customer responses. With these repetitive responsibilities out of the way, workers are freed up to focus on more complex and pressing matters.\nHigher-Quality Customer Experience\nIn the form of chatbots, natural language processing can take some of the weight off customer service teams, promptly responding to online queries and redirecting customers when needed. NLP can also analyze customer surveys and feedback, allowing teams to gather timely intel on how customers feel about a brand and steps they can take to improve customer sentiment.\n6. NLP Use Cases\nKeeping the advantages of natural language processing in mind, let\u2019s explore how different industries are applying this technology.\nCustomer Service\nWhile NLP-powered chatbots and callbots are most common in customer service contexts, companies have also relied on natural language processing to power virtual assistants. These assistants are a form of conversational AI that can carry on more sophisticated discussions. And if NLP is unable to resolve an issue, it can connect a customer with the appropriate personnel.\nMarketing\nGathering market intelligence becomes much easier with natural language processing, which can analyze online reviews, social media posts and web forums. Compiling this data can help marketing teams understand what consumers care about and how they perceive a business\u2019 brand.\nHuman Resources\nRecruiters and HR personnel can use natural language processing to sift through hundreds of resumes, picking out promising candidates based on keywords, education, skills and other criteria. In addition, NLP\u2019s data analysis capabilities are ideal for reviewing employee surveys and quickly determining how employees feel about the workplace.\nE-Commerce\nNatural language processing can help customers book tickets, track orders and even recommend similar products on e-commerce websites. Teams can also use data on customer purchases to inform what types of products to stock up on and when to replenish inventories.\nFinance\nIn finance, NLP can be paired with machine learning to generate financial reports based on invoices, statements and other documents. Financial analysts can also employ natural language processing to predict stock market trends by analyzing news articles, social media posts and other online sources for market sentiments.\nInsurance\nInsurance companies can assess claims with natural language processing since this technology can handle both structured and unstructured data. NLP can also be trained to pick out unusual information, allowing teams to spot fraudulent claims.\nEducation\nNLP-powered apps can check for spelling errors, highlight unnecessary or misapplied grammar and even suggest simpler ways to organize sentences. Natural language processing can also translate text into other languages, aiding students in learning a new language.\nHealthcare\nHealthcare professionals can develop more efficient workflows with the help of natural language processing. During procedures, doctors can dictate their actions and notes to an app, which produces an accurate transcription. NLP can also scan patient documents to identify patients who would be best suited for certain clinical trials.\nManufacturing\nWith its ability to process large amounts of data, NLP can inform manufacturers on how to improve production workflows, when to perform machine maintenance and what issues need to be fixed in products. And if companies need to find the best price for specific materials, natural language processing can review various websites and locate the optimal price.\nCybersecurity\nIT and security teams can deploy natural language processing to filter out suspicious emails based on word choice, sentiment and other factors. This makes it easier to protect different departments from spam, phishing scams and other cyber attacks. With its ability to understand data, NLP can also detect unusual behavior and alert teams of possible threats.\n7. Deep Learning and Natural Language Processing\nCentral to deep learning and natural language is \u201cword meaning,\u201d where a word and especially its meaning are represented as a vector of real numbers. With these vectors that represent words, we are placing words in a high-dimensional space. The interesting thing about this is that the words, which are represented by vectors, will act as a semantic space. This simply means the words that are similar and have a similar meaning tend to cluster together in this high-dimensional vector space. You can see a visual representation of word meaning below:\nYou can find out what a group of clustered words mean by doing principal component analysis (PCA) or dimensionality reduction with T-SNE, but this can sometimes be misleading because they oversimplify and leave a lot of information on the side. It\u2019s a good way to get started (like logistic or linear regression in data science), but it isn\u2019t cutting edge and it is possible to do it way better.\nWe can also think of parts of words as vectors that represent their meaning. Imagine the word \u201cundesirability.\u201d Using a morphological approach, which involves the different parts a word has, we would think of it as being made out of morphemes (word parts) like this: \u201cUn + desire + able + ity.\u201d Every morpheme gets its own vector. From this, we can build a neural network that can compose the meaning of a larger unit, which in turn is made up of all of the morphemes.\nDeep learning can also make sense of the structure of sentences with syntactic parsers. Google uses dependency parsing techniques like this, although in a more complex and larger manner, with their \u201cMcParseface\u201d and \u201cSyntaxNet.\u201d\nBy knowing the structure of sentences, we can start trying to understand the meaning of sentences. We start off with the meaning of words being vectors but we can also do this with whole phrases and sentences, where the meaning is also represented as vectors. And if we want to know the relationship of or between sentences, we train a neural network to make those decisions for us.\nDeep learning is also good for sentiment analysis. Take this movie review, for example: \u201cThis movie does not care about cleverness, with or any other kind of intelligent humor.\u201d A traditional approach would have fallen into the trap of thinking this is a positive review, because \u201ccleverness or any other kind of intelligent humor\u201d sounds like a positive intent, but a neural network would have recognized its real meaning. Other applications are chatbots, machine translation, Siri, Google inbox suggested replies and so on.\nThere have also been huge advancements in machine translation through the rise of recurrent neural networks, about which I also wrote a blog post.\nIn machine translation done by deep learning algorithms, language is translated by starting with a sentence and generating vector representations that represent it. Then it starts to generate words in another language that entail the same information.\nTo summarize, natural language processing in combination with deep learning, is all about vectors that represent words, phrases, etc. and to some degree their meanings.\n8. References\n- https:\/\/machinelearningmastery.com\/natural-language-processing\/\n- https:\/\/www.youtube.com\/watch?v=8S3qHHUKqYk\n- https:\/\/en.wikipedia.org\/wiki\/Natural_language_processing\n- https:\/\/www.youtube.com\/watch?v=TbrlRei_0h8\n- https:\/\/www.youtube.com\/watch?v=OQQ-W_63UgQ&list=PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6\n- https:\/\/ocw.mit.edu\/courses\/electrical-engineering-and-computer-science\/6-864-advanced-natural-language-processing-fall-2005\/lecture-notes\/lec2.pdf\nFrequently Asked Questions\nWhat is natural language processing used for?\nWith its ability to quickly process large data sets and extract insights, NLP is ideal for reviewing candidate resumes, generating financial reports and identifying patients for clinical trials, among many other use cases across various industries.\nHow does natural language processing work?\nNatural language processing brings together linguistics and algorithmic models to analyze written and spoken human language. Based on the content, speaker sentiment and possible intentions, NLP generates an appropriate response.",
    "scraped_at":"2025-07-07T18:26:09.633801"
  },
  {
    "topic":"Natural Language Processing",
    "title":"What is natural language processing (NLP)? - TechTarget",
    "url":"https:\/\/www.techtarget.com\/searchenterpriseai\/definition\/natural-language-processing-NLP",
    "domain":"www.techtarget.com",
    "snippet":"What is natural language processing (NLP)? Natural language processing (NLP) is the ability of a computer program to understand human language as it's spoken and written -- referred to as natural language. It's a component of artificial intelligence (AI). NLP has existed for more than 50 years and h...",
    "content":"What is natural language processing (NLP)?\nNatural language processing (NLP) is the ability of a computer program to understand human language as it's spoken and written -- referred to as natural language. It's a component of artificial intelligence (AI).\nNLP has existed for more than 50 years and has roots in the field of linguistics. It has a variety of real-world applications in numerous fields, including medical research, search engines and business intelligence.\nNLP uses either rule-based or machine learning approaches to understand the structure and meaning of text. It plays a role in chatbots, voice assistants, text-based scanning programs, translation applications and enterprise software that aids in business operations, increases productivity and simplifies different processes.\nHow does natural language processing work?\nNLP uses many different techniques to enable computers to understand natural language as humans do. Whether the language is spoken or written, natural language processing can use AI to take real-world input, process it and make sense of it in a way a computer can understand. Just as humans have different sensors -- such as ears to hear and eyes to see -- computers have programs to read and microphones to collect audio. And just as humans have a brain to process that input, computers have a program to process their respective inputs. At some point in processing, the input is converted to code that the computer can understand.\nThere are two main phases to natural language processing: data preprocessing and algorithm development.\nThis article is part of\nWhat is enterprise AI? A complete guide for businesses\nData preprocessing involves preparing and cleaning text data so that machines can analyze it. Preprocessing puts data in a workable form and highlights features in the text that an algorithm can work with. There are several ways this can be done, including the following:\n- Tokenization. Tokenization substitutes sensitive information with nonsensitive information, or a token. Tokenization is often used in payment transactions to protect credit card data.\n- Stop word removal. Common words are removed from the text, so unique words that offer the most information about the text remain.\n- Lemmatization and stemming. Lemmatization groups together different inflected versions of the same word. For example, the word \"walking\" would be reduced to its root form, or stem, \"walk\" to process.\n- Part-of-speech tagging. Words are tagged based on which part of speech they correspond to -- such as nouns, verbs or adjectives.\nOnce the data has been preprocessed, an algorithm is developed to process it. There are many different natural language processing algorithms, but the following two main types are commonly used:\n- Rule-based system. This system uses carefully designed linguistic rules. This approach was used early in the development of natural language processing and is still used.\n- Machine learning-based system. Machine learning algorithms use statistical methods. They learn to perform tasks based on training data they're fed and adjust their methods as more data is processed. Using a combination of machine learning, deep learning and neural networks, natural language processing algorithms hone their own rules through repeated processing and learning.\nWhy is natural language processing important?\nBusinesses use large amounts of unstructured, text-heavy data and need a way to efficiently process it. Much of the information created online and stored in databases is natural human language, and until recently, businesses couldn't effectively analyze this data. This is where natural language processing is useful.\nThe advantages of natural language processing can be seen when considering the following two statements: \"Cloud computing insurance should be part of every service-level agreement\" and \"A good SLA ensures an easier night's sleep -- even in the cloud.\" If a user relies on natural language processing for search, the program will recognize that cloud computing is an entity, that cloud is an abbreviated form of cloud computing, and that SLA is an industry acronym for service-level agreement.\nThese are the types of vague elements that frequently appear in human language and that machine learning algorithms have historically been bad at interpreting. Now, with improvements in deep learning and machine learning methods, algorithms can effectively interpret them. These improvements expand the breadth and depth of data that can be analyzed.\nLikewise, NLP is useful for the same reasons as when a person interacts with a generative AI chatbot or AI voice assistant. Instead of needing to use specific predefined language, a user could interact with a voice assistant like Siri on their phone using their regular diction, and their voice assistant will still be able to understand them.\nTechniques and methods of natural language processing\nSyntax and semantic analysis are two main techniques used in natural language processing.\nSyntax is the arrangement of words in a sentence to make grammatical sense. NLP uses syntax to assess meaning from a language based on grammatical rules. Syntax NLP techniques include the following:\nParsing\nThis is the grammatical analysis of a sentence. For example, a natural language processing algorithm is fed the sentence, \"The dog barked.\" Parsing involves breaking this sentence into parts of speech -- i.e., dog = noun, barked = verb. This is useful for more complex downstream processing tasks.\nWord segmentation\nThis is the act of taking a string of text and deriving word forms from it. For example, a person scans a handwritten document into a computer. The algorithm can analyze the page and recognize that the words are divided by white spaces.\nSentence breaking\nThis places sentence boundaries in large texts. For example, a natural language processing algorithm is fed the text, \"The dog barked. I woke up.\" The algorithm can use sentence breaking to recognize the period that splits up the sentences.\nMorphological segmentation\nThis divides words into smaller parts called morphemes. For example, the word untestably would be broken into [[un[[test]able]]ly], where the algorithm recognizes \"un,\" \"test,\" \"able\" and \"ly\" as morphemes. This is especially useful in machine translation and speech recognition.\nStemming\nThis divides words with inflection in them into root forms. For example, in the sentence, \"The dog barked,\" the algorithm would recognize the root of the word \"barked\" is \"bark.\" This is useful if a user is analyzing text for all instances of the word bark, as well as all its conjugations. The algorithm can see that they're essentially the same word even though the letters are different.\nSemantics involves the use of and meaning behind words. Natural language processing applies algorithms to understand the meaning and structure of sentences. Semantic techniques include the following:\nWord sense disambiguation\nThis derives the meaning of a word based on context. For example, consider the sentence, \"The pig is in the pen.\" The word pen has different meanings. An algorithm using this method can understand that the use of the word here refers to a fenced-in area, not a writing instrument.\nNamed entity recognition (NER)\nNER determines words that can be categorized into groups. For example, an algorithm using this method could analyze a news article and identify all mentions of a certain company or product. Using the semantics of the text, it could differentiate between entities that are visually the same. For instance, in the sentence, \"Daniel McDonald's son went to McDonald's and ordered a Happy Meal,\" the algorithm could recognize the two instances of \"McDonald's\" as two separate entities -- one a restaurant and one a person.\nNatural language generation (NLG)\nNLG uses a database to determine the semantics behind words and generate new text. For example, an algorithm could automatically write a summary of findings from a business intelligence (BI) platform, mapping certain words and phrases to features of the data in the BI platform. Another example would be automatically generating news articles or tweets based on a certain body of text used for training.\nCurrent approaches to natural language processing are based on deep learning, a type of AI that examines and uses patterns in data to improve a program's understanding. Deep learning models require massive amounts of labeled data for the natural language processing algorithm to train on and identify relevant correlations, and assembling this kind of big data set is one of the main hurdles to natural language processing.\nEarlier approaches to natural language processing involved a more rule-based approach, where simpler machine learning algorithms were told what words and phrases to look for in text and given specific responses when those phrases appeared. But deep learning is a more flexible, intuitive approach in which algorithms learn to identify speakers' intent from many examples -- almost like how a child would learn human language.\nThree open source tools commonly used for natural language processing include Natural Language Toolkit (NLTK), Gensim and NLP Architect by Intel. NLTK is a Python module with data sets and tutorials. Gensim is a Python library for topic modeling and document indexing. NLP Architect by Intel is a Python library for deep learning topologies and techniques.\nWhat is natural language processing used for?\nSome of the main functions and NLP tasks that natural language processing algorithms perform include the following:\n- Text classification. This function assigns tags to texts to put them in categories. This can be useful for sentiment analysis, which helps the natural language processing algorithm determine the sentiment, or emotion, behind a text. For example, when brand A is mentioned in X number of texts, the algorithm can determine how many of those mentions were positive and how many were negative. It can also be useful for intent detection, which helps predict what the speaker or writer might do based on the text they're producing.\n- Text extraction. This function automatically summarizes text and finds important pieces of data. One example of this is keyword extraction, which pulls the most important words from the text, which can be useful for search engine optimization. Doing this with natural language processing requires some programming -- it isn't completely automated. However, there are plenty of simple keyword extraction tools that automate most of the process -- the user just sets parameters within the program. For example, a tool might pull out the most frequently used words in the text. Another example is entity recognition, which extracts the names of people, places and other entities from text.\n- Machine translation. In this process, a computer translates text from one language, such as English, to another language, such as French, without human intervention.\n- Natural language generation. This process uses natural language processing algorithms to analyze unstructured data and automatically produce content based on that data. One example of this is in language models like the third-generation Generative Pre-trained Transformer (GPT-3), which can analyze unstructured text and then generate believable articles based on that text.\nThe functions listed above are used in a variety of real-world applications, including the following:\n- Customer feedback analysis. Tools using AI can analyze social media reviews and filter out comments and queries for a company.\n- Customer service automation. Voice assistants on a customer service phone line can use speech recognition to understand what the customer is saying, so that it can direct their call correctly.\n- Automatic translation. Tools such as Google Translate, Bing Translator and Translate Me can translate text, audio and documents into another language.\n- Academic research and analysis. Tools using AI can analyze huge amounts of academic material and research papers based on the metadata of the text as well as the text itself.\n- Analysis and categorization of healthcare records. AI-based tools can use insights to predict and, ideally, prevent disease.\n- Plagiarism detection. Tools such as Copyleaks and Grammarly use AI technology to scan documents and detect text matches and plagiarism.\n- Stock forecasting and insights into financial trading. NLP tools can analyze market history and annual reports that contain comprehensive summaries of a company's financial performance.\n- Talent recruitment in human resources. Organizations can use AI-based tools to reduce hiring time by automating the candidate sourcing and screening process.\n- Automation of routine litigation. AI-powered tools can do research, identify possible issues and summarize cases faster than human attorneys.\n- Spam detection. NLP-enabled tools can be used to classify text for language that's often used in spam or phishing attempts. For example, AI-enabled tools can detect bad grammar, misspelled names, urgent calls to action and threatening terms.\nBenefits of natural language processing\nThe main benefit of NLP is that it improves the way humans and computers communicate with each other. The most direct way to manipulate a computer is through code -- the computer's language. Enabling computers to understand human language makes interacting with computers much more intuitive for humans.\nOther benefits include the following:\n- Offers improved accuracy and efficiency of documentation.\n- Enables an organization to use chatbots for customer support.\n- Provides an organization with the ability to automatically make a readable summary of a larger, more complex original text.\n- Lets organizations analyze structured and unstructured data.\n- Enables personal assistants such as Alexa to understand the spoken word.\n- Makes it easier for organizations to perform sentiment analysis.\n- Organizations can use NLP to better understand lead generation, social media posts, surveys and reviews.\n- Provides advanced insights from analytics that were previously unreachable due to data volume.\nChallenges of natural language processing\nThere are numerous challenges in natural language processing, and most of them boil down to the fact that natural language is ever-evolving and somewhat ambiguous. They include the following:\n- Precision. Computers traditionally require humans to speak to them in a programming language that's precise, unambiguous and highly structured -- or through a limited number of clearly enunciated voice commands. Human speech, however, isn't always precise; it's often ambiguous and the linguistic structure can depend on many complex variables, including slang, regional dialects and social context.\n- Tone of voice and inflection. Natural language processing hasn't yet been perfected. For example, semantic analysis can still be a challenge. Other difficulties include the fact that the abstract use of language is typically tricky and complex for programs to understand. For instance, natural language processing doesn't pick up sarcasm easily. These topics usually require understanding the words being used and their context in a conversation. Also, a sentence can change meaning depending on which word or syllable the speaker puts stress on. NLP algorithms can miss the subtle but important tone changes in a person's voice when performing speech recognition. The tone and inflection of speech can also vary among different accents, which can be challenging for an algorithm to parse.\n- Evolving use of language. Natural language processing is also challenged by the fact that language -- and the way people use it -- is continually changing. Although there are rules to language, none are written in stone, and they're subject to change over time. Hard computational rules that work now might become obsolete, as the characteristics of real-world language change over time.\n- Bias. NLP systems can be biased when their processes reflect the biases that appear in their training data. This is an issue in medical fields and hiring positions, where a person might be discriminated against.\nThe evolution of natural language processing\nNLP draws from a variety of disciplines, including computer science and computational linguistics developments dating back to the mid-20th century. Its evolution included the following major milestones:\n1950s\nNatural language processing has its roots in this decade, when Alan Turing developed the Turing Test to determine whether or not a computer is truly intelligent. The test involves automated interpretation and the generation of natural language as a criterion of intelligence.\n1950s-1990s\nNLP was largely rules-based, using handcrafted rules developed by linguists to determine how computers would process language. The Georgetown-IBM experiment in 1954 became a notable demonstration of machine translation, automatically translating more than 60 sentences from Russian to English. The 1980s and 1990s saw the development of rule-based parsing, morphology, semantics and other forms of natural language understanding.\n1990s\nThe top-down, language-first approach to natural language processing was replaced with a more statistical approach because advancements in computing made this a more efficient way of developing NLP technology. Computers were becoming faster and could be used to develop rules based on linguistic statistics without a linguist creating all the rules. Data-driven natural language processing became mainstream during this decade. Natural language processing shifted from a linguist-based approach to an engineer-based approach, drawing on a wider variety of scientific disciplines instead of delving into linguistics.\n2000-2020s\nNatural language processing saw dramatic growth in popularity as a term. NLP processes using unsupervised and semi-supervised machine learning algorithms were also explored. With advances in computing power, natural language processing has also gained numerous real-world applications. NLP also began powering other applications like chatbots and virtual assistants. Today, approaches to NLP involve a combination of classical linguistics and statistical methods.\nNatural language processing plays a vital part in technology and the way humans interact with it. Though it has its challenges, NLP is expected to become more accurate with more sophisticated models, more accessible and more relevant in numerous industries. NLP will continue to be an important part of both industry and everyday life.\nAs natural language processing is making significant strides in new fields, it's becoming more important for developers to learn how it works. Learn how to develop your skills in creating NLP programs.",
    "scraped_at":"2025-07-07T18:26:09.878426"
  }
]